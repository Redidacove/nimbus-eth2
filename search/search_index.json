{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"The Nimbus Guide Nimbus is a client for the Ethereum network that is lightweight , secure and easy to use . Its efficiency and low resource consumption allows it to perform well on all kinds of systems: ranging from Raspberry Pi and mobile devices \u2014 where it contributes to low power consumption and security \u2014 to powerful servers where it leaves resources free to perform other tasks, such as running an execution node . This book describes the consensus layer client, nimbus-eth2 . An execution client, nimbus-eth1 , is also under development. Feature highlights Beacon node with integrated validator client, slashing protection and doppelganger detection Stand-alone validator client with sentry node support Fast Beacon and KeyManager APIs with extensions Web3Signer remote signing Validator monitoring and performance analysis tooling External block builder (PBS / mev-boost) support with execution client fallback Light consensus client for running an execution client without a full beacon node Design goals One of our most important design goals is an application architecture that makes it simple to embed Nimbus into other software. Another goal is to minimize reliance on third-party software. A third one is for the application binary to be as lightweight as possible in terms of resources used. Integration with Status I can't wait to run Nimbus straight from Status Desktop #hyped \u2014 JARRA\u00d0 HOP\u039e (@jarradhope) August 12, 2020 As part of our first design goal, our primary objective here is for Nimbus to be tightly integrated into the Status messaging app . Our dream is for you to be able to run and monitor your validator straight from Status desktop. Book contents You can read this book from start to finish, or you might want to read just specific topics you're interested in: If you're eager to get started, the quickstart guide is for you. Coming from a different client? Check out the migration guide . Visualize the important metrics with Grafana and Prometheus . Interested in becoming a validator? Follow the validator guide . If you're not planning on becoming a validator, you can run the light client . Get in touch Need help with anything? Join us on Status and Discord . Donate If you'd like to contribute to Nimbus development: Our donation address is 0xDeb4A0e8d9a8dB30a9f53AF2dCc9Eb27060c6557 We're also listed on GitCoin Stay updated Subscribe to our newsletter here . Disclaimer This documentation assumes Nimbus is in its ideal state. The project is still under active development. Please submit a Github issue if you come across a problem.","title":"The Nimbus Guide"},{"location":"index.html#the-nimbus-guide","text":"Nimbus is a client for the Ethereum network that is lightweight , secure and easy to use . Its efficiency and low resource consumption allows it to perform well on all kinds of systems: ranging from Raspberry Pi and mobile devices \u2014 where it contributes to low power consumption and security \u2014 to powerful servers where it leaves resources free to perform other tasks, such as running an execution node . This book describes the consensus layer client, nimbus-eth2 . An execution client, nimbus-eth1 , is also under development.","title":"The Nimbus Guide"},{"location":"index.html#feature-highlights","text":"Beacon node with integrated validator client, slashing protection and doppelganger detection Stand-alone validator client with sentry node support Fast Beacon and KeyManager APIs with extensions Web3Signer remote signing Validator monitoring and performance analysis tooling External block builder (PBS / mev-boost) support with execution client fallback Light consensus client for running an execution client without a full beacon node","title":"Feature highlights"},{"location":"index.html#design-goals","text":"One of our most important design goals is an application architecture that makes it simple to embed Nimbus into other software. Another goal is to minimize reliance on third-party software. A third one is for the application binary to be as lightweight as possible in terms of resources used.","title":"Design goals"},{"location":"index.html#integration-with-status","text":"I can't wait to run Nimbus straight from Status Desktop #hyped \u2014 JARRA\u00d0 HOP\u039e (@jarradhope) August 12, 2020 As part of our first design goal, our primary objective here is for Nimbus to be tightly integrated into the Status messaging app . Our dream is for you to be able to run and monitor your validator straight from Status desktop.","title":"Integration with Status"},{"location":"index.html#book-contents","text":"You can read this book from start to finish, or you might want to read just specific topics you're interested in: If you're eager to get started, the quickstart guide is for you. Coming from a different client? Check out the migration guide . Visualize the important metrics with Grafana and Prometheus . Interested in becoming a validator? Follow the validator guide . If you're not planning on becoming a validator, you can run the light client .","title":"Book contents"},{"location":"index.html#get-in-touch","text":"Need help with anything? Join us on Status and Discord .","title":"Get in touch"},{"location":"index.html#donate","text":"If you'd like to contribute to Nimbus development: Our donation address is 0xDeb4A0e8d9a8dB30a9f53AF2dCc9Eb27060c6557 We're also listed on GitCoin","title":"Donate"},{"location":"index.html#stay-updated","text":"Subscribe to our newsletter here .","title":"Stay updated"},{"location":"index.html#disclaimer","text":"This documentation assumes Nimbus is in its ideal state. The project is still under active development. Please submit a Github issue if you come across a problem.","title":"Disclaimer"},{"location":"additional-validator.html","text":"Add an additional validator To add an additional validator, generate a new key then follow the same steps as you did when adding your other keys. You'll have to restart the beacon node for the changes to take effect. Tip A single Nimbus instance is able to handle multiple validators.","title":"Add an additional validator"},{"location":"additional-validator.html#add-an-additional-validator","text":"To add an additional validator, generate a new key then follow the same steps as you did when adding your other keys. You'll have to restart the beacon node for the changes to take effect. Tip A single Nimbus instance is able to handle multiple validators.","title":"Add an additional validator"},{"location":"api.html","text":"JSON-RPC API (deprecated) Warning As of v22.6.0, the Nimbus JSON-RPC interface has been removed following an extended deprecation period. You are encouraged to migrate your applications to the REST API . The JSON-RPC API pre-dated the REST API and was based on early designs of the beacon chain. This guide is kept for historical reference, as well as to aid migration. Beacon chain API get_v1_beacon_genesis curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_genesis\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/genesis -s | jq get_v1_beacon_states_root curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_root\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/root -s | jq get_v1_beacon_states_fork curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_fork\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/fork -s | jq get_v1_beacon_states_finality_checkpoints curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_finality_checkpoints\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/finality_checkpoints -s | jq get_v1_beacon_states_stateId_validators curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_validators\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/validators -s | jq get_v1_beacon_states_stateId_validators_validatorId curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_validators_validatorId\",\"params\":[\"finalized\", \"100167\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/validators/100167 -s | jq get_v1_beacon_states_stateId_validator_balances curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_validator_balances\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/validator_balances -s | jq get_v1_beacon_states_stateId_committees_epoch curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_committees_epoch\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/committees -s | jq get_v1_beacon_headers get_v1_beacon_headers_blockId curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_headers_blockId\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/headers/finalized -s | jq post_v1_beacon_blocks curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_blocks\",\"params\":[{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body\":{\"randao_reveal\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"eth1_data\":{\"deposit_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"deposit_count\":\"1\",\"block_hash\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"graffiti\":\"string\",\"proposer_slashings\":[{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"attester_slashings\":[{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}],\"attestations\":[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}],\"deposits\":[{\"proof\":[\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"],\"data\":{\"pubkey\":\"0x93247f2209abcacf57b75a51dafae777f9dd38bc7053d1af526f220a7489a6d3a2753e5f3e8b1cfe39b56f43611df74a\",\"withdrawal_credentials\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"amount\":\"1\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"voluntary_exits\":[{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}]}},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body\":{\"randao_reveal\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"eth1_data\":{\"deposit_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"deposit_count\":\"1\",\"block_hash\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"graffiti\":\"string\",\"proposer_slashings\":[{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"attester_slashings\":[{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}],\"attestations\":[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}],\"deposits\":[{\"proof\":[\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"],\"data\":{\"pubkey\":\"0x93247f2209abcacf57b75a51dafae777f9dd38bc7053d1af526f220a7489a6d3a2753e5f3e8b1cfe39b56f43611df74a\",\"withdrawal_credentials\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"amount\":\"1\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"voluntary_exits\":[{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}]}},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/blocks -s | jq get_v1_beacon_blocks_blockId curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v2/beacon/blocks/finalized -s | jq get_v1_beacon_blocks_blockId_root curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId_root\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/blocks/finalized/root -s | jq get_v1_beacon_blocks_blockId_attestations curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId_attestations\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/blocks/finalized/attestations -s | jq post_v1_beacon_pool_attestations curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId_attestations\",\"params\":[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}]' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/attestations -s | jq get_v1_beacon_pool_attester_slashings curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_pool_attester_slashings\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/pool/attester_slashings -s | jq post_v1_beacon_pool_attester_slashings curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_pool_attester_slashings\",\"params\":[{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/attester_slashings -s | jq get_v1_beacon_pool_proposer_slashings curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_pool_proposer_slashings\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/pool/proposer_slashings -s | jq post_v1_beacon_pool_proposer_slashings curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_pool_proposer_slashings\",\"params\":[{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/proposer_slashings -s | jq get_v1_beacon_pool_voluntary_exits curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_pool_voluntary_exits\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/pool/voluntary_exits -s | jq post_v1_beacon_pool_voluntary_exits curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_pool_voluntary_exits\",\"params\":[{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/voluntary_exits -s | jq Beacon Node API get_v1_node_identity curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_identity\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/identity -s | jq get_v1_node_peers curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_peers\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/peers -s | jq get_v1_node_peers_peerId curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_peers_peerId\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/peer/QmYyQSo1c1Ym7orWxLYvCrM2EmxFTANf8wXmmE7DWjhx5N -s | jq get_v1_node_peer_count curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_peer_count\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/peer_count -s | jq get_v1_node_version curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_version\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/version -s | jq get_v1_node_syncing curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_syncing\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/syncing -s | jq get_v1_node_health curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_health\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/health -s -w \"%{http_code}\" Validator API get_v1_validator_duties_attester curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_duties_attester\",\"params\":[1,[\"a7a0502eae26043d1ac39a39457a6cdf68fae2055d89c7dc59092c25911e4ee55c4e7a31ade61c39480110a393be28e8\",\"a1826dd94cd96c48a81102d316a2af4960d19ca0b574ae5695f2d39a88685a43997cef9a5c26ad911847674d20c46b75\"]],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/eth/v1/validator/duties/attester/1 -H 'Content-Type: application/json' -d '[\"a7a0502eae26043d1ac39a39457a6cdf68fae2055d89c7dc59092c25911e4ee55c4e7a31ade61c39480110a393be28e8\"]' -s | jq get_v1_validator_duties_proposer curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"get_v1_validator_duties_proposer\",\"params\":[1] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/duties/proposer/1 -s | jq get_v1_validator_block curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_block\",\"params\":[1,\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"0x4e696d6275732f76312e302e322d64333032633164382d73746174656f667573\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v2/validator/blocks/1?randao_reveal=0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505&graffiti=0x4e696d6275732f76312e302e322d64333032633164382d73746174656f667573 -s | jq get_v1_validator_attestation_data curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_attestation_data\",\"params\":[1, 1],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/attestation_data?slot=1&committee_index=1 -s | jq get_v1_validator_aggregate_attestation curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_aggregate_attestation\",\"params\":[1, \"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/aggregate_attestation?slot=1&attestation_data_root=0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2 -s | jq post_v1_validator_aggregate_and_proofs curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_validator_aggregate_and_proofs\",\"params\":[{\"message\":{\"aggregator_index\":\"1\",\"aggregate\":{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"selection_proof\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/eth/v1/validator/aggregate_and_proofs -H 'Content-Type: application/json' -d '[{\"message\":{\"aggregator_index\":\"1\",\"aggregate\":{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"selection_proof\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}]' -s | jq post_v1_validator_beacon_committee_subscriptions Config API get_v1_config_fork_schedule curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_config_fork_schedule\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/config/fork_schedule -s | jq get_v1_config_spec curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_config_spec\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/config/spec -s | jq get_v1_config_deposit_contract curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_config_deposit_contract\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/config/deposit_contract -s | jq Administrative / Debug API get_v1_debug_beacon_states_stateId curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_debug_beacon_states_stateId\",\"params\":[\"head\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v2/debug/beacon/states/head -s | jq get_v2_debug_beacon_heads Equivalent call in the official REST API: curl http://localhost:5052/eth/v2/debug/beacon/heads -s | jq Nimbus extensions getBeaconHead The latest head slot, as chosen by the latest fork choice. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getBeaconHead\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/beacon/head -s | jq getChainHead Show chain head information, including head, justified and finalized checkpoints. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getChainHead\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/chain/head -s | jq getNodeVersion curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getNodeVersion\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/node/version -s | jq peers Show a list of peers in PeerPool. curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"peers\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/network/peers -s | jq getSyncing Shows current state of forward syncing manager. curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getSyncing\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/syncmanager/status -s | jq getNetworkPeerId Shows current node's libp2p peer identifier (PeerID). curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getNetworkPeerId\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq getNetworkPeers Shows list of available PeerIDs in PeerPool. curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getNetworkPeers\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/network/peers -s | jq getNetworkEnr setLogLevel Set the current logging level dynamically: TRACE, DEBUG, INFO, NOTICE, WARN, ERROR or FATAL curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"setLogLevel\",\"params\":[\"DEBUG; TRACE:discv5,libp2p; REQUIRED:none; DISABLED:none\"] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/nimbus/v1/chronicles/settings -d \"DEBUG; TRACE:discv5,libp2p; REQUIRED:none; DISABLED:none\" -s | jq setGraffiti Set the graffiti bytes that will be included in proposed blocks. The graffiti bytes can be specified as an UTF-8 encoded string or as an 0x-prefixed hex string specifying raw bytes. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"setGraffiti\",\"params\":[\"Mr F was here\"] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/nimbus/v1/graffiti -d \"Mr F was here\" -s | jq getEth1Chain Get the list of Eth1 blocks that the beacon node is currently storing in memory. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getEth1Chain\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/eth1/chain -s | jq getEth1ProposalData Inspect the eth1 data that the beacon node would produce if it was tasked to produce a block for the current slot. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getEth1ProposalData\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/eth1/proposal_data -s | jq debug_getChronosFutures Get the current list of live async futures in the process - compile with -d:chronosFutureTracking to enable. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"debug_getChronosFutures\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result | (.[0] | keys_unsorted) as $keys | $keys, map([.[ $keys[] ]])[] | @csv' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/debug/chronos/futures -s | jq debug_getGossipSubPeers Get the current list of live async futures in the process - compile with -d:chronosFutureTracking to enable. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"debug_getGossipSubPeers\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/debug/gossip/peers -s | jq","title":"JSON-RPC API (deprecated)"},{"location":"api.html#json-rpc-api-deprecated","text":"Warning As of v22.6.0, the Nimbus JSON-RPC interface has been removed following an extended deprecation period. You are encouraged to migrate your applications to the REST API . The JSON-RPC API pre-dated the REST API and was based on early designs of the beacon chain. This guide is kept for historical reference, as well as to aid migration.","title":"JSON-RPC API (deprecated)"},{"location":"api.html#beacon-chain-api","text":"","title":"Beacon chain API"},{"location":"api.html#get_v1_beacon_genesis","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_genesis\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/genesis -s | jq","title":"get_v1_beacon_genesis"},{"location":"api.html#get_v1_beacon_states_root","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_root\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/root -s | jq","title":"get_v1_beacon_states_root"},{"location":"api.html#get_v1_beacon_states_fork","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_fork\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/fork -s | jq","title":"get_v1_beacon_states_fork"},{"location":"api.html#get_v1_beacon_states_finality_checkpoints","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_finality_checkpoints\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/finality_checkpoints -s | jq","title":"get_v1_beacon_states_finality_checkpoints"},{"location":"api.html#get_v1_beacon_states_stateid_validators","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_validators\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/validators -s | jq","title":"get_v1_beacon_states_stateId_validators"},{"location":"api.html#get_v1_beacon_states_stateid_validators_validatorid","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_validators_validatorId\",\"params\":[\"finalized\", \"100167\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/validators/100167 -s | jq","title":"get_v1_beacon_states_stateId_validators_validatorId"},{"location":"api.html#get_v1_beacon_states_stateid_validator_balances","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_validator_balances\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/validator_balances -s | jq","title":"get_v1_beacon_states_stateId_validator_balances"},{"location":"api.html#get_v1_beacon_states_stateid_committees_epoch","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_states_stateId_committees_epoch\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/states/finalized/committees -s | jq","title":"get_v1_beacon_states_stateId_committees_epoch"},{"location":"api.html#get_v1_beacon_headers","text":"","title":"get_v1_beacon_headers"},{"location":"api.html#get_v1_beacon_headers_blockid","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_headers_blockId\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/headers/finalized -s | jq","title":"get_v1_beacon_headers_blockId"},{"location":"api.html#post_v1_beacon_blocks","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_blocks\",\"params\":[{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body\":{\"randao_reveal\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"eth1_data\":{\"deposit_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"deposit_count\":\"1\",\"block_hash\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"graffiti\":\"string\",\"proposer_slashings\":[{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"attester_slashings\":[{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}],\"attestations\":[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}],\"deposits\":[{\"proof\":[\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"],\"data\":{\"pubkey\":\"0x93247f2209abcacf57b75a51dafae777f9dd38bc7053d1af526f220a7489a6d3a2753e5f3e8b1cfe39b56f43611df74a\",\"withdrawal_credentials\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"amount\":\"1\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"voluntary_exits\":[{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}]}},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body\":{\"randao_reveal\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"eth1_data\":{\"deposit_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"deposit_count\":\"1\",\"block_hash\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"graffiti\":\"string\",\"proposer_slashings\":[{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"attester_slashings\":[{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}],\"attestations\":[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}],\"deposits\":[{\"proof\":[\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"],\"data\":{\"pubkey\":\"0x93247f2209abcacf57b75a51dafae777f9dd38bc7053d1af526f220a7489a6d3a2753e5f3e8b1cfe39b56f43611df74a\",\"withdrawal_credentials\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"amount\":\"1\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"voluntary_exits\":[{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}]}},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/blocks -s | jq","title":"post_v1_beacon_blocks"},{"location":"api.html#get_v1_beacon_blocks_blockid","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v2/beacon/blocks/finalized -s | jq","title":"get_v1_beacon_blocks_blockId"},{"location":"api.html#get_v1_beacon_blocks_blockid_root","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId_root\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/blocks/finalized/root -s | jq","title":"get_v1_beacon_blocks_blockId_root"},{"location":"api.html#get_v1_beacon_blocks_blockid_attestations","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId_attestations\",\"params\":[\"finalized\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/blocks/finalized/attestations -s | jq","title":"get_v1_beacon_blocks_blockId_attestations"},{"location":"api.html#post_v1_beacon_pool_attestations","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_blocks_blockId_attestations\",\"params\":[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '[{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}]' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/attestations -s | jq","title":"post_v1_beacon_pool_attestations"},{"location":"api.html#get_v1_beacon_pool_attester_slashings","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_pool_attester_slashings\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/pool/attester_slashings -s | jq","title":"get_v1_beacon_pool_attester_slashings"},{"location":"api.html#post_v1_beacon_pool_attester_slashings","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_pool_attester_slashings\",\"params\":[{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"attestation_1\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"attestation_2\":{\"attesting_indices\":[\"1\"],\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}}}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/attester_slashings -s | jq","title":"post_v1_beacon_pool_attester_slashings"},{"location":"api.html#get_v1_beacon_pool_proposer_slashings","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_pool_proposer_slashings\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/pool/proposer_slashings -s | jq","title":"get_v1_beacon_pool_proposer_slashings"},{"location":"api.html#post_v1_beacon_pool_proposer_slashings","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_pool_proposer_slashings\",\"params\":[{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"signed_header_1\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signed_header_2\":{\"message\":{\"slot\":\"1\",\"proposer_index\":\"1\",\"parent_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"state_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"body_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/proposer_slashings -s | jq","title":"post_v1_beacon_pool_proposer_slashings"},{"location":"api.html#get_v1_beacon_pool_voluntary_exits","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_beacon_pool_voluntary_exits\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/beacon/pool/voluntary_exits -s | jq","title":"get_v1_beacon_pool_voluntary_exits"},{"location":"api.html#post_v1_beacon_pool_voluntary_exits","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_beacon_pool_voluntary_exits\",\"params\":[{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST -d '{\"message\":{\"epoch\":\"1\",\"validator_index\":\"1\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}' -H 'Content-Type: application/json' http://localhost:5052/eth/v1/beacon/pool/voluntary_exits -s | jq","title":"post_v1_beacon_pool_voluntary_exits"},{"location":"api.html#beacon-node-api","text":"","title":"Beacon Node API"},{"location":"api.html#get_v1_node_identity","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_identity\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/identity -s | jq","title":"get_v1_node_identity"},{"location":"api.html#get_v1_node_peers","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_peers\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/peers -s | jq","title":"get_v1_node_peers"},{"location":"api.html#get_v1_node_peers_peerid","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_peers_peerId\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/peer/QmYyQSo1c1Ym7orWxLYvCrM2EmxFTANf8wXmmE7DWjhx5N -s | jq","title":"get_v1_node_peers_peerId"},{"location":"api.html#get_v1_node_peer_count","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_peer_count\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/peer_count -s | jq","title":"get_v1_node_peer_count"},{"location":"api.html#get_v1_node_version","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_version\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/version -s | jq","title":"get_v1_node_version"},{"location":"api.html#get_v1_node_syncing","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_syncing\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/syncing -s | jq","title":"get_v1_node_syncing"},{"location":"api.html#get_v1_node_health","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_node_health\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/node/health -s -w \"%{http_code}\"","title":"get_v1_node_health"},{"location":"api.html#validator-api","text":"","title":"Validator API"},{"location":"api.html#get_v1_validator_duties_attester","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_duties_attester\",\"params\":[1,[\"a7a0502eae26043d1ac39a39457a6cdf68fae2055d89c7dc59092c25911e4ee55c4e7a31ade61c39480110a393be28e8\",\"a1826dd94cd96c48a81102d316a2af4960d19ca0b574ae5695f2d39a88685a43997cef9a5c26ad911847674d20c46b75\"]],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/eth/v1/validator/duties/attester/1 -H 'Content-Type: application/json' -d '[\"a7a0502eae26043d1ac39a39457a6cdf68fae2055d89c7dc59092c25911e4ee55c4e7a31ade61c39480110a393be28e8\"]' -s | jq","title":"get_v1_validator_duties_attester"},{"location":"api.html#get_v1_validator_duties_proposer","text":"curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"get_v1_validator_duties_proposer\",\"params\":[1] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/duties/proposer/1 -s | jq","title":"get_v1_validator_duties_proposer"},{"location":"api.html#get_v1_validator_block","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_block\",\"params\":[1,\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"0x4e696d6275732f76312e302e322d64333032633164382d73746174656f667573\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v2/validator/blocks/1?randao_reveal=0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505&graffiti=0x4e696d6275732f76312e302e322d64333032633164382d73746174656f667573 -s | jq","title":"get_v1_validator_block"},{"location":"api.html#get_v1_validator_attestation_data","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_attestation_data\",\"params\":[1, 1],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/attestation_data?slot=1&committee_index=1 -s | jq","title":"get_v1_validator_attestation_data"},{"location":"api.html#get_v1_validator_aggregate_attestation","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_aggregate_attestation\",\"params\":[1, \"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/validator/aggregate_attestation?slot=1&attestation_data_root=0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2 -s | jq","title":"get_v1_validator_aggregate_attestation"},{"location":"api.html#post_v1_validator_aggregate_and_proofs","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"post_v1_validator_aggregate_and_proofs\",\"params\":[{\"message\":{\"aggregator_index\":\"1\",\"aggregate\":{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"selection_proof\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/eth/v1/validator/aggregate_and_proofs -H 'Content-Type: application/json' -d '[{\"message\":{\"aggregator_index\":\"1\",\"aggregate\":{\"aggregation_bits\":\"0x01\",\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\",\"data\":{\"slot\":\"1\",\"index\":\"1\",\"beacon_block_root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\",\"source\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"},\"target\":{\"epoch\":\"1\",\"root\":\"0xcf8e0d4e9587369b2301d0790347320302cc0943d5a1884560367e8208d920f2\"}}},\"selection_proof\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"},\"signature\":\"0x1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505cc411d61252fb6cb3fa0017b679f8bb2305b26a285fa2737f175668d0dff91cc1b66ac1fb663c9bc59509846d6ec05345bd908eda73e670af888da41af171505\"}]' -s | jq","title":"post_v1_validator_aggregate_and_proofs"},{"location":"api.html#post_v1_validator_beacon_committee_subscriptions","text":"","title":"post_v1_validator_beacon_committee_subscriptions"},{"location":"api.html#config-api","text":"","title":"Config API"},{"location":"api.html#get_v1_config_fork_schedule","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_config_fork_schedule\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/config/fork_schedule -s | jq","title":"get_v1_config_fork_schedule"},{"location":"api.html#get_v1_config_spec","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_config_spec\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/config/spec -s | jq","title":"get_v1_config_spec"},{"location":"api.html#get_v1_config_deposit_contract","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_config_deposit_contract\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v1/config/deposit_contract -s | jq","title":"get_v1_config_deposit_contract"},{"location":"api.html#administrative-debug-api","text":"","title":"Administrative / Debug API"},{"location":"api.html#get_v1_debug_beacon_states_stateid","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_debug_beacon_states_stateId\",\"params\":[\"head\"],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/eth/v2/debug/beacon/states/head -s | jq","title":"get_v1_debug_beacon_states_stateId"},{"location":"api.html#get_v2_debug_beacon_heads","text":"Equivalent call in the official REST API: curl http://localhost:5052/eth/v2/debug/beacon/heads -s | jq","title":"get_v2_debug_beacon_heads"},{"location":"api.html#nimbus-extensions","text":"","title":"Nimbus extensions"},{"location":"api.html#getbeaconhead","text":"The latest head slot, as chosen by the latest fork choice. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getBeaconHead\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/beacon/head -s | jq","title":"getBeaconHead"},{"location":"api.html#getchainhead","text":"Show chain head information, including head, justified and finalized checkpoints. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getChainHead\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/chain/head -s | jq","title":"getChainHead"},{"location":"api.html#getnodeversion","text":"curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getNodeVersion\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/node/version -s | jq","title":"getNodeVersion"},{"location":"api.html#peers","text":"Show a list of peers in PeerPool. curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"peers\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/network/peers -s | jq","title":"peers"},{"location":"api.html#getsyncing","text":"Shows current state of forward syncing manager. curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getSyncing\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/syncmanager/status -s | jq","title":"getSyncing"},{"location":"api.html#getnetworkpeerid","text":"Shows current node's libp2p peer identifier (PeerID). curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getNetworkPeerId\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq","title":"getNetworkPeerId"},{"location":"api.html#getnetworkpeers","text":"Shows list of available PeerIDs in PeerPool. curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"getNetworkPeers\",\"params\":[],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/network/peers -s | jq","title":"getNetworkPeers"},{"location":"api.html#getnetworkenr","text":"","title":"getNetworkEnr"},{"location":"api.html#setloglevel","text":"Set the current logging level dynamically: TRACE, DEBUG, INFO, NOTICE, WARN, ERROR or FATAL curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"setLogLevel\",\"params\":[\"DEBUG; TRACE:discv5,libp2p; REQUIRED:none; DISABLED:none\"] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/nimbus/v1/chronicles/settings -d \"DEBUG; TRACE:discv5,libp2p; REQUIRED:none; DISABLED:none\" -s | jq","title":"setLogLevel"},{"location":"api.html#setgraffiti","text":"Set the graffiti bytes that will be included in proposed blocks. The graffiti bytes can be specified as an UTF-8 encoded string or as an 0x-prefixed hex string specifying raw bytes. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"setGraffiti\",\"params\":[\"Mr F was here\"] }' -H 'Content-Type: application/json' localhost:9190 -s | jq Equivalent call in the official REST API: curl -X POST http://localhost:5052/nimbus/v1/graffiti -d \"Mr F was here\" -s | jq","title":"setGraffiti"},{"location":"api.html#geteth1chain","text":"Get the list of Eth1 blocks that the beacon node is currently storing in memory. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getEth1Chain\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/eth1/chain -s | jq","title":"getEth1Chain"},{"location":"api.html#geteth1proposaldata","text":"Inspect the eth1 data that the beacon node would produce if it was tasked to produce a block for the current slot. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"getEth1ProposalData\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/eth1/proposal_data -s | jq","title":"getEth1ProposalData"},{"location":"api.html#debug_getchronosfutures","text":"Get the current list of live async futures in the process - compile with -d:chronosFutureTracking to enable. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"debug_getChronosFutures\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result | (.[0] | keys_unsorted) as $keys | $keys, map([.[ $keys[] ]])[] | @csv' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/debug/chronos/futures -s | jq","title":"debug_getChronosFutures"},{"location":"api.html#debug_getgossipsubpeers","text":"Get the current list of live async futures in the process - compile with -d:chronosFutureTracking to enable. curl -d '{\"jsonrpc\":\"2.0\",\"id\":\"id\",\"method\":\"debug_getGossipSubPeers\",\"params\":[] }' -H 'Content-Type: application/json' localhost:9190 -s | jq '.result' Equivalent call in the official REST API: curl http://localhost:5052/nimbus/v1/debug/gossip/peers -s | jq","title":"debug_getGossipSubPeers"},{"location":"attestation-performance.html","text":"Attestation performance ncli_db validatorPerf is an advanced tool that helps you analyze the performance of your validator over time. The tool requires that you build nimbus from source . Steps Make sure you're in the nimbus-eth2 repository. 1. Build ncli_db The first step is to build ncli_db : make ncli_db 2. View options To view the options available to you, run: build/ncli_db --help At the top you should see: ncli_db [OPTIONS]... command The following options are available: --db Directory where `nbc.sqlite` is stored. --network The Eth2 network preset to use. Where: The network can be mainnet , holesky , or sepolia . The default location of the db is build/data/shared_mainnet_0/db for mainnet , build/data/shared_holesky_0/db for holesky , etc. Near the bottom, you should see: ncli_db validatorPerf [OPTIONS]... The following options are available: --start-slot Starting slot, negative = backwards from head [=-128 * SLOTS_PER_EPOCH.int64]. --slots Number of slots to run benchmark for, 0 = all the way to head [=0]. Use start-slot and slots to restrict the analysis on a specific block range. 3. Run To view the performance of all validators on Holesky so far across the entire block range stored in your database, run: build/ncli_db validatorPerf \\ --network = holesky \\ --db = build/data/shared_holesky_0/db You should see output that looks like to the following: validator_index,attestation_hits,attestation_misses,head_attestation_hits,head_attestation_misses,target_attestation_hits,target_attestation_misses,delay_avg,first_slot_head_attester_when_first_slot_empty,first_slot_head_attester_when_first_slot_not_empty 0,128,0,127,1,128,0,1.0078125,0,3 1,128,0,125,3,127,1,1.0078125,0,2 2,128,0,127,1,127,1,1.0078125,0,5 ... 4. Adjust to target a specific block range To restrict the analysis to the performance between slots 0 and 128, say, run: build/ncli_db validatorPerf \\ --network = holesky \\ --db = build/data/shared_holesky_0/db \\ --start-slot = 0 \\ --slots = 128 5. Compare my validators to the global average We'll use Paul Hauner's wonderful workbook as a template. This workbook consists of three inter-related spreadsheets: Summary , My Validators , and datasource . Make a copy of the document. Remove the table entries in My Validators and delete everything in the datasource sheet. Import the output from validatorPerf to datasource . The easiest way to do this is to pipe the output to a csv , remove the first few lines, and import the csv into datasource . Manually copy over your validator(s) to the My Validators sheet. The easiest way to find your validator's validator_index is to search for it by its public key on beaconcha.in (for example, this validator's index is 115733). Go to the Summary page and view your results. Resources The workbook's method is explained here .","title":"Attestation performance"},{"location":"attestation-performance.html#attestation-performance","text":"ncli_db validatorPerf is an advanced tool that helps you analyze the performance of your validator over time. The tool requires that you build nimbus from source .","title":"Attestation performance"},{"location":"attestation-performance.html#steps","text":"Make sure you're in the nimbus-eth2 repository.","title":"Steps"},{"location":"attestation-performance.html#1-build-ncli_db","text":"The first step is to build ncli_db : make ncli_db","title":"1. Build ncli_db"},{"location":"attestation-performance.html#2-view-options","text":"To view the options available to you, run: build/ncli_db --help At the top you should see: ncli_db [OPTIONS]... command The following options are available: --db Directory where `nbc.sqlite` is stored. --network The Eth2 network preset to use. Where: The network can be mainnet , holesky , or sepolia . The default location of the db is build/data/shared_mainnet_0/db for mainnet , build/data/shared_holesky_0/db for holesky , etc. Near the bottom, you should see: ncli_db validatorPerf [OPTIONS]... The following options are available: --start-slot Starting slot, negative = backwards from head [=-128 * SLOTS_PER_EPOCH.int64]. --slots Number of slots to run benchmark for, 0 = all the way to head [=0]. Use start-slot and slots to restrict the analysis on a specific block range.","title":"2. View options"},{"location":"attestation-performance.html#3-run","text":"To view the performance of all validators on Holesky so far across the entire block range stored in your database, run: build/ncli_db validatorPerf \\ --network = holesky \\ --db = build/data/shared_holesky_0/db You should see output that looks like to the following: validator_index,attestation_hits,attestation_misses,head_attestation_hits,head_attestation_misses,target_attestation_hits,target_attestation_misses,delay_avg,first_slot_head_attester_when_first_slot_empty,first_slot_head_attester_when_first_slot_not_empty 0,128,0,127,1,128,0,1.0078125,0,3 1,128,0,125,3,127,1,1.0078125,0,2 2,128,0,127,1,127,1,1.0078125,0,5 ...","title":"3. Run"},{"location":"attestation-performance.html#4-adjust-to-target-a-specific-block-range","text":"To restrict the analysis to the performance between slots 0 and 128, say, run: build/ncli_db validatorPerf \\ --network = holesky \\ --db = build/data/shared_holesky_0/db \\ --start-slot = 0 \\ --slots = 128","title":"4. Adjust to target a specific block range"},{"location":"attestation-performance.html#5-compare-my-validators-to-the-global-average","text":"We'll use Paul Hauner's wonderful workbook as a template. This workbook consists of three inter-related spreadsheets: Summary , My Validators , and datasource . Make a copy of the document. Remove the table entries in My Validators and delete everything in the datasource sheet. Import the output from validatorPerf to datasource . The easiest way to do this is to pipe the output to a csv , remove the first few lines, and import the csv into datasource . Manually copy over your validator(s) to the My Validators sheet. The easiest way to find your validator's validator_index is to search for it by its public key on beaconcha.in (for example, this validator's index is 115733). Go to the Summary page and view your results.","title":"5. Compare my validators to the global average"},{"location":"attestation-performance.html#resources","text":"The workbook's method is explained here .","title":"Resources"},{"location":"audit.html","text":"Security Audit Summary Nimbus has undergone an extensive multi-vendor ( ConsenSys Diligence , NCC Group , and Trail of Bits ) security assessment over a period of several months. During that process, we were notified of several issues within the codebase. These issues have been addressed, contributing significantly to the overall security of Nimbus and other applications that use its libraries. Additionally, as a result of the work done from our security vendors, we have incoroprated many new security processes and tooling to improve our ability to find security issues in the future. For more information on the issues and how they were addressed, the interested reader should direct themselves to the scoped repositories ; all reported issues and their mitigations are open to the public. History Back in May of 2020, Status and the Nimbus Team posted a Request for Proposal document regarding the security assessment of the nimbus-eth2 repository (formerly nim-beacon-chain ) and its software dependencies. After thoroughly vetting and weighing the submitted proposals, three security vendors were chosen to review the codebase for a timeline of approximately three months . The kickoff announcement can be read here . We separated the codebase into sub-topics with various tasks. These tasks were then broken up and assigned to the vendor(s) with the required expertise. The desired deliverable outcome was GitHub issues in the repositories under review, which is a shift from the standard \u201cassessment report\u201d provided by most security assessments in the space. You can view the issues here . To be very clear, we did not engage in this security assessment to get a stamp of approval from the security community. All of the effort put into creating this process and engaging the community was in the service of increasing the level of security and code quality of the Nimbus software.","title":"Security Audit"},{"location":"audit.html#security-audit","text":"","title":"Security Audit"},{"location":"audit.html#summary","text":"Nimbus has undergone an extensive multi-vendor ( ConsenSys Diligence , NCC Group , and Trail of Bits ) security assessment over a period of several months. During that process, we were notified of several issues within the codebase. These issues have been addressed, contributing significantly to the overall security of Nimbus and other applications that use its libraries. Additionally, as a result of the work done from our security vendors, we have incoroprated many new security processes and tooling to improve our ability to find security issues in the future. For more information on the issues and how they were addressed, the interested reader should direct themselves to the scoped repositories ; all reported issues and their mitigations are open to the public.","title":"Summary"},{"location":"audit.html#history","text":"Back in May of 2020, Status and the Nimbus Team posted a Request for Proposal document regarding the security assessment of the nimbus-eth2 repository (formerly nim-beacon-chain ) and its software dependencies. After thoroughly vetting and weighing the submitted proposals, three security vendors were chosen to review the codebase for a timeline of approximately three months . The kickoff announcement can be read here . We separated the codebase into sub-topics with various tasks. These tasks were then broken up and assigned to the vendor(s) with the required expertise. The desired deliverable outcome was GitHub issues in the repositories under review, which is a shift from the standard \u201cassessment report\u201d provided by most security assessments in the space. You can view the issues here . To be very clear, we did not engage in this security assessment to get a stamp of approval from the security community. All of the effort put into creating this process and engaging the community was in the service of increasing the level of security and code quality of the Nimbus software.","title":"History"},{"location":"beacon-node-systemd.html","text":"Set up a systemd service This page will take you through how to set up a systemd service for your beacon node. systemd is used in order to have a command or a program run when your device boots (i.e. add it as a service). Once this is done, you can start/stop enable/disable from the linux prompt. systemd systemd is a service manager designed specifically for Linux: it cannot be used on Windows / Mac. You can find out more about systemd here . Package manager installations When installing Nimbus via your package manager , a user and service will already have been created for you and you can skip straight to the configuration section. 1. Create a dedicated user We will start by creating a dedicated user and data directory for Nimbus. The same user can also be used for the execution client. # Create the `nimbus` group sudo groupadd nimbus # Create the `nimbus` user in the `nimbus` group - we will use /var/lib/nimbus as data directory. sudo useradd -g nimbus nimbus -m -d /var/lib/nimbus 2. Create the service file systemd services are created by placing a service file in /etc/systemd/system , or, if Nimbus was installed by a package manager, /usr/lib/systemd/system . A good starting point is the example service file in the Nimbus repository. # Download example service file and save it to `/etc/systemd/system/nimbus_beacon_node.service` curl -s https://raw.githubusercontent.com/status-im/nimbus-eth2/stable/scripts/package_src/nimbus_beacon_node/image/lib/systemd/system/nimbus_beacon_node.service | sudo tee /etc/systemd/system/nimbus_beacon_node.service > /dev/null The format of service files is documented in the systemd manual . Tip Automatic restarts increase the risk that the doppelganger detection fails - set RestartPreventExitStatus=129 to prevent this from happening 3. Configure your service Services are configured either by editing the service file directly or using systemctl edit to create an override. # Edit the systemd file to match your installation sudo vi /etc/systemd/system/nimbus_beacon_node.service # If you installed nimbus via the package manager, use `systemctl edit` instead sudo systemctl edit nimbus_beacon_node.service The service file contains several options for controlling Nimbus. Important options include: Environment=NETWORK : set this to mainnet , holesky or sepolia , depending on which network you want to connect to Environment=WEB3_URL : point this to your execution client, see the Execution Client setup guide Environment=REST_ENABLED : REST is used to interact with the beacon node, in particular when setting up a separate Validator Client, see the REST API guide Environment=METRICS_ENABLED : metrics are used for monitoring the node, see the metrics setup guide ExecStart= : custom options, see the options guide Note The example assumes Nimbus was installed in /usr/bin/nimbus_beacon_node . If you installed Nimbus elsewhere, make sure to update this path. 4. Notify systemd of the newly added service Every time you add or update a service, the systemd daemon must be notified of the changes: sudo systemctl daemon-reload 4. Start the service # start the beacon node sudo systemctl start nimbus_beacon_node # (Optional) Set the beacon node to start automatically at boot sudo systemctl enable nimbus_beacon_node 5. Check the status of the service systemctl status will show if your beacon node is up and running, or has stopped for some reason. sudo systemctl status nimbus_beacon_node.service You can also follow the logs using the following command: sudo journalctl -uf nimbus_beacon_node.service This will show you the Nimbus logs at the default setting \u2014 it should include regular \"slot start\" messages which will show your sync progress . Press ctrl-c to stop following the logs. To rewind logs \u2014 by one day, say \u2014 run: sudo journalctl -u nimbus_beacon_node.service --since yesterday Import validator keys Before you start, familiarize yourself with the standard way of importing validators . Make sure you use the correct data directory . Look for the --data-dir option in the .service file. When using a service, the beacon node is running as a different user. Look for the User= option in the .service . Here we assume that the user is called nimbus . The key import must be performed as this user in order for the key files to have the correct permission: # Run import command as the `nimbus` user sudo -u nimbus /usr/bin/nimbus_beacon_node deposits import --data-dir=/var/lib/nimbus/shared_mainnet_0 /path/to/keys Note Make sure to use the same --data-dir option as is used in the service file! Some guides use --data-dir=/var/lib/nimbus instead. Running multiple beacon nodes You can run multiple beacon nodes on the same machine simply by copying the .service file and adjusting the parameters. When running multiple beacon nodes, make sure that each service: has its own .service file has its own --data-dir has its own --*-port settings Further examples A service template file by Pawel Bylica which allows you to start two services at the same time, e.g. nimbus@holesky.service and nimbus@mainnet.service . The EthereumOnARM project maintains a service file as part of their Ethereum installation package repository.","title":"Set up a systemd service"},{"location":"beacon-node-systemd.html#set-up-a-systemd-service","text":"This page will take you through how to set up a systemd service for your beacon node. systemd is used in order to have a command or a program run when your device boots (i.e. add it as a service). Once this is done, you can start/stop enable/disable from the linux prompt. systemd systemd is a service manager designed specifically for Linux: it cannot be used on Windows / Mac. You can find out more about systemd here . Package manager installations When installing Nimbus via your package manager , a user and service will already have been created for you and you can skip straight to the configuration section.","title":"Set up a systemd service"},{"location":"beacon-node-systemd.html#1-create-a-dedicated-user","text":"We will start by creating a dedicated user and data directory for Nimbus. The same user can also be used for the execution client. # Create the `nimbus` group sudo groupadd nimbus # Create the `nimbus` user in the `nimbus` group - we will use /var/lib/nimbus as data directory. sudo useradd -g nimbus nimbus -m -d /var/lib/nimbus","title":"1. Create a dedicated user"},{"location":"beacon-node-systemd.html#2-create-the-service-file","text":"systemd services are created by placing a service file in /etc/systemd/system , or, if Nimbus was installed by a package manager, /usr/lib/systemd/system . A good starting point is the example service file in the Nimbus repository. # Download example service file and save it to `/etc/systemd/system/nimbus_beacon_node.service` curl -s https://raw.githubusercontent.com/status-im/nimbus-eth2/stable/scripts/package_src/nimbus_beacon_node/image/lib/systemd/system/nimbus_beacon_node.service | sudo tee /etc/systemd/system/nimbus_beacon_node.service > /dev/null The format of service files is documented in the systemd manual . Tip Automatic restarts increase the risk that the doppelganger detection fails - set RestartPreventExitStatus=129 to prevent this from happening","title":"2. Create the service file"},{"location":"beacon-node-systemd.html#3-configure-your-service","text":"Services are configured either by editing the service file directly or using systemctl edit to create an override. # Edit the systemd file to match your installation sudo vi /etc/systemd/system/nimbus_beacon_node.service # If you installed nimbus via the package manager, use `systemctl edit` instead sudo systemctl edit nimbus_beacon_node.service The service file contains several options for controlling Nimbus. Important options include: Environment=NETWORK : set this to mainnet , holesky or sepolia , depending on which network you want to connect to Environment=WEB3_URL : point this to your execution client, see the Execution Client setup guide Environment=REST_ENABLED : REST is used to interact with the beacon node, in particular when setting up a separate Validator Client, see the REST API guide Environment=METRICS_ENABLED : metrics are used for monitoring the node, see the metrics setup guide ExecStart= : custom options, see the options guide Note The example assumes Nimbus was installed in /usr/bin/nimbus_beacon_node . If you installed Nimbus elsewhere, make sure to update this path.","title":"3. Configure your service"},{"location":"beacon-node-systemd.html#4-notify-systemd-of-the-newly-added-service","text":"Every time you add or update a service, the systemd daemon must be notified of the changes: sudo systemctl daemon-reload","title":"4. Notify systemd of the newly added service"},{"location":"beacon-node-systemd.html#4-start-the-service","text":"# start the beacon node sudo systemctl start nimbus_beacon_node # (Optional) Set the beacon node to start automatically at boot sudo systemctl enable nimbus_beacon_node","title":"4. Start the service"},{"location":"beacon-node-systemd.html#5-check-the-status-of-the-service","text":"systemctl status will show if your beacon node is up and running, or has stopped for some reason. sudo systemctl status nimbus_beacon_node.service You can also follow the logs using the following command: sudo journalctl -uf nimbus_beacon_node.service This will show you the Nimbus logs at the default setting \u2014 it should include regular \"slot start\" messages which will show your sync progress . Press ctrl-c to stop following the logs. To rewind logs \u2014 by one day, say \u2014 run: sudo journalctl -u nimbus_beacon_node.service --since yesterday","title":"5. Check the status of the service"},{"location":"beacon-node-systemd.html#import-validator-keys","text":"Before you start, familiarize yourself with the standard way of importing validators . Make sure you use the correct data directory . Look for the --data-dir option in the .service file. When using a service, the beacon node is running as a different user. Look for the User= option in the .service . Here we assume that the user is called nimbus . The key import must be performed as this user in order for the key files to have the correct permission: # Run import command as the `nimbus` user sudo -u nimbus /usr/bin/nimbus_beacon_node deposits import --data-dir=/var/lib/nimbus/shared_mainnet_0 /path/to/keys Note Make sure to use the same --data-dir option as is used in the service file! Some guides use --data-dir=/var/lib/nimbus instead.","title":"Import validator keys"},{"location":"beacon-node-systemd.html#running-multiple-beacon-nodes","text":"You can run multiple beacon nodes on the same machine simply by copying the .service file and adjusting the parameters. When running multiple beacon nodes, make sure that each service: has its own .service file has its own --data-dir has its own --*-port settings","title":"Running multiple beacon nodes"},{"location":"beacon-node-systemd.html#further-examples","text":"A service template file by Pawel Bylica which allows you to start two services at the same time, e.g. nimbus@holesky.service and nimbus@mainnet.service . The EthereumOnARM project maintains a service file as part of their Ethereum installation package repository.","title":"Further examples"},{"location":"binaries.html","text":"Binaries Binary releases are available from GitHub and our APT repository (Debian/Ubuntu). We currently have binaries available for Linux AMD64 , ARM and ARM64 , Windows AMD64 and macOS ( AMD64 and ARM64 ). Manual installation Debian / Ubuntu The latest release is always available from Github under the Assets header at the bottom of the page. To install or upgrade a binary release, unpack the archive appropriate for your operating system and architecture in a directory of your choice, and run the binary. # Create a directory that can hold the beacon chain data and applications - this should be a fast SSD mkdir -p nimbus-eth2 # Unpack the archive into the `nimbus-eth2` directory you just created tar xvf nimbus-eth2_Linux_amd64_22.6.1_2444e994.tar.gz --strip-components 1 -C nimbus-eth2 After unpacking, you may wish to verify the checksum . Install Nimbus from our APT repository : # Add the nimbus repository echo 'deb https://apt.status.im/nimbus all main' | sudo tee /etc/apt/sources.list.d/nimbus.list # Import the GPG key sudo curl https://apt.status.im/pubkey.asc -o /etc/apt/trusted.gpg.d/apt-status-im.asc # Update repository files and install Nimbus components sudo apt-get update sudo apt-get install nimbus-beacon-node nimbus-validator-client Helper scripts When installing via package manager, replace run-mainnet-beacon-node.sh and similar helper scripts used in this guide with nimbus_beacon_node : blockchain data will be written to the default data directory unless changed with --data-dir . systemd Packages include systemd service unit files: see the systemd guide for usage instructions. The nimbus user is created as part of the installation process! Reproducible builds We've designed the build process to be reproducible. In practice, this means that anyone can verify that these exact binaries were produced from the corresponding source code commits. For more about the philosophy and importance of this feature see reproducible-builds.org . For instructions on how to reproduce those binaries, see \"README.md\" inside the archive, as well as the in-depth guide .","title":"Binaries"},{"location":"binaries.html#binaries","text":"Binary releases are available from GitHub and our APT repository (Debian/Ubuntu). We currently have binaries available for Linux AMD64 , ARM and ARM64 , Windows AMD64 and macOS ( AMD64 and ARM64 ). Manual installation Debian / Ubuntu The latest release is always available from Github under the Assets header at the bottom of the page. To install or upgrade a binary release, unpack the archive appropriate for your operating system and architecture in a directory of your choice, and run the binary. # Create a directory that can hold the beacon chain data and applications - this should be a fast SSD mkdir -p nimbus-eth2 # Unpack the archive into the `nimbus-eth2` directory you just created tar xvf nimbus-eth2_Linux_amd64_22.6.1_2444e994.tar.gz --strip-components 1 -C nimbus-eth2 After unpacking, you may wish to verify the checksum . Install Nimbus from our APT repository : # Add the nimbus repository echo 'deb https://apt.status.im/nimbus all main' | sudo tee /etc/apt/sources.list.d/nimbus.list # Import the GPG key sudo curl https://apt.status.im/pubkey.asc -o /etc/apt/trusted.gpg.d/apt-status-im.asc # Update repository files and install Nimbus components sudo apt-get update sudo apt-get install nimbus-beacon-node nimbus-validator-client Helper scripts When installing via package manager, replace run-mainnet-beacon-node.sh and similar helper scripts used in this guide with nimbus_beacon_node : blockchain data will be written to the default data directory unless changed with --data-dir . systemd Packages include systemd service unit files: see the systemd guide for usage instructions. The nimbus user is created as part of the installation process!","title":"Binaries"},{"location":"binaries.html#reproducible-builds","text":"We've designed the build process to be reproducible. In practice, this means that anyone can verify that these exact binaries were produced from the corresponding source code commits. For more about the philosophy and importance of this feature see reproducible-builds.org . For instructions on how to reproduce those binaries, see \"README.md\" inside the archive, as well as the in-depth guide .","title":"Reproducible builds"},{"location":"build.html","text":"Build from source Building Nimbus from source ensures that all hardware-specific optimizations are turned on. The build process itself is simple and fully automated, but may take a few minutes. Nim Nimbus is written in the Nim programming language. The correct version will automatically be downloaded as part of the build process! Prerequisites Make sure you have all needed build prerequisites . Building the node 1. Clone the nimbus-eth2 repository git clone https://github.com/status-im/nimbus-eth2 cd nimbus-eth2 2. Run the beacon node build process To build the Nimbus beacon node and its dependencies, run: make -j4 nimbus_beacon_node Tip Omit -j4 on systems with 4GB of memory or less. This step can take several minutes. After it has finished, you can check if the installation was successful by running: build/nimbus_beacon_node --help If you see the command-line options, your installation was successful! Otherwise, don't hesitate to reach out to us in the #helpdesk channel of our discord . Keeping Nimbus updated When you decide to upgrade Nimbus to a newer version, make sure to follow the keeping updated guide .","title":"Build from source"},{"location":"build.html#build-from-source","text":"Building Nimbus from source ensures that all hardware-specific optimizations are turned on. The build process itself is simple and fully automated, but may take a few minutes. Nim Nimbus is written in the Nim programming language. The correct version will automatically be downloaded as part of the build process!","title":"Build from source"},{"location":"build.html#prerequisites","text":"Make sure you have all needed build prerequisites .","title":"Prerequisites"},{"location":"build.html#building-the-node","text":"","title":"Building the node"},{"location":"build.html#1-clone-the-nimbus-eth2-repository","text":"git clone https://github.com/status-im/nimbus-eth2 cd nimbus-eth2","title":"1. Clone the nimbus-eth2 repository"},{"location":"build.html#2-run-the-beacon-node-build-process","text":"To build the Nimbus beacon node and its dependencies, run: make -j4 nimbus_beacon_node Tip Omit -j4 on systems with 4GB of memory or less. This step can take several minutes. After it has finished, you can check if the installation was successful by running: build/nimbus_beacon_node --help If you see the command-line options, your installation was successful! Otherwise, don't hesitate to reach out to us in the #helpdesk channel of our discord .","title":"2. Run the beacon node build process"},{"location":"build.html#keeping-nimbus-updated","text":"When you decide to upgrade Nimbus to a newer version, make sure to follow the keeping updated guide .","title":"Keeping Nimbus updated"},{"location":"checksums.html","text":"Checksums Checksums for each build are included in the release notes . Please make sure you get into the habit of verifying these \ud83d\ude4f For those of you who are unfamiliar, a checksum is a special type of hash used to verify the integrity of a file. Verifying a checksum ensures there was no corruption or manipulation during the download and that the file was downloaded completely and correctly. For a short and simple guide on how to do so, see here . In the case of the v23.11.0 release for example, the SHA512 checksums are: # Linux AMD64 1f53f58373fa3540028ff17f2a46254f4d9236f844a01fb548359e3241bd9e9791abc3637b474b4e834a08c36d259b84032db01975944d5eb92aef4fbab14821 nimbus_beacon_node efd1d5f0261b30cfb7e81c3e19ae5f2e2828a1af37a6f85c3151545a1725c68003d7331390ab4b24ac583cf62ccae448755b607c4717a7ec660bb95b4981d9a3 nimbus_validator_client # Linux ARM64 27a2572216afead921a3c59ab1582ba3b0a06a53c753ac46a3aee4afe0122d01e2ddc4436b2518993369db06e3eff5fab88c1613dd79f1668b55be15b77802aa nimbus_beacon_node 4affb3c9fb1c3fa83f99e6f806967db2a5fb1b474a4613ab4747d73fe6c0ed2e54391b6b8495cf438d50ee3b41ee46b824e4128bb4a9606e612a18bc0908998b nimbus_validator_client # Linux ARM 83b5a99eb3bc98ebfa0a6c0c609c837e3e582e03a1728487dcdcfdca937d3185c6b4ca71ca2eb835b47840ff87b965286a2266ec876f1e0cff66d71e9d87d059 nimbus_beacon_node 9a13849a1c72ca30adf54c87abaa603f1028b82f6eec5d0f4baca0e914ae422e86b42e8b9688f8031488032aa71d8819e0ccdea76d5f43bfd02d233dced8536a nimbus_validator_client # Windows AMD64 625ac9fabc65679f484c0988ceb664c51c5e3749ac84ad90426d8029ba49590585f377f0fdeba92ff7330a43335f9068c03c09f628a44053a6c42e202b06a699 nimbus_beacon_node.exe 78aa38439e6e6dbec7c68c33ce4e316bc06da9983409828ea61aa014d794bea968b482c954d38055f4ca36f12e8b5287d3afaa78b2c3650cb535ab1a127f30cb nimbus_validator_client.exe # macOS AMD64 9f6d4b66cc9ee5334c1675e748c0bc99a1fae55a15ed5ac4db3d6ef287bc2ebaccda85984f613991d35f7c86c87c857281ab80aace02abaf1e94828a2690085a nimbus_beacon_node df7b676f451cd9bb05c6f55c2a1eaf5f166fdc7592e1f2b6d54c81f4c0234b6788d936a872d38dd922bd6bdd54e5276bc6d032d83540e76fb93ba65fee765a21 nimbus_validator_client # macOS ARM64 1a8efc60b0cdedf0f931ba15509393c268285cd8f1fe3f21f123f241c83fa79befd5bd7aaae99a43ed6a87f69a9a1a8bcef37f1b9ca2c488cbaa124725111fbd nimbus_beacon_node 96dd77e672aac8d92d6339b89891260d35d18d5938ae97f1126eb3f8fc86e25fafb506caf1f900479a17c762f76ad71b57bafb49d848627d2244d16075b45ee5 nimbus_validator_client","title":"Checksums"},{"location":"checksums.html#checksums","text":"Checksums for each build are included in the release notes . Please make sure you get into the habit of verifying these \ud83d\ude4f For those of you who are unfamiliar, a checksum is a special type of hash used to verify the integrity of a file. Verifying a checksum ensures there was no corruption or manipulation during the download and that the file was downloaded completely and correctly. For a short and simple guide on how to do so, see here . In the case of the v23.11.0 release for example, the SHA512 checksums are: # Linux AMD64 1f53f58373fa3540028ff17f2a46254f4d9236f844a01fb548359e3241bd9e9791abc3637b474b4e834a08c36d259b84032db01975944d5eb92aef4fbab14821 nimbus_beacon_node efd1d5f0261b30cfb7e81c3e19ae5f2e2828a1af37a6f85c3151545a1725c68003d7331390ab4b24ac583cf62ccae448755b607c4717a7ec660bb95b4981d9a3 nimbus_validator_client # Linux ARM64 27a2572216afead921a3c59ab1582ba3b0a06a53c753ac46a3aee4afe0122d01e2ddc4436b2518993369db06e3eff5fab88c1613dd79f1668b55be15b77802aa nimbus_beacon_node 4affb3c9fb1c3fa83f99e6f806967db2a5fb1b474a4613ab4747d73fe6c0ed2e54391b6b8495cf438d50ee3b41ee46b824e4128bb4a9606e612a18bc0908998b nimbus_validator_client # Linux ARM 83b5a99eb3bc98ebfa0a6c0c609c837e3e582e03a1728487dcdcfdca937d3185c6b4ca71ca2eb835b47840ff87b965286a2266ec876f1e0cff66d71e9d87d059 nimbus_beacon_node 9a13849a1c72ca30adf54c87abaa603f1028b82f6eec5d0f4baca0e914ae422e86b42e8b9688f8031488032aa71d8819e0ccdea76d5f43bfd02d233dced8536a nimbus_validator_client # Windows AMD64 625ac9fabc65679f484c0988ceb664c51c5e3749ac84ad90426d8029ba49590585f377f0fdeba92ff7330a43335f9068c03c09f628a44053a6c42e202b06a699 nimbus_beacon_node.exe 78aa38439e6e6dbec7c68c33ce4e316bc06da9983409828ea61aa014d794bea968b482c954d38055f4ca36f12e8b5287d3afaa78b2c3650cb535ab1a127f30cb nimbus_validator_client.exe # macOS AMD64 9f6d4b66cc9ee5334c1675e748c0bc99a1fae55a15ed5ac4db3d6ef287bc2ebaccda85984f613991d35f7c86c87c857281ab80aace02abaf1e94828a2690085a nimbus_beacon_node df7b676f451cd9bb05c6f55c2a1eaf5f166fdc7592e1f2b6d54c81f4c0234b6788d936a872d38dd922bd6bdd54e5276bc6d032d83540e76fb93ba65fee765a21 nimbus_validator_client # macOS ARM64 1a8efc60b0cdedf0f931ba15509393c268285cd8f1fe3f21f123f241c83fa79befd5bd7aaae99a43ed6a87f69a9a1a8bcef37f1b9ca2c488cbaa124725111fbd nimbus_beacon_node 96dd77e672aac8d92d6339b89891260d35d18d5938ae97f1126eb3f8fc86e25fafb506caf1f900479a17c762f76ad71b57bafb49d848627d2244d16075b45ee5 nimbus_validator_client","title":"Checksums"},{"location":"connect-eth2.html","text":"This page has been removed. Follow our validating guide .","title":"Connect eth2"},{"location":"contribute.html","text":"Updating this guide We use Material for MkDocs to produce our documentation. Before You Start Clone the repository by git clone https://github.com/status-im/nimbus-eth2.git . Go to the docs folder and type make to install mkdocs Activate mkdocs: . mkdocs/bin/activate Go to where the Markdown files are located by cd the_nimbus_book/ . Real-Time Update and Preview Changes Run mkdocs serve in the terminal. Preview the book at http://localhost:8000 . Build and Deploy The first step is to submit a pull request to the unstable branch . Then, after it is merged, do the following under our main repository: cd nimbus-eth2 git checkout unstable git pull make update # (This is to update the submodules to the latest version) make publish-book Troubleshooting If you see file conflicts in the pull request, this may due to that you have created your new branch from an old version of the unstable branch. Update your new branch using the following commands: git checkout unstable git pull make update git checkout readme git merge unstable # use something like \"git mergetool\" to resolve conflicts, then read the instructions for completing the merge (usually just a `git commit`) # check the output of \"git diff unstable\" Thank you so much for your help to the decentralized and open source community. :)","title":"Updating this guide"},{"location":"contribute.html#updating-this-guide","text":"We use Material for MkDocs to produce our documentation.","title":"Updating this guide"},{"location":"contribute.html#before-you-start","text":"Clone the repository by git clone https://github.com/status-im/nimbus-eth2.git . Go to the docs folder and type make to install mkdocs Activate mkdocs: . mkdocs/bin/activate Go to where the Markdown files are located by cd the_nimbus_book/ .","title":"Before You Start"},{"location":"contribute.html#real-time-update-and-preview-changes","text":"Run mkdocs serve in the terminal. Preview the book at http://localhost:8000 .","title":"Real-Time Update and Preview Changes"},{"location":"contribute.html#build-and-deploy","text":"The first step is to submit a pull request to the unstable branch . Then, after it is merged, do the following under our main repository: cd nimbus-eth2 git checkout unstable git pull make update # (This is to update the submodules to the latest version) make publish-book","title":"Build and Deploy"},{"location":"contribute.html#troubleshooting","text":"If you see file conflicts in the pull request, this may due to that you have created your new branch from an old version of the unstable branch. Update your new branch using the following commands: git checkout unstable git pull make update git checkout readme git merge unstable # use something like \"git mergetool\" to resolve conflicts, then read the instructions for completing the merge (usually just a `git commit`) # check the output of \"git diff unstable\" Thank you so much for your help to the decentralized and open source community. :)","title":"Troubleshooting"},{"location":"data-dir.html","text":"The data directory Nimbus stores all the information it needs to run in a data directory. In this directory, you'll find a database, your validator keys and secrets, and several other items. When following the installation guide, the chain data will be stored in build/data with separate directories for each chain (mainnet, holesky, etc). The --data-dir option The --data-dir=/path/to/data allows picking a specific data directory to store the chain. Make sure you use the same --data-dir option for all beacon node commands! Contents Inside the data directory, you'll find several subdirectories and files containing various information about the node, chain and validators. You can examine the contents of the data directory using the ls -l command: cd nimbus-eth2 ls -l build/data/shared_mainnet_0 -rw-r--r-- 1 nimbus nimbus 234 Jul 19 18 :18 beacon_node.enr drwx------ 1 nimbus nimbus 22 Jul 19 18 :18 db drwx------ 1 nimbus nimbus 196 Jul 19 17 :36 secrets drwx------ 1 nimbus nimbus 250 Jul 19 18 :18 validators db The db folder contains historical chain data and information about the latest observed state of the chain. If you remove the db folder, the beacon node will have to resync. The growth of the database depends on the history mode . secrets and validators These two folders contain your validator keys, as well as the passwords needed to unlock them when starting the beacon node. By default, the folders are nested directly under the selected data directory, but you can alter the location through the options --validators-dir and --secrets-dir . Warning Be careful not to copy the secrets and validator folders, leaving them in two locations! Instead, always move them to the new location. Using the same validators with two nodes poses a significant slashing risk! For each imported validator, the validators directory includes a sub-folder named after the 0x-prefixed hex-encoded public key of the validator. The per-validator directory contains either a local keystore file with the name keystore.json or remote keystore file with the name remote_keystore.json . It may also contain the following additional configuration files: suggested_fee_recipient.hex - a hex-encoded execution layer address that will receive the transaction fees from blocks produced by the particular validator. suggested_gas_limit.json - the suggested gas limit of the blocks produced by the particular validator. For each imported validator with a local keystore, the secrets directory includes a file named after the 0x-prefixed hex-encoded public key of the validator. The contents of the file will be used as the password for unlocking the keystore. If a password file for a particular validator is missing, Nimbus obtains the password interactively from the user on start-up. If the --non-interactive option is specified, Nimbus considers a missing password file to be a fatal error and it will terminate with a non-zero exit code. Moving the data directory You can move the data directory to another location or computer simply by moving its contents and updating the --data-dir option when starting the node. Permissions To protect against key loss, Nimbus requires that files and directories be owned by the user running the application. Furthermore, they should not be readable by others. It may happen that the wrong permissions are applied, particularly when creating the directories manually. The following errors are a sign of this: Data folder has insecure ACL Data directory has insecure permissions File has insecure permissions Here is how to fix them. Linux / BSD / MacOS Windows Run: # Changing ownership to `user:group` for all files/directories in <data-dir>. chown user:group -R <data-dir> # Set permissions to (rwx------ 0700) for all directories starting from <data-dir> find <data-dir> -type d -exec chmod 700 {} \\; # Set permissions to (rw------- 0600) for all files inside <data-dir>/validators find <data-dir>/validators -type f -exec chmod 0600 {} \\; # Set permissions to (rw------- 0600) for all files inside <data-dir>/secrets find <data-dir>/secrets -type f -exec chmod 0600 {} \\; In sum: Directories <data-dir> , <data-dir>/validators , <data-dir>/secrets must be owned by user and have rwx------ or 0700 permissions set. Files stored inside <data-dir> , <data-dir>/validators , /secrets must be owned by user and have rw------ or 0600 permission set. From inside Git Bash , run: # Set permissions for all the directories starting from <data-dir> find <data-dir> -type d -exec icacls {} /inheritance:r /grant:r $USERDOMAIN \\\\ $USERNAME : \\( OI \\)\\( CI \\)\\( F \\) \\; # Set permissions for all the files inside <data-dir>/validators find <data-dir>/validators -type f -exec icacls {} /inheritance:r /grant:r $USERDOMAIN \\\\ $USERNAME : \\( F \\) \\; # Set permissions for all the files inside <data-dir>/secrets find <data-dir>/secrets -type f -exec icacls {} /inheritance:r /grant:r $USERDOMAIN \\\\ $USERNAME : \\( F \\) \\; Note Make sure you run the above from inside Git Bash , these commands will not work from inside the standard Windows Command Prompt. If you don't already have a Git Bash shell, you'll need to install Git for Windows . In sum: Directories <data-dir> , <data-dir>/validators , <data-dir>/secrets must be owned by user and have permissions set for the user only (OI)(CI)(F). All inherited permissions should be removed. Files which are stored inside , /validators, /secrets must be owned by user and have permissions set for the user only (F). All inherited permissions should be removed.","title":"The data directory"},{"location":"data-dir.html#the-data-directory","text":"Nimbus stores all the information it needs to run in a data directory. In this directory, you'll find a database, your validator keys and secrets, and several other items. When following the installation guide, the chain data will be stored in build/data with separate directories for each chain (mainnet, holesky, etc). The --data-dir option The --data-dir=/path/to/data allows picking a specific data directory to store the chain. Make sure you use the same --data-dir option for all beacon node commands!","title":"The data directory"},{"location":"data-dir.html#contents","text":"Inside the data directory, you'll find several subdirectories and files containing various information about the node, chain and validators. You can examine the contents of the data directory using the ls -l command: cd nimbus-eth2 ls -l build/data/shared_mainnet_0 -rw-r--r-- 1 nimbus nimbus 234 Jul 19 18 :18 beacon_node.enr drwx------ 1 nimbus nimbus 22 Jul 19 18 :18 db drwx------ 1 nimbus nimbus 196 Jul 19 17 :36 secrets drwx------ 1 nimbus nimbus 250 Jul 19 18 :18 validators","title":"Contents"},{"location":"data-dir.html#db","text":"The db folder contains historical chain data and information about the latest observed state of the chain. If you remove the db folder, the beacon node will have to resync. The growth of the database depends on the history mode .","title":"db"},{"location":"data-dir.html#secrets-and-validators","text":"These two folders contain your validator keys, as well as the passwords needed to unlock them when starting the beacon node. By default, the folders are nested directly under the selected data directory, but you can alter the location through the options --validators-dir and --secrets-dir . Warning Be careful not to copy the secrets and validator folders, leaving them in two locations! Instead, always move them to the new location. Using the same validators with two nodes poses a significant slashing risk! For each imported validator, the validators directory includes a sub-folder named after the 0x-prefixed hex-encoded public key of the validator. The per-validator directory contains either a local keystore file with the name keystore.json or remote keystore file with the name remote_keystore.json . It may also contain the following additional configuration files: suggested_fee_recipient.hex - a hex-encoded execution layer address that will receive the transaction fees from blocks produced by the particular validator. suggested_gas_limit.json - the suggested gas limit of the blocks produced by the particular validator. For each imported validator with a local keystore, the secrets directory includes a file named after the 0x-prefixed hex-encoded public key of the validator. The contents of the file will be used as the password for unlocking the keystore. If a password file for a particular validator is missing, Nimbus obtains the password interactively from the user on start-up. If the --non-interactive option is specified, Nimbus considers a missing password file to be a fatal error and it will terminate with a non-zero exit code.","title":"secrets and validators"},{"location":"data-dir.html#moving-the-data-directory","text":"You can move the data directory to another location or computer simply by moving its contents and updating the --data-dir option when starting the node.","title":"Moving the data directory"},{"location":"data-dir.html#permissions","text":"To protect against key loss, Nimbus requires that files and directories be owned by the user running the application. Furthermore, they should not be readable by others. It may happen that the wrong permissions are applied, particularly when creating the directories manually. The following errors are a sign of this: Data folder has insecure ACL Data directory has insecure permissions File has insecure permissions Here is how to fix them. Linux / BSD / MacOS Windows Run: # Changing ownership to `user:group` for all files/directories in <data-dir>. chown user:group -R <data-dir> # Set permissions to (rwx------ 0700) for all directories starting from <data-dir> find <data-dir> -type d -exec chmod 700 {} \\; # Set permissions to (rw------- 0600) for all files inside <data-dir>/validators find <data-dir>/validators -type f -exec chmod 0600 {} \\; # Set permissions to (rw------- 0600) for all files inside <data-dir>/secrets find <data-dir>/secrets -type f -exec chmod 0600 {} \\; In sum: Directories <data-dir> , <data-dir>/validators , <data-dir>/secrets must be owned by user and have rwx------ or 0700 permissions set. Files stored inside <data-dir> , <data-dir>/validators , /secrets must be owned by user and have rw------ or 0600 permission set. From inside Git Bash , run: # Set permissions for all the directories starting from <data-dir> find <data-dir> -type d -exec icacls {} /inheritance:r /grant:r $USERDOMAIN \\\\ $USERNAME : \\( OI \\)\\( CI \\)\\( F \\) \\; # Set permissions for all the files inside <data-dir>/validators find <data-dir>/validators -type f -exec icacls {} /inheritance:r /grant:r $USERDOMAIN \\\\ $USERNAME : \\( F \\) \\; # Set permissions for all the files inside <data-dir>/secrets find <data-dir>/secrets -type f -exec icacls {} /inheritance:r /grant:r $USERDOMAIN \\\\ $USERNAME : \\( F \\) \\; Note Make sure you run the above from inside Git Bash , these commands will not work from inside the standard Windows Command Prompt. If you don't already have a Git Bash shell, you'll need to install Git for Windows . In sum: Directories <data-dir> , <data-dir>/validators , <data-dir>/secrets must be owned by user and have permissions set for the user only (OI)(CI)(F). All inherited permissions should be removed. Files which are stored inside , /validators, /secrets must be owned by user and have permissions set for the user only (F). All inherited permissions should be removed.","title":"Permissions"},{"location":"database-backup.html","text":"Back up your database The best way to do this is to use .backup sqlite command: Navigate to either build/data/shared_mainnet_0/db/ (if you're running Holesky: shared_holesky_0 ) or the directory you supplied to the --data-dir argument when you launched Nimbus. Run the following command: sqlite3 nbc.sqlite3 \".backup 'backup_nbc.sqlite3'\" Make sure to correctly type both single and double quotes, as written above.","title":"Back up your database"},{"location":"database-backup.html#back-up-your-database","text":"The best way to do this is to use .backup sqlite command: Navigate to either build/data/shared_mainnet_0/db/ (if you're running Holesky: shared_holesky_0 ) or the directory you supplied to the --data-dir argument when you launched Nimbus. Run the following command: sqlite3 nbc.sqlite3 \".backup 'backup_nbc.sqlite3'\" Make sure to correctly type both single and double quotes, as written above.","title":"Back up your database"},{"location":"deposit.html","text":"This page has been removed. Follow our validating guide .","title":"Deposit"},{"location":"developers.html","text":"For Developers This page contains tips and tricks for developers, further resources, along with information on how to set up your build environment on your platform. Before building Nimbus for the first time, make sure to install the prerequisites . Helpful resources Ethereum consensus spec Ben Edgington's annotated spec Vitalik's annotated spec Nim programming language Nimbus is built in the Nim language . The compiler is automatically installed when building the project for the first time. More information \u2014 in particular security-related information about the language \u2014 can be found in the Auditor Handbook . Code style The code follows the Status Nim Style Guide . Branch lifecycle The git repository has 3 main branches, stable , testing and unstable as well as feature and bugfix branches. Unstable The unstable branch contains features and bugfixes that are actively being tested and worked on. Features and bugfixes are generally pushed to individual branches, each with their own pull request against the unstable branch. Once the branch has been reviewed and passed CI, the developer or reviewer merges the branch to unstable . The unstable branch is regularly deployed to the Nimbus Prater fleet where additional testing happens. Testing The testing branch contains features and bugfixes that have gone through CI and initial testing on the unstable branch and are ready to be included in the next release. After testing a bugfix or feature on unstable , the features and fixes that are planned for the next release get merged to the testing branch either by the release manager or team members. The testing branch is regularly deployed to the Nimbus prater fleet as well as a smaller mainnet fleet. The branch should remain release-ready at most times. Stable The stable branch tracks the latest released version of Nimbus and is suitable for mainnet staking. Build system Windows mingw32-make # this first invocation will update the Git submodules You can now follow the instructions in this this book by replacing make with mingw32-make (you should run mingw32 regardless of whether you're running 32-bit or 64-bit architecture): mingw32-make test # run the test suite Linux, macOS After cloning the repo: # Build nimbus_beacon_node and all the tools, using 4 parallel Make jobs make -j4 # Run tests make test # Update to latest version git pull make update Environment Nimbus comes with a build environment similar to Python venv. This helps ensure that the correct version of Nim is used and that all dependencies can be found. ./env.sh bash # start a new interactive shell with the right env vars set which nim nim --version # Nimbus is tested and supported on 1.2.12 at the moment # or without starting a new interactive shell: ./env.sh which nim ./env.sh nim --version # Start Visual Studio code with environment ./env.sh code Makefile tips and tricks for developers build all those tools known to the Makefile: # $(nproc) corresponds to the number of cores you have make -j $( nproc ) build a specific tool: make block_sim you can control the Makefile's verbosity with the V variable (defaults to 0): make V = 1 # verbose make V = 2 test # even more verbose same for the Chronicles log level : make LOG_LEVEL = DEBUG bench_bls_sig_aggregation # this is the default make LOG_LEVEL = TRACE nimbus_beacon_node # log everything pass arbitrary parameters to the Nim compiler: make NIMFLAGS = \"-d:release\" you can freely combine those variables on the make command line: make -j $( nproc ) NIMFLAGS = \"-d:release\" USE_MULTITAIL = yes local-testnet-minimal don't use the lightweight stack tracing implementation from nim-libbacktrace : make USE_LIBBACKTRACE = 0 # expect the resulting binaries to be 2-3 times slower disable -march=native because you want to run the binary on a different machine than the one you're building it on: make NIMFLAGS = \"-d:disableMarchNative\" nimbus_beacon_node disable link-time optimization (LTO): make NIMFLAGS = \"-d:disableLTO\" nimbus_beacon_node show C compiler warnings: make NIMFLAGS = \"-d:cwarnings\" nimbus_beacon_node limit stack usage to 1 MiB per C function (static analysis - see the GCC docs ; if LTO is enabled, it works without -d:cwarnings ): make NIMFLAGS = \"-d:limitStackUsage\" nimbus_beacon_node build a static binary: make NIMFLAGS = \"--passL:-static\" nimbus_beacon_node publish a book using mdBook from sources in \"docs/\" to GitHub pages: make publish-book create a binary distribution: make dist Multi-client interop scripts This repository contains a set of scripts used by the client implementation teams to test interop between the clients (in certain simplified scenarios). It mostly helps us find and debug issues. Stress-testing the client by limiting the CPU power make prater CPU_LIMIT = 20 The limiting is provided by the cpulimit utility, available on Linux and macOS. The specified value is a percentage of a single CPU core. Usually 1 - 100, but can be higher on multi-core CPUs. Build and run the local beacon chain simulation The beacon chain simulation runs several beacon nodes on the local machine, attaches several local validators to each, and builds a beacon chain between them. To run the simulation: make update make local-testnet-minimal To clean the previous run's data: make clean_eth2_network_simulation_all To change the number of validators and nodes: # Clear data files from your last run and start the simulation with a new genesis block: make VALIDATORS = 192 NODES = 6 USER_NODES = 1 local-testnet-minimal If you\u2019d like to see the nodes running on separated sub-terminals inside one big window, install Multitail (if you're on a Mac, follow the instructions here ), then: USE_MULTITAIL=\"yes\" make local-testnet-minimal You\u2019ll get something like this (click for full size): You can find out more about the beacon node simulation here . Build and run the local state transition simulation This simulation is primarily designed for researchers, but we'll cover it briefly here in case you're curious :) The state transition simulation quickly runs the beacon chain state transition function in isolation and outputs JSON snapshots of the state (directly to the nimbus-eth2 directory). It runs without networking and blocks are processed without slot time delays. # build the state simulator, then display its help (\"-d:release\" speeds it # up substantially, allowing the simulation of longer runs in reasonable time) make NIMFLAGS = \"-d:release\" block_sim build/block_sim --help Use the output of the help command to pass desired values to the simulator. Experiment with changing the number of slots, validators, etc. to get different results. The most important options are: slots : the number of slots to run the simulation for (default 192) validators : the number of validators (default 6400) attesterRatio : the expected fraction of attesters that actually do their work for every slot (default 0.73) For example, to run the block simulator for 384 slots, with 20,000 validators, and an average of 66% of attesters doing their work every slot, run: build/block_sim --slots=384 --validators=20000 --attesterRatio=0.66 Sync from a specific peer build/nimbus_beacon_node --no-el --discv5:off --tcp-port = 9876 --direct-peer = \"/ip4/127.0.0.1/tcp/9000/p2p/ $( curl -s -X 'GET' 'http://localhost:5052/eth/v1/node/identity' -H 'accept: application/json' | jq -r .data.peer_id ) \"","title":"For Developers"},{"location":"developers.html#for-developers","text":"This page contains tips and tricks for developers, further resources, along with information on how to set up your build environment on your platform. Before building Nimbus for the first time, make sure to install the prerequisites .","title":"For Developers"},{"location":"developers.html#helpful-resources","text":"Ethereum consensus spec Ben Edgington's annotated spec Vitalik's annotated spec","title":"Helpful resources"},{"location":"developers.html#nim-programming-language","text":"Nimbus is built in the Nim language . The compiler is automatically installed when building the project for the first time. More information \u2014 in particular security-related information about the language \u2014 can be found in the Auditor Handbook .","title":"Nim programming language"},{"location":"developers.html#code-style","text":"The code follows the Status Nim Style Guide .","title":"Code style"},{"location":"developers.html#branch-lifecycle","text":"The git repository has 3 main branches, stable , testing and unstable as well as feature and bugfix branches.","title":"Branch lifecycle"},{"location":"developers.html#unstable","text":"The unstable branch contains features and bugfixes that are actively being tested and worked on. Features and bugfixes are generally pushed to individual branches, each with their own pull request against the unstable branch. Once the branch has been reviewed and passed CI, the developer or reviewer merges the branch to unstable . The unstable branch is regularly deployed to the Nimbus Prater fleet where additional testing happens.","title":"Unstable"},{"location":"developers.html#testing","text":"The testing branch contains features and bugfixes that have gone through CI and initial testing on the unstable branch and are ready to be included in the next release. After testing a bugfix or feature on unstable , the features and fixes that are planned for the next release get merged to the testing branch either by the release manager or team members. The testing branch is regularly deployed to the Nimbus prater fleet as well as a smaller mainnet fleet. The branch should remain release-ready at most times.","title":"Testing"},{"location":"developers.html#stable","text":"The stable branch tracks the latest released version of Nimbus and is suitable for mainnet staking.","title":"Stable"},{"location":"developers.html#build-system","text":"","title":"Build system"},{"location":"developers.html#windows","text":"mingw32-make # this first invocation will update the Git submodules You can now follow the instructions in this this book by replacing make with mingw32-make (you should run mingw32 regardless of whether you're running 32-bit or 64-bit architecture): mingw32-make test # run the test suite","title":"Windows"},{"location":"developers.html#linux-macos","text":"After cloning the repo: # Build nimbus_beacon_node and all the tools, using 4 parallel Make jobs make -j4 # Run tests make test # Update to latest version git pull make update","title":"Linux, macOS"},{"location":"developers.html#environment","text":"Nimbus comes with a build environment similar to Python venv. This helps ensure that the correct version of Nim is used and that all dependencies can be found. ./env.sh bash # start a new interactive shell with the right env vars set which nim nim --version # Nimbus is tested and supported on 1.2.12 at the moment # or without starting a new interactive shell: ./env.sh which nim ./env.sh nim --version # Start Visual Studio code with environment ./env.sh code","title":"Environment"},{"location":"developers.html#makefile-tips-and-tricks-for-developers","text":"build all those tools known to the Makefile: # $(nproc) corresponds to the number of cores you have make -j $( nproc ) build a specific tool: make block_sim you can control the Makefile's verbosity with the V variable (defaults to 0): make V = 1 # verbose make V = 2 test # even more verbose same for the Chronicles log level : make LOG_LEVEL = DEBUG bench_bls_sig_aggregation # this is the default make LOG_LEVEL = TRACE nimbus_beacon_node # log everything pass arbitrary parameters to the Nim compiler: make NIMFLAGS = \"-d:release\" you can freely combine those variables on the make command line: make -j $( nproc ) NIMFLAGS = \"-d:release\" USE_MULTITAIL = yes local-testnet-minimal don't use the lightweight stack tracing implementation from nim-libbacktrace : make USE_LIBBACKTRACE = 0 # expect the resulting binaries to be 2-3 times slower disable -march=native because you want to run the binary on a different machine than the one you're building it on: make NIMFLAGS = \"-d:disableMarchNative\" nimbus_beacon_node disable link-time optimization (LTO): make NIMFLAGS = \"-d:disableLTO\" nimbus_beacon_node show C compiler warnings: make NIMFLAGS = \"-d:cwarnings\" nimbus_beacon_node limit stack usage to 1 MiB per C function (static analysis - see the GCC docs ; if LTO is enabled, it works without -d:cwarnings ): make NIMFLAGS = \"-d:limitStackUsage\" nimbus_beacon_node build a static binary: make NIMFLAGS = \"--passL:-static\" nimbus_beacon_node publish a book using mdBook from sources in \"docs/\" to GitHub pages: make publish-book create a binary distribution: make dist","title":"Makefile tips and tricks for developers"},{"location":"developers.html#multi-client-interop-scripts","text":"This repository contains a set of scripts used by the client implementation teams to test interop between the clients (in certain simplified scenarios). It mostly helps us find and debug issues.","title":"Multi-client interop scripts"},{"location":"developers.html#stress-testing-the-client-by-limiting-the-cpu-power","text":"make prater CPU_LIMIT = 20 The limiting is provided by the cpulimit utility, available on Linux and macOS. The specified value is a percentage of a single CPU core. Usually 1 - 100, but can be higher on multi-core CPUs.","title":"Stress-testing the client by limiting the CPU power"},{"location":"developers.html#build-and-run-the-local-beacon-chain-simulation","text":"The beacon chain simulation runs several beacon nodes on the local machine, attaches several local validators to each, and builds a beacon chain between them. To run the simulation: make update make local-testnet-minimal To clean the previous run's data: make clean_eth2_network_simulation_all To change the number of validators and nodes: # Clear data files from your last run and start the simulation with a new genesis block: make VALIDATORS = 192 NODES = 6 USER_NODES = 1 local-testnet-minimal If you\u2019d like to see the nodes running on separated sub-terminals inside one big window, install Multitail (if you're on a Mac, follow the instructions here ), then: USE_MULTITAIL=\"yes\" make local-testnet-minimal You\u2019ll get something like this (click for full size): You can find out more about the beacon node simulation here .","title":"Build and run the local beacon chain simulation"},{"location":"developers.html#build-and-run-the-local-state-transition-simulation","text":"This simulation is primarily designed for researchers, but we'll cover it briefly here in case you're curious :) The state transition simulation quickly runs the beacon chain state transition function in isolation and outputs JSON snapshots of the state (directly to the nimbus-eth2 directory). It runs without networking and blocks are processed without slot time delays. # build the state simulator, then display its help (\"-d:release\" speeds it # up substantially, allowing the simulation of longer runs in reasonable time) make NIMFLAGS = \"-d:release\" block_sim build/block_sim --help Use the output of the help command to pass desired values to the simulator. Experiment with changing the number of slots, validators, etc. to get different results. The most important options are: slots : the number of slots to run the simulation for (default 192) validators : the number of validators (default 6400) attesterRatio : the expected fraction of attesters that actually do their work for every slot (default 0.73) For example, to run the block simulator for 384 slots, with 20,000 validators, and an average of 66% of attesters doing their work every slot, run: build/block_sim --slots=384 --validators=20000 --attesterRatio=0.66","title":"Build and run the local state transition simulation"},{"location":"developers.html#sync-from-a-specific-peer","text":"build/nimbus_beacon_node --no-el --discv5:off --tcp-port = 9876 --direct-peer = \"/ip4/127.0.0.1/tcp/9000/p2p/ $( curl -s -X 'GET' 'http://localhost:5052/eth/v1/node/identity' -H 'accept: application/json' | jq -r .data.peer_id ) \"","title":"Sync from a specific peer"},{"location":"distribution_internals.html","text":"Binary distribution internals Reproducibility The binaries we build in GitHub Actions and distribute in our releases come from an intricate process meant to ensure reproducibility . While the ability to produce the same exact binaries from the corresponding Git commits is a good idea for any open source project, it is a requirement for software that deals with digital tokens of significant value. Docker containers for internal use The easiest way to guarantee that users are able to replicate our binaries for themselves is to give them the same software environment we used in CI. Docker containers fit the bill, so everything starts with the architecture- and OS-specific containers in docker/dist/base_image/ . These images contain all the packages we need, are built and published once (to Docker Hub), and are then reused as the basis for temporary Docker images where the nimbus-eth2 build is carried out. These temporary images are controlled by Dockerfiles in docker/dist/ . Since we're not publishing them anywhere, we can customize them to the system they run on (we ensure they use the host's UID/GID, the host's QEMU static binaries, etc); they get access to the source code through the use of external volumes. Build process It all starts from the GitHub actions in .github/workflows/release.yml . There is a different job for each supported OS-architecture combination and they all run in parallel (ideally). Once all those CI jobs are completed successfully, a GitHub release draft is created and all the distributable archives are uploaded to it. A list of checksums for the main binaries is inserted in the release description. That draft needs to be manually published. The build itself is triggered by a Make target, e.g. make dist-amd64 . This invokes scripts/make_dist.sh which builds the corresponding Docker container from docker/dist/ and runs it with the Git repository's top directory as an external volume. The entry point for that container is docker/dist/entry_point.sh and that's where you'll find the Make invocations needed to finally build the software and create distributable tarballs. Docker images for end users Configured in .github/workflows/release.yml (only for Linux AMD64, ARM and ARM64), we unpack the distribution tarball and copy its content into a third type of Docker image \u2014 meant for end users and defined by docker/dist/binaries/Dockerfile.amd64 (and related). We then publish that to Docker Hub .","title":"Binary distribution internals"},{"location":"distribution_internals.html#binary-distribution-internals","text":"","title":"Binary distribution internals"},{"location":"distribution_internals.html#reproducibility","text":"The binaries we build in GitHub Actions and distribute in our releases come from an intricate process meant to ensure reproducibility . While the ability to produce the same exact binaries from the corresponding Git commits is a good idea for any open source project, it is a requirement for software that deals with digital tokens of significant value.","title":"Reproducibility"},{"location":"distribution_internals.html#docker-containers-for-internal-use","text":"The easiest way to guarantee that users are able to replicate our binaries for themselves is to give them the same software environment we used in CI. Docker containers fit the bill, so everything starts with the architecture- and OS-specific containers in docker/dist/base_image/ . These images contain all the packages we need, are built and published once (to Docker Hub), and are then reused as the basis for temporary Docker images where the nimbus-eth2 build is carried out. These temporary images are controlled by Dockerfiles in docker/dist/ . Since we're not publishing them anywhere, we can customize them to the system they run on (we ensure they use the host's UID/GID, the host's QEMU static binaries, etc); they get access to the source code through the use of external volumes.","title":"Docker containers for internal use"},{"location":"distribution_internals.html#build-process","text":"It all starts from the GitHub actions in .github/workflows/release.yml . There is a different job for each supported OS-architecture combination and they all run in parallel (ideally). Once all those CI jobs are completed successfully, a GitHub release draft is created and all the distributable archives are uploaded to it. A list of checksums for the main binaries is inserted in the release description. That draft needs to be manually published. The build itself is triggered by a Make target, e.g. make dist-amd64 . This invokes scripts/make_dist.sh which builds the corresponding Docker container from docker/dist/ and runs it with the Git repository's top directory as an external volume. The entry point for that container is docker/dist/entry_point.sh and that's where you'll find the Make invocations needed to finally build the software and create distributable tarballs.","title":"Build process"},{"location":"distribution_internals.html#docker-images-for-end-users","text":"Configured in .github/workflows/release.yml (only for Linux AMD64, ARM and ARM64), we unpack the distribution tarball and copy its content into a third type of Docker image \u2014 meant for end users and defined by docker/dist/binaries/Dockerfile.amd64 (and related). We then publish that to Docker Hub .","title":"Docker images for end users"},{"location":"docker.html","text":"Docker images Docker images for the Nimbus beacon node and the Nimbus validator client are available at docker hub. We have version-specific Docker tags (e.g. statusim/nimbus-eth2:amd64-v1.2.3 ) and a tag for the latest image (e.g. statusim/nimbus-eth2:amd64-latest ). These images contain the same binaries as the release tarballs inside a debian:bullseye-slim image, running under a user imaginatively named user , with UID:GID of 1000:1000. The binaries are placed under the /home/user/ directory which is also the default WORKDIR . The ENTRYPOINT of the image is configured to directly launch the respective binary without any extra arguments. Usage Before running Nimbus via docker, you need to prepare a data directory and mount it in docker. It is recommended that you mount the directory at /home/user/data and pass --data-dir=data/beacon_node/mainnet_0 to all nimbus_beacon_node commands. mkdir data docker run -it --rm \\ -v ${ PWD } /data:/home/user/data \\ statusim/nimbus-eth2:amd64-latest \\ --data-dir = data/beacon_node/mainnet_0 --network = mainnet \\ [ other options ] Similarly, to launch a Nimbus validator client you can use the following command: mkdir data docker run -it --rm \\ -v ${ PWD } /data:/home/user/data \\ statusim/nimbus-validator_client:amd64-latest \\ --data-dir = data/validator_client/mainnet_0 \\ [ other options ] Warning Do not use the same data directory for beacon node and validator client! They will both try to load the same keys which may result in slashing. Docker compose Our preferred setup is using docker-compose . You can use one of our example configuration files as a base for your own custom configuration: mkdir data docker-compose -f docker-compose-example1.yml up --quiet-pull --no-color --detach Note The rather voluminous logging is done on stdout , so you might want to change the system-wide Docker logging defaults (which dumps everything in /var/lib/docker/containers/CONTAINER_ID/CONTAINER_ID-json.log ) to something like syslog . We recommend using a log rotation system with appropriate intervals for logs of this size.","title":"Docker images"},{"location":"docker.html#docker-images","text":"Docker images for the Nimbus beacon node and the Nimbus validator client are available at docker hub. We have version-specific Docker tags (e.g. statusim/nimbus-eth2:amd64-v1.2.3 ) and a tag for the latest image (e.g. statusim/nimbus-eth2:amd64-latest ). These images contain the same binaries as the release tarballs inside a debian:bullseye-slim image, running under a user imaginatively named user , with UID:GID of 1000:1000. The binaries are placed under the /home/user/ directory which is also the default WORKDIR . The ENTRYPOINT of the image is configured to directly launch the respective binary without any extra arguments.","title":"Docker images"},{"location":"docker.html#usage","text":"Before running Nimbus via docker, you need to prepare a data directory and mount it in docker. It is recommended that you mount the directory at /home/user/data and pass --data-dir=data/beacon_node/mainnet_0 to all nimbus_beacon_node commands. mkdir data docker run -it --rm \\ -v ${ PWD } /data:/home/user/data \\ statusim/nimbus-eth2:amd64-latest \\ --data-dir = data/beacon_node/mainnet_0 --network = mainnet \\ [ other options ] Similarly, to launch a Nimbus validator client you can use the following command: mkdir data docker run -it --rm \\ -v ${ PWD } /data:/home/user/data \\ statusim/nimbus-validator_client:amd64-latest \\ --data-dir = data/validator_client/mainnet_0 \\ [ other options ] Warning Do not use the same data directory for beacon node and validator client! They will both try to load the same keys which may result in slashing.","title":"Usage"},{"location":"docker.html#docker-compose","text":"Our preferred setup is using docker-compose . You can use one of our example configuration files as a base for your own custom configuration: mkdir data docker-compose -f docker-compose-example1.yml up --quiet-pull --no-color --detach Note The rather voluminous logging is done on stdout , so you might want to change the system-wide Docker logging defaults (which dumps everything in /var/lib/docker/containers/CONTAINER_ID/CONTAINER_ID-json.log ) to something like syslog . We recommend using a log rotation system with appropriate intervals for logs of this size.","title":"Docker compose"},{"location":"doppelganger-detection.html","text":"Doppelganger detection Doppelganger detection is a safety feature for preventing slashing in the event that two setups are using the same validator keys, for example after a migration of keys from one setup to another. Doppelganger detection works by monitoring network activity for a short period for each validator while preventing duties from being performed. If any activity is detected, the node shuts down with exit code 129. Because detection depends on network detection, there are cases where it may fail to find duplicate validators even though they are live. You should never use it as a mechanism for running redundant setups! Command line Doppelganger detection is turned on by default - disable it with: Beacon node Validator client # Disable doppelganger detection ./run-mainnet-beacon-node.sh --doppelganger-detection = off ... # Disable doppelganger detection build/nimbus_validator_client --doppelganger-detection = off ...","title":"Doppelganger detection"},{"location":"doppelganger-detection.html#doppelganger-detection","text":"Doppelganger detection is a safety feature for preventing slashing in the event that two setups are using the same validator keys, for example after a migration of keys from one setup to another. Doppelganger detection works by monitoring network activity for a short period for each validator while preventing duties from being performed. If any activity is detected, the node shuts down with exit code 129. Because detection depends on network detection, there are cases where it may fail to find duplicate validators even though they are live. You should never use it as a mechanism for running redundant setups!","title":"Doppelganger detection"},{"location":"doppelganger-detection.html#command-line","text":"Doppelganger detection is turned on by default - disable it with: Beacon node Validator client # Disable doppelganger detection ./run-mainnet-beacon-node.sh --doppelganger-detection = off ... # Disable doppelganger detection build/nimbus_validator_client --doppelganger-detection = off ...","title":"Command line"},{"location":"el-light-client.html","text":"Light client Warning The light client is currently in BETA and details around running it may change. The Nimbus Light Client is a light-weight alternative to running a full beacon node, when you're not planning on becoming a validator but still want to run an Ethereum execution layer client. Execution layer (EL) clients provide the Web3 API to expose information stored on the Ethereum blockchain. Since the merge \ud83d\udc3c, execution clients can no longer run standalone. Comparison Compared to a full beacon node, a light client has several advantages and disadvantages. Feature Beacon Node Light Client Disk usage ~200GB <1MB Bandwidth TBD TBD (low) Sync time Hours Seconds Head delay None 4/3 slot (15 s) Security Full Light Light clients delegate full validation to other network participants and operate under a honest supermajority (> 2/3) assumption among elected participants. Due to this delegation, light clients are typically behind by ~4/3 slots (~15 seconds on Ethereum mainnet). Note If you are validating, you must run a full beacon node. To use Nimbus, follow the installation instructions . Building from source The Nimbus light client is currently not bundled as part of the Docker images and needs to be built from source. 1. Clone the nimbus-eth2 repository git clone https://github.com/status-im/nimbus-eth2 cd nimbus-eth2 2. Run the build process To build the Nimbus light client and its dependencies, make sure you have all prerequisites and then run: make -j4 nimbus_light_client Tip Omit -j4 on systems with 4GB of memory or less. This may take a few minutes. When the process finishes, the nimbus_light_client executable can be found in the build subdirectory. Pairing with the EL client To ensure that only the light client can control the EL client, a file with random content (JWT secret) must be created. The format is 64 hexadecimal (0-9, a-f) characters. To create one, the following command may be used: openssl rand -hex 32 | tr -d \"\\n\" > \" $HOME /jwtsecret\" Tip To adjust where the file is created, adjust the $HOME/jwtsecret portion in the command above. Also adjust other commands in this guide accordingly. The JWT secret must be passed to both the EL client and the light client to complete the pairing. Running the EL client In addition to the regular instructions to run an EL client, the JWT secret must be configured. The following sections explain how to do this for certain EL clients. Geth Nethermind Others Mainnet Holesky geth --authrpc.jwtsecret = \" $HOME /jwtsecret\" geth --holesky --authrpc.jwtsecret = \" $HOME /jwtsecret\" Mainnet Holesky nethermind --JsonRpc.JwtSecretFile = \" $HOME /jwtsecret\" nethermind --config holesky --JsonRpc.JwtSecretFile = \" $HOME /jwtsecret\" Please consult your EL client's documentation for instructions on how to configure the JWT secret and running the EL client. Running the light client The light client starts syncing from a trusted block. This trusted block should be somewhat recent ( ~1-2 weeks ) and needs to be configured each time when starting the light client. 1. Obtaining a trusted block root A block root may be obtained from another trusted beacon node, or from a trusted provider. Trusted beacon node Beaconcha.in The REST interface must be enabled on the trusted beacon node ( --rest --rest-port=5052 for Nimbus). curl -s \"http://localhost:5052/eth/v1/beacon/headers/finalized\" | \\ jq -r '.data.root' On the beaconcha.in website ( Holesky ), navigate to the Epochs section and select a recent Finalized epoch. Then, scroll down to the bottom of the page. If the bottom-most slot has a Proposed status, copy its Root Hash . Otherwise, for example if the bottom-most slot was Missed , go back and pick a different epoch. Warning Selecting a block root from an untrusted source or using an outdated block root may lead to the light client syncing to an unexpected state. If that happens, stop the light client and restart it with a new trusted block root. Depending on the EL client, its database must be deleted and sync restarted from scratch. 2. Starting the light client To start the light client, run the following commands (inserting your own trusted block root): Mainnet Holesky TRUSTED_BLOCK_ROOT = 0x1234567890123456789012345678901234567890123456789012345678901234 build/nimbus_light_client \\ --web3-url = http://127.0.0.1:8551 --jwt-secret = \" $HOME /jwtsecret\" \\ --trusted-block-root = $TRUSTED_BLOCK_ROOT TRUSTED_BLOCK_ROOT = 0x1234567890123456789012345678901234567890123456789012345678901234 build/nimbus_light_client --network = holesky \\ --web3-url = http://127.0.0.1:8551 --jwt-secret = \" $HOME /jwtsecret\" \\ --trusted-block-root = $TRUSTED_BLOCK_ROOT Tip The light client can be left running in the background. Note that a new trusted block root is required when restarting. Observing the sync process After a while, the light client will pick up beacon block headers from the Ethereum network and start informing the EL client about the latest data. You should see logs similar to the following: Nimbus NTC 2022-11-21 18:00:23.666+01:00 Starting light client topics=\"lightcl\" trusted_block_root=some(c092a1d110a1c8d630ac2c3fa2565813d43087f42c986855a2cd985b995a328c) ... INF 2022-11-21 18:01:24.001+01:00 Slot start slot=1109707 epoch=34678 sync=bootstrapping(c092a1d110a1c8d630ac2c3fa2565813d43087f42c986855a2cd985b995a328c) peers=5 head=fb9b64fe:0 finalized=fb9b64fe:0 delay=1ms495us INF 2022-11-21 18:01:24.734+01:00 Exchanged engine configuration topics=\"eth1\" terminalTotalDifficulty=17000000000000000 terminalBlockHash=0x0000000000000000000000000000000000000000000000000000000000000000 terminalBlockNumber=0 ... INF 2022-11-21 18:02:48.001+01:00 Slot start slot=1109714 epoch=34678 sync=bootstrapping(c092a1d110a1c8d630ac2c3fa2565813d43087f42c986855a2cd985b995a328c) peers=6 head=fb9b64fe:0 finalized=fb9b64fe:0 delay=1ms161us WRN 2022-11-21 18:02:53.603+01:00 Peer count low, no new peers discovered topics=\"networking\" discovered_nodes=1 new_peers=@[] current_peers=6 wanted_peers=160 INF 2022-11-21 18:03:00.001+01:00 Slot start slot=1109715 epoch=34678 sync=bootstrapping(c092a1d110a1c8d630ac2c3fa2565813d43087f42c986855a2cd985b995a328c) peers=5 head=fb9b64fe:0 finalized=fb9b64fe:0 delay=1ms154us INF 2022-11-21 18:03:09.989+01:00 New LC optimistic header optimistic_header=\"(beacon: (slot: 1109216, proposer_index: 1813, parent_root: \\\"0871af30\\\", state_root: \\\"5c0afc98\\\"))\" INF 2022-11-21 18:03:09.989+01:00 New LC finalized header finalized_header=\"(beacon: (slot: 1109216, proposer_index: 1813, parent_root: \\\"0871af30\\\", state_root: \\\"5c0afc98\\\"))\" INF 2022-11-21 18:03:12.001+01:00 Slot start slot=1109716 epoch=34678 sync=syncing peers=6 head=c092a1d1:1109216 finalized=c092a1d1:1109216 delay=1ms159us INF 2022-11-21 18:03:16.047+01:00 New LC optimistic header optimistic_header=\"(beacon: (slot: 1109715, proposer_index: 262, parent_root: \\\"676f4fe4\\\", state_root: \\\"2d13aa42\\\"))\" INF 2022-11-21 18:03:24.001+01:00 Slot start slot=1109717 epoch=34678 sync=synced peers=7 head=58cae92a:1109715 finalized=c092a1d1:1109216 delay=1ms120us INF 2022-11-21 18:03:27.984+01:00 New LC optimistic header optimistic_header=\"(beacon: (slot: 1109716, proposer_index: 1281, parent_root: \\\"58cae92a\\\", state_root: \\\"de464f71\\\"))\" WRN 2022-11-21 18:03:31.419+01:00 Peer count low, no new peers discovered topics=\"networking\" discovered_nodes=0 new_peers=@[] current_peers=7 wanted_peers=160 INF 2022-11-21 18:03:36.001+01:00 Slot start slot=1109718 epoch=34678 sync=synced peers=7 head=c5464508:1109716 finalized=c092a1d1:1109216 delay=1ms98us INF 2022-11-21 18:03:40.012+01:00 New LC optimistic header optimistic_header=\"(beacon: (slot: 1109717, proposer_index: 835, parent_root: \\\"c5464508\\\", state_root: \\\"13f823f8\\\"))\" WRN 2022-11-21 18:03:40.422+01:00 Peer count low, no new peers discovered topics=\"networking\" discovered_nodes=1 new_peers=@[] current_peers=7 wanted_peers=160 INF 2022-11-21 18:03:48.001+01:00 Slot start slot=1109719 epoch=34678 sync=synced peers=7 head=99ab28aa:1109717 finalized=c092a1d1:1109216 delay=1ms53us WRN 2022-11-21 18:03:50.205+01:00 Peer count low, no new peers discovered topics=\"networking\" discovered_nodes=0 new_peers=@[] current_peers=7 wanted_peers=160 INF 2022-11-21 18:04:00.001+01:00 Slot start slot=1109720 epoch=34678 sync=synced peers=7 head=99ab28aa:1109717 finalized=c092a1d1:1109216 delay=1ms145us INF 2022-11-21 18:04:03.982+01:00 New LC optimistic header optimistic_header=\"(beacon: (slot: 1109718, proposer_index: 1202, parent_root: \\\"99ab28aa\\\", state_root: \\\"7f7f88d2\\\"))\" Note The light client protocol depends on consensus layer (CL) full nodes to serve additional data. As this is a new protocol, not all implementations are supporting it yet. Therefore, it may take several minutes to discover supporting peers, during which no log messages may be produced. Geth Nethermind WARN [07-24|22:19:16.777] Ignoring payload with missing parent number=12,658,012 hash=306fad..bdfd44 parent=a22dc7..093bea INFO [07-24|22:19:16.778] Forkchoice requested sync to new head number=12,658,012 hash=306fad..bdfd44 INFO [07-24|22:19:17.232] Syncing beacon headers downloaded=7168 left=12,650,843 eta=13m21.441s INFO [07-24|22:19:21.626] Syncing beacon headers downloaded=75201 left=0 eta=0s INFO [07-24|22:19:21.627] Block synchronisation started 2022-07-24 22:09:05.0853|Received a new payload: 12657968 (0xa5eedb4e4e4b0f84238464d563b82d7dddadfc68f21cfa2bfcbbbcdb944c4b63) 2022-07-24 22:09:05.1018|Insert block into cache without parent 12657968 (0xa5eedb...4c4b63) 2022-07-24 22:09:05.1141|Received: ForkchoiceState: (HeadBlockHash: 0xa5eedb4e4e4b0f84238464d563b82d7dddadfc68f21cfa2bfcbbbcdb944c4b63, SafeBlockHash: 0xa5eedb4e4e4b0f84238464d563b82d7dddadfc68f21cfa2bfcbbbcdb944c4b63, FinalizedBlockHash: 0x0000000000000000000000000000000000000000000000000000000000000000) . 2022-07-24 22:09:05.1141|Syncing... Block 0xa5eedb4e4e4b0f84238464d563b82d7dddadfc68f21cfa2bfcbbbcdb944c4b63 not found.","title":"Light client"},{"location":"el-light-client.html#light-client","text":"Warning The light client is currently in BETA and details around running it may change. The Nimbus Light Client is a light-weight alternative to running a full beacon node, when you're not planning on becoming a validator but still want to run an Ethereum execution layer client. Execution layer (EL) clients provide the Web3 API to expose information stored on the Ethereum blockchain. Since the merge \ud83d\udc3c, execution clients can no longer run standalone.","title":"Light client"},{"location":"el-light-client.html#comparison","text":"Compared to a full beacon node, a light client has several advantages and disadvantages. Feature Beacon Node Light Client Disk usage ~200GB <1MB Bandwidth TBD TBD (low) Sync time Hours Seconds Head delay None 4/3 slot (15 s) Security Full Light Light clients delegate full validation to other network participants and operate under a honest supermajority (> 2/3) assumption among elected participants. Due to this delegation, light clients are typically behind by ~4/3 slots (~15 seconds on Ethereum mainnet). Note If you are validating, you must run a full beacon node. To use Nimbus, follow the installation instructions .","title":"Comparison"},{"location":"el-light-client.html#building-from-source","text":"The Nimbus light client is currently not bundled as part of the Docker images and needs to be built from source.","title":"Building from source"},{"location":"el-light-client.html#1-clone-the-nimbus-eth2-repository","text":"git clone https://github.com/status-im/nimbus-eth2 cd nimbus-eth2","title":"1. Clone the nimbus-eth2 repository"},{"location":"el-light-client.html#2-run-the-build-process","text":"To build the Nimbus light client and its dependencies, make sure you have all prerequisites and then run: make -j4 nimbus_light_client Tip Omit -j4 on systems with 4GB of memory or less. This may take a few minutes. When the process finishes, the nimbus_light_client executable can be found in the build subdirectory.","title":"2. Run the build process"},{"location":"el-light-client.html#pairing-with-the-el-client","text":"To ensure that only the light client can control the EL client, a file with random content (JWT secret) must be created. The format is 64 hexadecimal (0-9, a-f) characters. To create one, the following command may be used: openssl rand -hex 32 | tr -d \"\\n\" > \" $HOME /jwtsecret\" Tip To adjust where the file is created, adjust the $HOME/jwtsecret portion in the command above. Also adjust other commands in this guide accordingly. The JWT secret must be passed to both the EL client and the light client to complete the pairing.","title":"Pairing with the EL client"},{"location":"el-light-client.html#running-the-el-client","text":"In addition to the regular instructions to run an EL client, the JWT secret must be configured. The following sections explain how to do this for certain EL clients. Geth Nethermind Others Mainnet Holesky geth --authrpc.jwtsecret = \" $HOME /jwtsecret\" geth --holesky --authrpc.jwtsecret = \" $HOME /jwtsecret\" Mainnet Holesky nethermind --JsonRpc.JwtSecretFile = \" $HOME /jwtsecret\" nethermind --config holesky --JsonRpc.JwtSecretFile = \" $HOME /jwtsecret\" Please consult your EL client's documentation for instructions on how to configure the JWT secret and running the EL client.","title":"Running the EL client"},{"location":"el-light-client.html#running-the-light-client","text":"The light client starts syncing from a trusted block. This trusted block should be somewhat recent ( ~1-2 weeks ) and needs to be configured each time when starting the light client.","title":"Running the light client"},{"location":"el-light-client.html#1-obtaining-a-trusted-block-root","text":"A block root may be obtained from another trusted beacon node, or from a trusted provider. Trusted beacon node Beaconcha.in The REST interface must be enabled on the trusted beacon node ( --rest --rest-port=5052 for Nimbus). curl -s \"http://localhost:5052/eth/v1/beacon/headers/finalized\" | \\ jq -r '.data.root' On the beaconcha.in website ( Holesky ), navigate to the Epochs section and select a recent Finalized epoch. Then, scroll down to the bottom of the page. If the bottom-most slot has a Proposed status, copy its Root Hash . Otherwise, for example if the bottom-most slot was Missed , go back and pick a different epoch. Warning Selecting a block root from an untrusted source or using an outdated block root may lead to the light client syncing to an unexpected state. If that happens, stop the light client and restart it with a new trusted block root. Depending on the EL client, its database must be deleted and sync restarted from scratch.","title":"1. Obtaining a trusted block root"},{"location":"el-light-client.html#2-starting-the-light-client","text":"To start the light client, run the following commands (inserting your own trusted block root): Mainnet Holesky TRUSTED_BLOCK_ROOT = 0x1234567890123456789012345678901234567890123456789012345678901234 build/nimbus_light_client \\ --web3-url = http://127.0.0.1:8551 --jwt-secret = \" $HOME /jwtsecret\" \\ --trusted-block-root = $TRUSTED_BLOCK_ROOT TRUSTED_BLOCK_ROOT = 0x1234567890123456789012345678901234567890123456789012345678901234 build/nimbus_light_client --network = holesky \\ --web3-url = http://127.0.0.1:8551 --jwt-secret = \" $HOME /jwtsecret\" \\ --trusted-block-root = $TRUSTED_BLOCK_ROOT Tip The light client can be left running in the background. Note that a new trusted block root is required when restarting.","title":"2. Starting the light client"},{"location":"el-light-client.html#observing-the-sync-process","text":"After a while, the light client will pick up beacon block headers from the Ethereum network and start informing the EL client about the latest data. You should see logs similar to the following:","title":"Observing the sync process"},{"location":"el-light-client.html#nimbus","text":"NTC 2022-11-21 18:00:23.666+01:00 Starting light client topics=\"lightcl\" trusted_block_root=some(c092a1d110a1c8d630ac2c3fa2565813d43087f42c986855a2cd985b995a328c) ... INF 2022-11-21 18:01:24.001+01:00 Slot start slot=1109707 epoch=34678 sync=bootstrapping(c092a1d110a1c8d630ac2c3fa2565813d43087f42c986855a2cd985b995a328c) peers=5 head=fb9b64fe:0 finalized=fb9b64fe:0 delay=1ms495us INF 2022-11-21 18:01:24.734+01:00 Exchanged engine configuration topics=\"eth1\" terminalTotalDifficulty=17000000000000000 terminalBlockHash=0x0000000000000000000000000000000000000000000000000000000000000000 terminalBlockNumber=0 ... INF 2022-11-21 18:02:48.001+01:00 Slot start slot=1109714 epoch=34678 sync=bootstrapping(c092a1d110a1c8d630ac2c3fa2565813d43087f42c986855a2cd985b995a328c) peers=6 head=fb9b64fe:0 finalized=fb9b64fe:0 delay=1ms161us WRN 2022-11-21 18:02:53.603+01:00 Peer count low, no new peers discovered topics=\"networking\" discovered_nodes=1 new_peers=@[] current_peers=6 wanted_peers=160 INF 2022-11-21 18:03:00.001+01:00 Slot start slot=1109715 epoch=34678 sync=bootstrapping(c092a1d110a1c8d630ac2c3fa2565813d43087f42c986855a2cd985b995a328c) peers=5 head=fb9b64fe:0 finalized=fb9b64fe:0 delay=1ms154us INF 2022-11-21 18:03:09.989+01:00 New LC optimistic header optimistic_header=\"(beacon: (slot: 1109216, proposer_index: 1813, parent_root: \\\"0871af30\\\", state_root: \\\"5c0afc98\\\"))\" INF 2022-11-21 18:03:09.989+01:00 New LC finalized header finalized_header=\"(beacon: (slot: 1109216, proposer_index: 1813, parent_root: \\\"0871af30\\\", state_root: \\\"5c0afc98\\\"))\" INF 2022-11-21 18:03:12.001+01:00 Slot start slot=1109716 epoch=34678 sync=syncing peers=6 head=c092a1d1:1109216 finalized=c092a1d1:1109216 delay=1ms159us INF 2022-11-21 18:03:16.047+01:00 New LC optimistic header optimistic_header=\"(beacon: (slot: 1109715, proposer_index: 262, parent_root: \\\"676f4fe4\\\", state_root: \\\"2d13aa42\\\"))\" INF 2022-11-21 18:03:24.001+01:00 Slot start slot=1109717 epoch=34678 sync=synced peers=7 head=58cae92a:1109715 finalized=c092a1d1:1109216 delay=1ms120us INF 2022-11-21 18:03:27.984+01:00 New LC optimistic header optimistic_header=\"(beacon: (slot: 1109716, proposer_index: 1281, parent_root: \\\"58cae92a\\\", state_root: \\\"de464f71\\\"))\" WRN 2022-11-21 18:03:31.419+01:00 Peer count low, no new peers discovered topics=\"networking\" discovered_nodes=0 new_peers=@[] current_peers=7 wanted_peers=160 INF 2022-11-21 18:03:36.001+01:00 Slot start slot=1109718 epoch=34678 sync=synced peers=7 head=c5464508:1109716 finalized=c092a1d1:1109216 delay=1ms98us INF 2022-11-21 18:03:40.012+01:00 New LC optimistic header optimistic_header=\"(beacon: (slot: 1109717, proposer_index: 835, parent_root: \\\"c5464508\\\", state_root: \\\"13f823f8\\\"))\" WRN 2022-11-21 18:03:40.422+01:00 Peer count low, no new peers discovered topics=\"networking\" discovered_nodes=1 new_peers=@[] current_peers=7 wanted_peers=160 INF 2022-11-21 18:03:48.001+01:00 Slot start slot=1109719 epoch=34678 sync=synced peers=7 head=99ab28aa:1109717 finalized=c092a1d1:1109216 delay=1ms53us WRN 2022-11-21 18:03:50.205+01:00 Peer count low, no new peers discovered topics=\"networking\" discovered_nodes=0 new_peers=@[] current_peers=7 wanted_peers=160 INF 2022-11-21 18:04:00.001+01:00 Slot start slot=1109720 epoch=34678 sync=synced peers=7 head=99ab28aa:1109717 finalized=c092a1d1:1109216 delay=1ms145us INF 2022-11-21 18:04:03.982+01:00 New LC optimistic header optimistic_header=\"(beacon: (slot: 1109718, proposer_index: 1202, parent_root: \\\"99ab28aa\\\", state_root: \\\"7f7f88d2\\\"))\" Note The light client protocol depends on consensus layer (CL) full nodes to serve additional data. As this is a new protocol, not all implementations are supporting it yet. Therefore, it may take several minutes to discover supporting peers, during which no log messages may be produced. Geth Nethermind WARN [07-24|22:19:16.777] Ignoring payload with missing parent number=12,658,012 hash=306fad..bdfd44 parent=a22dc7..093bea INFO [07-24|22:19:16.778] Forkchoice requested sync to new head number=12,658,012 hash=306fad..bdfd44 INFO [07-24|22:19:17.232] Syncing beacon headers downloaded=7168 left=12,650,843 eta=13m21.441s INFO [07-24|22:19:21.626] Syncing beacon headers downloaded=75201 left=0 eta=0s INFO [07-24|22:19:21.627] Block synchronisation started 2022-07-24 22:09:05.0853|Received a new payload: 12657968 (0xa5eedb4e4e4b0f84238464d563b82d7dddadfc68f21cfa2bfcbbbcdb944c4b63) 2022-07-24 22:09:05.1018|Insert block into cache without parent 12657968 (0xa5eedb...4c4b63) 2022-07-24 22:09:05.1141|Received: ForkchoiceState: (HeadBlockHash: 0xa5eedb4e4e4b0f84238464d563b82d7dddadfc68f21cfa2bfcbbbcdb944c4b63, SafeBlockHash: 0xa5eedb4e4e4b0f84238464d563b82d7dddadfc68f21cfa2bfcbbbcdb944c4b63, FinalizedBlockHash: 0x0000000000000000000000000000000000000000000000000000000000000000) . 2022-07-24 22:09:05.1141|Syncing... Block 0xa5eedb4e4e4b0f84238464d563b82d7dddadfc68f21cfa2bfcbbbcdb944c4b63 not found.","title":"Nimbus"},{"location":"email-notifications.html","text":"Email notifications You can create an account on beaconcha.in to set up email notifications in case your validator loses balance (goes offline), or gets slashed. Tip If your validator loses balance for two epochs in a row, you may want to investigate. It's a strong signal that it may be offline. 1. Sign up at beaconcha.in/register 2. Type your validator's public key into the search bar 3. Click on the bookmark icon 4. Tick the boxes and select Add To Watchlist","title":"Email notifications"},{"location":"email-notifications.html#email-notifications","text":"You can create an account on beaconcha.in to set up email notifications in case your validator loses balance (goes offline), or gets slashed. Tip If your validator loses balance for two epochs in a row, you may want to investigate. It's a strong signal that it may be offline.","title":"Email notifications"},{"location":"email-notifications.html#1-sign-up-at-beaconchainregister","text":"","title":"1. Sign up at beaconcha.in/register"},{"location":"email-notifications.html#2-type-your-validators-public-key-into-the-search-bar","text":"","title":"2. Type your validator's public key into the search bar"},{"location":"email-notifications.html#3-click-on-the-bookmark-icon","text":"","title":"3. Click on the bookmark icon"},{"location":"email-notifications.html#4-tick-the-boxes-and-select-add-to-watchlist","text":"","title":"4. Tick the boxes and select Add To Watchlist"},{"location":"era-store.html","text":"Era store Warning This feature is currently in BETA! Nodes using era files may need to be resynced as the data format is not yet considered stable. Era files are a long-term archival format for Ethereum data. They are used to provide an easy interchange medium that clients interested in deep ethereum history can use to recreate past states. Tip For more information about era files, see this post . Each era file contains the blocks of 8192 slots (~27 hours). Blocks in era files are considered finalized. Since the history no longer is subject to change, the files are suitable to be archived for long-term storage, history recreation and other uses, and can be shared using traditional mediums such as http and bittorrent . Nimbus can both create and use era files as a starting point to regenerate past history as well as to serve blocks. Importing era files To import an era archive, place the files in a folder called era in the data directory : # Go to the nimbus directory cd build/data/shared_mainnet_0 # Create era directory mkdir -p era # Download era store from era provider wget --no-parent -A '*.era' -q --show-progress -nd -r -c https://provider/era With the era files present, perform a trusted node sync to complete the import, possibly with --reindex in order to create an archive node . Generating era files To generate era files, you need to first build Nimbus from source and sync the node using full sync. A checkpoint-synced node can be used to generate era files from the checkpoint onwards. After that, build the additional ncli_db tool: make ncli_db The era export tool works by reading an existing Nimbus database and creating an era store. Every time the tool is run, it will check the existing store and export any new data to it. # Go to the data directory of nimbus (the directory passed to --data-dir) cd build/data/shared_mainnet_0/ # Create a directory for the era store mkdir -p era cd era # Launch the era export ../../../ncli_db exportEra --db:../db The first time the export is run, full history is exported which may take some time. Subsequent runs will top up the era store with new blocks. It is recommended to set up a cron job or a timer, and run the export command every hour - doing so will ensure that era files are created on a timely basis. Tip You do not need to stop Nimbus to generate era files. It is however not recommended to run era file generation on a node that is also serving validators. Sharing era files Era files can be shared directly from the era folder using a web server, or simply by copying them to a new location. Options You can pass a custom era store location to Nimbus using --era-dir : nimbus_beacon_node --era-dir:/path/to/era Tip Multiple nimbus beacon node instances can share the same era store.","title":"Era store"},{"location":"era-store.html#era-store","text":"Warning This feature is currently in BETA! Nodes using era files may need to be resynced as the data format is not yet considered stable. Era files are a long-term archival format for Ethereum data. They are used to provide an easy interchange medium that clients interested in deep ethereum history can use to recreate past states. Tip For more information about era files, see this post . Each era file contains the blocks of 8192 slots (~27 hours). Blocks in era files are considered finalized. Since the history no longer is subject to change, the files are suitable to be archived for long-term storage, history recreation and other uses, and can be shared using traditional mediums such as http and bittorrent . Nimbus can both create and use era files as a starting point to regenerate past history as well as to serve blocks.","title":"Era store"},{"location":"era-store.html#importing-era-files","text":"To import an era archive, place the files in a folder called era in the data directory : # Go to the nimbus directory cd build/data/shared_mainnet_0 # Create era directory mkdir -p era # Download era store from era provider wget --no-parent -A '*.era' -q --show-progress -nd -r -c https://provider/era With the era files present, perform a trusted node sync to complete the import, possibly with --reindex in order to create an archive node .","title":"Importing era files"},{"location":"era-store.html#generating-era-files","text":"To generate era files, you need to first build Nimbus from source and sync the node using full sync. A checkpoint-synced node can be used to generate era files from the checkpoint onwards. After that, build the additional ncli_db tool: make ncli_db The era export tool works by reading an existing Nimbus database and creating an era store. Every time the tool is run, it will check the existing store and export any new data to it. # Go to the data directory of nimbus (the directory passed to --data-dir) cd build/data/shared_mainnet_0/ # Create a directory for the era store mkdir -p era cd era # Launch the era export ../../../ncli_db exportEra --db:../db The first time the export is run, full history is exported which may take some time. Subsequent runs will top up the era store with new blocks. It is recommended to set up a cron job or a timer, and run the export command every hour - doing so will ensure that era files are created on a timely basis. Tip You do not need to stop Nimbus to generate era files. It is however not recommended to run era file generation on a node that is also serving validators.","title":"Generating era files"},{"location":"era-store.html#sharing-era-files","text":"Era files can be shared directly from the era folder using a web server, or simply by copying them to a new location.","title":"Sharing era files"},{"location":"era-store.html#options","text":"You can pass a custom era store location to Nimbus using --era-dir : nimbus_beacon_node --era-dir:/path/to/era Tip Multiple nimbus beacon node instances can share the same era store.","title":"Options"},{"location":"eth1.html","text":"Run an execution client In order to perform validation duties, you must have an execution client running \u2014 at least one for each beacon node. Relying on third-party services such as Infura, Alchemy and Pocket is no longer possible. Sharing the same execution client between multiple beacon nodes is not supported. Nimbus has been tested with all major execution clients. See the execution client comparison for more information. Info Syncing an execution client may take hours or even days , depending on your hardware! Steps 1. Install execution client Select an execution client and install it, configuring it such that that the authenticated JSON-RPC interface is enabled and a JWT secret file is created. Nimbus Geth Nethermind Besu Erigon In parallel to nimbus-eth2 , we are working hard on the Nimbus execution client . While this is very much a project in development (i.e. not yet ready for public consumption), we welcome you to experiment with it. 1. Install Geth See the Installing Geth guide for instructions on installing Geth. 2. Start Geth Once you have geth installed, make sure to enable the authenticated JSON-RPC interface when running geth: Mainnet Holesky geth --authrpc.addr localhost --authrpc.port 8551 --authrpc.vhosts localhost --authrpc.jwtsecret /tmp/jwtsecret geth --holesky --authrpc.addr localhost --authrpc.port 8551 --authrpc.vhosts localhost --authrpc.jwtsecret /tmp/jwtsecret See the Installing Nethermind guide to set up Nethermind. Make sure to enable the JSON-RPC interface and pass --JsonRpc.JwtSecretFile=/tmp/jwtsecret to select a JWT secret file location. See the Besu documentation for instructions on setting up Besu. Make sure to enable the JSON-RPC interface and store the JWT token in /tmp/jwtsecret . See the Erigon README for instructions on setting up Erigon. Make sure to enable the JSON-RPC interface and use --authrpc.jwtsecret=/tmp/jwtsecret to set a path to the JWT token file. 2. Leave the execution client running The execution client needs to be running at all times in order for the beacon node to be able to support validators. It will start its syncing process as soon as the beacon node connects to it. Once both are synced, they will continue to work in tandem to validate the latest Ethereum state. It is safe to start the beacon node even if the execution client is not yet fully synced, and vice versa. 3. Pass the URL and JWT secret to Nimbus The --el option informs the beacon node how to connect to the execution client \u2014 both http:// and ws:// URLs are supported. Info By default, the execution client accepts connections on the localhost interface ( 127.0.0.1 ), with default authenticated RPC port 8551 . When the --el option is not explicitly specified, Nimbus will assume that the execution client is running on the same machine with such default settings. Once started, the execution client will create a file containing a JWT secret token. The token file is needed for Nimbus to authenticate itself with the execution client and perform trusted operations. You will need to pass the path to the token file to Nimbus together with the web3 URL. Mainnet Holesky ./run-mainnet-beacon-node.sh \\ --el = http://127.0.0.1:8551 \\ --jwt-secret = /tmp/jwtsecret ./run-holesky-beacon-node.sh \\ --el = http://127.0.0.1:8551 \\ --jwt-secret = /tmp/jwtsecret Upgrade execution client Nimbus Geth Nethermind Besu In the nimbus-eth1 directory, run the following commands: git pull make -j4 update make -j4 nimbus Following Geth update instructions , to update Geth you need to: stop the node, download the latest release (follow installation instructions ), restart the node. There are several ways of updating Nethermind, depending on the installation method. Follow Nethermind upgrade instructions . Follow Besu upgrade instructions . Advanced setups Running multiple execution clients You can increase the resilience of your setup and eliminate any downtime during upgrade procedure of the execution client software by allowing your beacon node to manage multiple execution clients. To enable this mode, just specify multiple URLs through the --el option when starting your beacon node: ./run-mainnet-beacon-node.sh \\ --el = http://127.0.0.1:8551 \\ --el = ws://other:8551 \\ --jwt-secret = /tmp/jwtsecret Tip You can use a different secret for each connection by specifying jwt-secret or jwt-secret-file as a query parameter in the anchor section of the URL (e.g. http://127.0.0.1:8551/#jwt-secret=0x12345... or http://127.0.0.1:8551/#jwt-secret-file=/tmp/jwtsecret ). If you use a TOML config file , you can also use the following, more natural, syntax: data-dir = \"my-data-dir\" rest = true ... [[el]] url = \"http://127.0.0.1:8551\" jwt-secret-file = \"/path/to/jwt/file\" [[el]] url = \"http://192.168.1.2:8551\" jwt-secret = \"\" As long as any of execution clients remains operational and fully synced, Nimbus will keep performing all validator duties. Tip To carry out an upgrade procedure without any downtime, just restart the execution clients one by one, waiting for each instance to re-sync before moving to the next one. If you use this mode with different execution client implementations, Nimbus will act as an execution layer consensus violation detector, preventing the publishing of blocks that may trigger a catastrophic partitioning in the network.","title":"Run an execution client"},{"location":"eth1.html#run-an-execution-client","text":"In order to perform validation duties, you must have an execution client running \u2014 at least one for each beacon node. Relying on third-party services such as Infura, Alchemy and Pocket is no longer possible. Sharing the same execution client between multiple beacon nodes is not supported. Nimbus has been tested with all major execution clients. See the execution client comparison for more information. Info Syncing an execution client may take hours or even days , depending on your hardware!","title":"Run an execution client"},{"location":"eth1.html#steps","text":"","title":"Steps"},{"location":"eth1.html#1-install-execution-client","text":"Select an execution client and install it, configuring it such that that the authenticated JSON-RPC interface is enabled and a JWT secret file is created. Nimbus Geth Nethermind Besu Erigon In parallel to nimbus-eth2 , we are working hard on the Nimbus execution client . While this is very much a project in development (i.e. not yet ready for public consumption), we welcome you to experiment with it.","title":"1. Install execution client"},{"location":"eth1.html#2-leave-the-execution-client-running","text":"The execution client needs to be running at all times in order for the beacon node to be able to support validators. It will start its syncing process as soon as the beacon node connects to it. Once both are synced, they will continue to work in tandem to validate the latest Ethereum state. It is safe to start the beacon node even if the execution client is not yet fully synced, and vice versa.","title":"2. Leave the execution client running"},{"location":"eth1.html#3-pass-the-url-and-jwt-secret-to-nimbus","text":"The --el option informs the beacon node how to connect to the execution client \u2014 both http:// and ws:// URLs are supported. Info By default, the execution client accepts connections on the localhost interface ( 127.0.0.1 ), with default authenticated RPC port 8551 . When the --el option is not explicitly specified, Nimbus will assume that the execution client is running on the same machine with such default settings. Once started, the execution client will create a file containing a JWT secret token. The token file is needed for Nimbus to authenticate itself with the execution client and perform trusted operations. You will need to pass the path to the token file to Nimbus together with the web3 URL. Mainnet Holesky ./run-mainnet-beacon-node.sh \\ --el = http://127.0.0.1:8551 \\ --jwt-secret = /tmp/jwtsecret ./run-holesky-beacon-node.sh \\ --el = http://127.0.0.1:8551 \\ --jwt-secret = /tmp/jwtsecret","title":"3. Pass the URL and JWT secret to Nimbus"},{"location":"eth1.html#upgrade-execution-client","text":"Nimbus Geth Nethermind Besu In the nimbus-eth1 directory, run the following commands: git pull make -j4 update make -j4 nimbus Following Geth update instructions , to update Geth you need to: stop the node, download the latest release (follow installation instructions ), restart the node. There are several ways of updating Nethermind, depending on the installation method. Follow Nethermind upgrade instructions . Follow Besu upgrade instructions .","title":"Upgrade execution client"},{"location":"eth1.html#advanced-setups","text":"","title":"Advanced setups"},{"location":"eth1.html#running-multiple-execution-clients","text":"You can increase the resilience of your setup and eliminate any downtime during upgrade procedure of the execution client software by allowing your beacon node to manage multiple execution clients. To enable this mode, just specify multiple URLs through the --el option when starting your beacon node: ./run-mainnet-beacon-node.sh \\ --el = http://127.0.0.1:8551 \\ --el = ws://other:8551 \\ --jwt-secret = /tmp/jwtsecret Tip You can use a different secret for each connection by specifying jwt-secret or jwt-secret-file as a query parameter in the anchor section of the URL (e.g. http://127.0.0.1:8551/#jwt-secret=0x12345... or http://127.0.0.1:8551/#jwt-secret-file=/tmp/jwtsecret ). If you use a TOML config file , you can also use the following, more natural, syntax: data-dir = \"my-data-dir\" rest = true ... [[el]] url = \"http://127.0.0.1:8551\" jwt-secret-file = \"/path/to/jwt/file\" [[el]] url = \"http://192.168.1.2:8551\" jwt-secret = \"\" As long as any of execution clients remains operational and fully synced, Nimbus will keep performing all validator duties. Tip To carry out an upgrade procedure without any downtime, just restart the execution clients one by one, waiting for each instance to re-sync before moving to the next one. If you use this mode with different execution client implementations, Nimbus will act as an execution layer consensus violation detector, preventing the publishing of blocks that may trigger a catastrophic partitioning in the network.","title":"Running multiple execution clients"},{"location":"external-block-builder.html","text":"Set up block builders / MEV Nimbus supports outsourcing block production to an external block builder, thus presenting the opportunity to capture Maximal Extractable Value (MEV). When external block building is enabled, the beacon node connects to a service using the builder API with the execution client acting as a fallback. Setting up external block building typically involves running an additional service on your server which is configured to choose the best block from one or more relays and having the beacon node connect to this service. Warning External block builders introduce additional risk to the block building process which may cause loss of rewards. In particular, once Nimbus has signed the block header proposed by the external builder, the execution client can no longer be used as fallback, and the external builder is trusted to complete the building process. Note By default, priority and maximum gas fees determine transaction inclusion in blocks. External block builders may use other strategies for transaction selection, including regulatory constraints and extracted value. For further information, check the documentation of the block builder. Command line External block building is must be enabled on both beacon node and validator client using the --payload-builder=true flag. You can use the --local-block-value-boost option to give preference to the best block provided by an execution client, as long as its value is within the specified percentage of the value advertised by the best external builder. Tip Setting this flag to a non-zero value is recommended due to the additional risk introduced by the usage of an external block builder. Additionally, the URL of the service exposing the builder API must be provided to the beacon node: Mainnet Beacon Node Holesky Beacon Node Validator Client ./run-mainnet-beacon-node.sh --payload-builder = true --payload-builder-url = https:// ${ HOST } : ${ PORT } / ./run-holesky-beacon-node.sh --payload-builder = true --payload-builder-url = https:// ${ HOST } : ${ PORT } / build/nimbus_validator_client --payload-builder = true Useful resources EthStaker MEV setup guide EthStaker MEV relay list Mainnet Relay Overview Holesky Relay Overview","title":"Set up block builders / MEV"},{"location":"external-block-builder.html#set-up-block-builders-mev","text":"Nimbus supports outsourcing block production to an external block builder, thus presenting the opportunity to capture Maximal Extractable Value (MEV). When external block building is enabled, the beacon node connects to a service using the builder API with the execution client acting as a fallback. Setting up external block building typically involves running an additional service on your server which is configured to choose the best block from one or more relays and having the beacon node connect to this service. Warning External block builders introduce additional risk to the block building process which may cause loss of rewards. In particular, once Nimbus has signed the block header proposed by the external builder, the execution client can no longer be used as fallback, and the external builder is trusted to complete the building process. Note By default, priority and maximum gas fees determine transaction inclusion in blocks. External block builders may use other strategies for transaction selection, including regulatory constraints and extracted value. For further information, check the documentation of the block builder.","title":"Set up block builders / MEV"},{"location":"external-block-builder.html#command-line","text":"External block building is must be enabled on both beacon node and validator client using the --payload-builder=true flag. You can use the --local-block-value-boost option to give preference to the best block provided by an execution client, as long as its value is within the specified percentage of the value advertised by the best external builder. Tip Setting this flag to a non-zero value is recommended due to the additional risk introduced by the usage of an external block builder. Additionally, the URL of the service exposing the builder API must be provided to the beacon node: Mainnet Beacon Node Holesky Beacon Node Validator Client ./run-mainnet-beacon-node.sh --payload-builder = true --payload-builder-url = https:// ${ HOST } : ${ PORT } / ./run-holesky-beacon-node.sh --payload-builder = true --payload-builder-url = https:// ${ HOST } : ${ PORT } / build/nimbus_validator_client --payload-builder = true","title":"Command line"},{"location":"external-block-builder.html#useful-resources","text":"EthStaker MEV setup guide EthStaker MEV relay list Mainnet Relay Overview Holesky Relay Overview","title":"Useful resources"},{"location":"faq.html","text":"Frequently Asked Questions General Can I run Nimbus on my machine? Check our system requirements and how to prepare your machine . Note that it is also possible to run Nimbus on Raspberry Pi . I'm currently using Prysm / Lighthouse / Teku, how do I migrate to Nimbus? See our migration guide . Which version of Nimbus am I running? You can check the version through a number of methods: # Run the beacon node with the --version flag: build/nimbus_beacon_node --version # Query the metrics server - requires running with the '--metrics' option curl -s http://localhost:8008/metrics | grep version # Query the REST API - requires running with the '--rest' option curl -s http://localhost:9100/eth/v1/node/version How to upgrade Nimbus to a newer version? See our upgrading guide . Why are metrics not working? The metrics server is disabled by default. Enable it by passing --metrics to the run command: build/nimbus_beacon_node --metrics ... Why is the REST server not working? The REST server is disabled by default. Enable it by passing --rest to the run command: build/nimbus_beacon_node --rest ... Why does my validator miss two epochs of attestations after (re)starting? When a validator is started (or restarted), it listens for 2 epochs for attestations from a validator with the same public key (a doppelganger), before sending an attestation itself. This is a simple way of handling the case where one validator comes online with the same key as another validator that's already online, e.g. one device was started without switching the other off. While this strategy requires the client to wait two whole epochs on restart before attesting, a couple of missed attestations is a very minor price to pay in exchange for significantly reducing the risk of an accidental slashing. You can think of it as a small penalty that you pay only on first launch and restarts. When you take into account the total runtime of your validator, the impact should be minimal. While we strongly recommend against it, you can disable doppelganger detection with an explicit flag ( --doppelganger-detection=false ) if you don't plan on moving your setup. What is the best way to stress test my execution+consensus setup before committing with real ETH? We recommend running a Nimbus beacon node on Holesky and a mainnet execution client on the same machine. This will simulate the load of running a mainnet validator. To stress test it, add --subscribe-all-subnets to the beacon node options . This simulates the maximum load that the consensus layer will put on the machine should you run 64 validators or more on it. How do I add an additional validator? See the information here . What does synced/opt mean, in the \"Slot start\" message? When /opt is present in the \"Slot start\" message, it means the node is optimistically synced and is waiting for the execution client to finish its syncing process. Until that happens, validator duties are disabled. Syncing is very slow, can this be sped up? A complete sync might take several hours or even days. We recommend you to do a trusted node sync , which takes only few minutes. How can I automate running my beacon node? You can set up a systemd service. See our systemd guide . Folder Permissions To protect against key loss, Nimbus requires that files and directories be owned by the user running the application. Furthermore, they should not be readable by others. It may happen that the wrong permissions are applied, particularly when creating the directories manually. The following errors are a sign of this: Data folder has insecure ACL Data directory has insecure permissions File has insecure permissions See the data directory page for instructions on how to fix this. Networking How can I improve my peer count? See the networking guide . How do I fix the discovered new external address warning log? WRN 2021-03-15 02:23:37.569+00:00 Discovered new external address but ENR auto update is off topics=\"discv5\"... It's possible that your ISP has changed your dynamic IP address without you knowing. The first thing to do it to try relaunching the beacon node with --enr-auto-update (pass it as an option in the command line). If this doesn't fix the problem, the next thing to do is to check your external (public) IP address and detect open ports on your connection: you can use https://www.yougetsignal.com/tools/open-ports/ . Note that Nimbus TCP and UDP ports are both set to 9000 by default. See here for how to set up port forwarding. Validating What exactly is a validator? A validator is an entity that participates in the consensus of the Ethereum protocol, and has staked 32 ETH to do so. Or, in plain English, a human running a computer process. This process proposes and vouches for new blocks to be added to the blockchain. In other words, you can think of a validator as a voter for new blocks. The more votes a block gets, the more likely it is to be added to the chain. Importantly, a validator's vote is weighted by the amount it has at stake. Do I need a separate validator client? No, Nimbus doesn't require setting up a separate validator client process \u2014 the beacon node can itself perform validator duties. What is a deposit contract? You can think of it as a transfer of funds between Ethereum 1.0 accounts and Ethereum 2.0 validators. It specifies who is staking, who is validating, how much is being staked, and who can withdraw the funds. Why do validators need to have funds at stake? Validators need to have funds at stake so they can be penalized for behaving dishonestly. In other words: to keep them honest, their actions need to have financial consequences. How much ETH does a validator need to stake? Before a validator can start to secure the network, they need to stake 32 ETH . This forms the validator's initial balance. Is there any advantage to having more than 32 ETH at stake? No, there is no advantage to having more than 32 ETH staked. Limiting the maximum stake to 32 ETH encourages decentralization of power as it prevents any single validator from having an excessively large vote on the state of the chain. Remember that a validator\u2019s vote is weighted by the amount it has at stake. Can I stop my validator for a few days and then start it back up again? You can, but, under normal conditions, you will lose an amount of ETH roughly equivalent to the amount of ETH you would have gained in that period. In other words, if you stood to earn \u22480.01 ETH, you would instead be penalized \u22480.01 ETH. How can I keep track of my validator? One way of keeping track is using an online service such as beaconcha.in: Mainnet or Holesky . Another way is to set up validator monitoring together with a dashboard to keep track of its performance. I want to switch my validator keys to another machine, how long do I need to wait to avoid getting slashed? We recommend waiting 2 epochs (around 15 minutes), before restarting Nimbus on a different machine. When should I top up my validator's balance? The answer to this question very much depends on how much ETH you have at your disposal. You should certainly top up if your balance is close to 16 ETH: this is to ensure you don't get removed from the validator set (which automatically happens if your balance falls below 16 ETH). At the other end of the spectrum, if your balance is closer to 31 ETH, it's probably not worth your while adding the extra ETH required to get back to 32. When can I withdraw my funds, and what's the difference between exiting and withdrawing? After the Capella hard-fork, activated on 12th of April 2023, all exited validators that use 0x01 withdrawal credentials will have their funds automatically withdrawn. Please see our dedicated guide for withdrawals for further information. How are validators incentivized to stay active and honest? In addition to being penalized for being offline, validators are penalized for behaving maliciously (for example, attesting to invalid or contradicting blocks). On the other hand, they are rewarded for proposing / attesting to blocks that are included in the chain. The key concept is the following: Rewards are given for actions that help the network reach consensus. Minor penalties are given for inadvertent actions (or inactions) that hinder consensus. And major penalties \u2014 or slashings \u2014 are given for malicious actions. In other words, validators that maximize their rewards also provide the greatest benefit to the network as a whole. How are rewards/penalties issued? Remember that each validator has its own balance, with the initial balance outlined in the deposit contract. This balance is updated periodically by the Ethereum network rules as the validator carries (or fails to carry) out his or her responsibilities. Put another way, rewards and penalties are reflected in the validator's balance over time. How often are rewards/penalties issued? Approximately every six and a half minutes \u2014 a period of time known as an epoch. Every epoch, the network measures the actions of each validator and issues rewards or penalties appropriately. How large are the rewards/penalties? There is no easy answer to this question as there are many factors that go into this calculation. Arguably the most impactful factor on rewards earned for validating transactions is the total amount of stake in the network. In other words, the total amount of validators. Depending on this figure the max annual return rate for a validator can be anywhere between 2 and 20%. Given a fixed total number of validators, the rewards/penalties predominantly scale with the balance of the validator: attesting with a higher balance results in larger rewards/penalties whereas attesting with a lower balance results in lower rewards/penalties. Note however that this scaling mechanism works in a non-obvious way. To understand the precise details of how it works requires understanding a concept called effective balance . If you're not yet familiar with this concept, we recommend you read through this excellent post . Why do rewards depend on the total number of validators in the network? Block rewards are calculated using a sliding scale based on the total amount of ETH staked on the network. In plain English: if the total amount of ETH staked is low, the reward (interest rate) is high, but as the total stake rises, the reward (interest) paid out to each validator starts to fall. Why a sliding scale? While we won't get into the gory details here, the basic intuition is that there needs to be a minimum number of validators (and hence a minimum amount of ETH staked) for the network to function properly. So, to incentivize more validators to join, it's important that the interest rate remains high until this minimum number is reached. Afterwards, validators are still encouraged to join (the more validators the more decentralized the network), but it's not absolutely essential that they do so (so the interest rate can fall). How badly will a validator be penalized for being offline? It depends. In addition to the impact of effective balance , there are two important scenarios to be aware of: Being offline while a supermajority (2/3) of validators is still online leads to relatively small penalties as there are still enough validators online for the chain to finalize. This is the expected scenario. Being offline at the same time as more than 1/3 of the total number of validators leads to harsher penalties, since blocks do not finalize anymore. This scenario is very extreme and unlikely to happen. Note that in the second (unlikely) scenario, validators stand to progressively lose up to 50% (16 ETH) of their stake over 21 days. After 21 days they are ejected out of the validator pool. This ensures that blocks start finalizing again at some point. How great does an honest validator's uptime need to be for it to be net profitable? Overall, validators are expected to be net profitable as long as their uptime is greater than 50% . This means that validators don't need to go to extreme lengths with backup clients or redundant internet connections as the repercussions of being offline are not so severe. How much will a validator be penalized for acting maliciously? Again, it depends. Behaving maliciously, e.g. attesting to invalid or contradicting blocks, will lead to a validator's stake being slashed. If a malicious behavior is detected, 1/32 of validator's staked ether (up to a maximum of 1 ETH) is immediately slashed and a 36-day removal period begins. During this period, the validator's stake is gradually slashed and at day 18 an additional penalty is applied: the amount depends on the number of other slashed validators \u2014 the more validators are slashed, the magnitude of the slash increases. The idea behind this is to minimize the losses from honest mistakes, but strongly discouraging coordinated attacks. What exactly is slashing? Slashing has two purposes: to make it prohibitively expensive to attack eth2, and to stop validators from being lazy by checking that they actually perform their duties. Slashing a validator is to destroy (a portion of) the validator\u2019s stake if they act in a provably destructive manner. Validators that are slashed are prevented from participating in the protocol further and are forcibly exited. What happens I lose my signing key? If the signing key is lost, the validator can no longer propose or attest. However, all is not lost. Assuming validators derive their keys using EIP2334 (as per the default onboarding flow) then validators can always recalculate their signing key from their withdrawal key . What happens if I lose my withdrawal key? If the withdrawal key is lost, there is no way to obtain access to the funds held by the validator. As such, it's a good idea to create your keys from mnemonics which act as another backup. This will be the default for validators who join via this site's onboarding process. If the validator can no longer propose or attest, their balance will decrease over time as they are punished for not participating in the consensus process. When the validator's balance reaches 16 ETH, they will be automatically exited from the validator pool, and 16 ETH will be transferred to their withdrawal address (as long it's specified). Note After the Capella hard-fork, activated on 12th of April 2023, all exited validators that use 0x01 withdrawal credentials will have their funds automatically withdrawn. Please see our dedicated guide for withdrawals for further information. What happens if my withdrawal key is stolen? If the withdrawal key is stolen, the thief can transfer the validator\u2019s balance, but only once the validator has exited. If the signing key is not under the thief\u2019s control, the thief cannot exit the validator. The user with the signing key could attempt to quickly exit the validator and then transfer the funds \u2014 with the withdrawal key \u2014 before the thief. Why two keys instead of one? In a nutshell, security. The signing key must be available at all times. As such, it will need to be held online. Since anything online is vulnerable to being hacked, it's not a good idea to use the same key for withdrawals.","title":"Frequently Asked Questions"},{"location":"faq.html#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"faq.html#general","text":"","title":"General"},{"location":"faq.html#can-i-run-nimbus-on-my-machine","text":"Check our system requirements and how to prepare your machine . Note that it is also possible to run Nimbus on Raspberry Pi .","title":"Can I run Nimbus on my machine?"},{"location":"faq.html#im-currently-using-prysm-lighthouse-teku-how-do-i-migrate-to-nimbus","text":"See our migration guide .","title":"I'm currently using Prysm / Lighthouse / Teku, how do I migrate to Nimbus?"},{"location":"faq.html#which-version-of-nimbus-am-i-running","text":"You can check the version through a number of methods: # Run the beacon node with the --version flag: build/nimbus_beacon_node --version # Query the metrics server - requires running with the '--metrics' option curl -s http://localhost:8008/metrics | grep version # Query the REST API - requires running with the '--rest' option curl -s http://localhost:9100/eth/v1/node/version","title":"Which version of Nimbus am I running?"},{"location":"faq.html#how-to-upgrade-nimbus-to-a-newer-version","text":"See our upgrading guide .","title":"How to upgrade Nimbus to a newer version?"},{"location":"faq.html#why-are-metrics-not-working","text":"The metrics server is disabled by default. Enable it by passing --metrics to the run command: build/nimbus_beacon_node --metrics ...","title":"Why are metrics not working?"},{"location":"faq.html#why-is-the-rest-server-not-working","text":"The REST server is disabled by default. Enable it by passing --rest to the run command: build/nimbus_beacon_node --rest ...","title":"Why is the REST server not working?"},{"location":"faq.html#why-does-my-validator-miss-two-epochs-of-attestations-after-restarting","text":"When a validator is started (or restarted), it listens for 2 epochs for attestations from a validator with the same public key (a doppelganger), before sending an attestation itself. This is a simple way of handling the case where one validator comes online with the same key as another validator that's already online, e.g. one device was started without switching the other off. While this strategy requires the client to wait two whole epochs on restart before attesting, a couple of missed attestations is a very minor price to pay in exchange for significantly reducing the risk of an accidental slashing. You can think of it as a small penalty that you pay only on first launch and restarts. When you take into account the total runtime of your validator, the impact should be minimal. While we strongly recommend against it, you can disable doppelganger detection with an explicit flag ( --doppelganger-detection=false ) if you don't plan on moving your setup.","title":"Why does my validator miss two epochs of attestations after (re)starting?"},{"location":"faq.html#what-is-the-best-way-to-stress-test-my-executionconsensus-setup-before-committing-with-real-eth","text":"We recommend running a Nimbus beacon node on Holesky and a mainnet execution client on the same machine. This will simulate the load of running a mainnet validator. To stress test it, add --subscribe-all-subnets to the beacon node options . This simulates the maximum load that the consensus layer will put on the machine should you run 64 validators or more on it.","title":"What is the best way to stress test my execution+consensus setup before committing with real ETH?"},{"location":"faq.html#how-do-i-add-an-additional-validator","text":"See the information here .","title":"How do I add an additional validator?"},{"location":"faq.html#what-does-syncedopt-mean-in-the-slot-start-message","text":"When /opt is present in the \"Slot start\" message, it means the node is optimistically synced and is waiting for the execution client to finish its syncing process. Until that happens, validator duties are disabled.","title":"What does synced/opt mean, in the \"Slot start\" message?"},{"location":"faq.html#syncing-is-very-slow-can-this-be-sped-up","text":"A complete sync might take several hours or even days. We recommend you to do a trusted node sync , which takes only few minutes.","title":"Syncing is very slow, can this be sped up?"},{"location":"faq.html#how-can-i-automate-running-my-beacon-node","text":"You can set up a systemd service. See our systemd guide .","title":"How can I automate running my beacon node?"},{"location":"faq.html#folder-permissions","text":"To protect against key loss, Nimbus requires that files and directories be owned by the user running the application. Furthermore, they should not be readable by others. It may happen that the wrong permissions are applied, particularly when creating the directories manually. The following errors are a sign of this: Data folder has insecure ACL Data directory has insecure permissions File has insecure permissions See the data directory page for instructions on how to fix this.","title":"Folder Permissions"},{"location":"faq.html#networking","text":"","title":"Networking"},{"location":"faq.html#how-can-i-improve-my-peer-count","text":"See the networking guide .","title":"How can I improve my peer count?"},{"location":"faq.html#how-do-i-fix-the-discovered-new-external-address-warning-log","text":"WRN 2021-03-15 02:23:37.569+00:00 Discovered new external address but ENR auto update is off topics=\"discv5\"... It's possible that your ISP has changed your dynamic IP address without you knowing. The first thing to do it to try relaunching the beacon node with --enr-auto-update (pass it as an option in the command line). If this doesn't fix the problem, the next thing to do is to check your external (public) IP address and detect open ports on your connection: you can use https://www.yougetsignal.com/tools/open-ports/ . Note that Nimbus TCP and UDP ports are both set to 9000 by default. See here for how to set up port forwarding.","title":"How do I fix the discovered new external address warning log?"},{"location":"faq.html#validating","text":"","title":"Validating"},{"location":"faq.html#what-exactly-is-a-validator","text":"A validator is an entity that participates in the consensus of the Ethereum protocol, and has staked 32 ETH to do so. Or, in plain English, a human running a computer process. This process proposes and vouches for new blocks to be added to the blockchain. In other words, you can think of a validator as a voter for new blocks. The more votes a block gets, the more likely it is to be added to the chain. Importantly, a validator's vote is weighted by the amount it has at stake.","title":"What exactly is a validator?"},{"location":"faq.html#do-i-need-a-separate-validator-client","text":"No, Nimbus doesn't require setting up a separate validator client process \u2014 the beacon node can itself perform validator duties.","title":"Do I need a separate validator client?"},{"location":"faq.html#what-is-a-deposit-contract","text":"You can think of it as a transfer of funds between Ethereum 1.0 accounts and Ethereum 2.0 validators. It specifies who is staking, who is validating, how much is being staked, and who can withdraw the funds.","title":"What is a deposit contract?"},{"location":"faq.html#why-do-validators-need-to-have-funds-at-stake","text":"Validators need to have funds at stake so they can be penalized for behaving dishonestly. In other words: to keep them honest, their actions need to have financial consequences.","title":"Why do validators need to have funds at stake?"},{"location":"faq.html#how-much-eth-does-a-validator-need-to-stake","text":"Before a validator can start to secure the network, they need to stake 32 ETH . This forms the validator's initial balance.","title":"How much ETH does a validator need to stake?"},{"location":"faq.html#is-there-any-advantage-to-having-more-than-32-eth-at-stake","text":"No, there is no advantage to having more than 32 ETH staked. Limiting the maximum stake to 32 ETH encourages decentralization of power as it prevents any single validator from having an excessively large vote on the state of the chain. Remember that a validator\u2019s vote is weighted by the amount it has at stake.","title":"Is there any advantage to having more than 32 ETH at stake?"},{"location":"faq.html#can-i-stop-my-validator-for-a-few-days-and-then-start-it-back-up-again","text":"You can, but, under normal conditions, you will lose an amount of ETH roughly equivalent to the amount of ETH you would have gained in that period. In other words, if you stood to earn \u22480.01 ETH, you would instead be penalized \u22480.01 ETH.","title":"Can I stop my validator for a few days and then start it back up again?"},{"location":"faq.html#how-can-i-keep-track-of-my-validator","text":"One way of keeping track is using an online service such as beaconcha.in: Mainnet or Holesky . Another way is to set up validator monitoring together with a dashboard to keep track of its performance.","title":"How can I keep track of my validator?"},{"location":"faq.html#i-want-to-switch-my-validator-keys-to-another-machine-how-long-do-i-need-to-wait-to-avoid-getting-slashed","text":"We recommend waiting 2 epochs (around 15 minutes), before restarting Nimbus on a different machine.","title":"I want to switch my validator keys to another machine, how long do I need to wait to avoid getting slashed?"},{"location":"faq.html#when-should-i-top-up-my-validators-balance","text":"The answer to this question very much depends on how much ETH you have at your disposal. You should certainly top up if your balance is close to 16 ETH: this is to ensure you don't get removed from the validator set (which automatically happens if your balance falls below 16 ETH). At the other end of the spectrum, if your balance is closer to 31 ETH, it's probably not worth your while adding the extra ETH required to get back to 32.","title":"When should I top up my validator's balance?"},{"location":"faq.html#when-can-i-withdraw-my-funds-and-whats-the-difference-between-exiting-and-withdrawing","text":"After the Capella hard-fork, activated on 12th of April 2023, all exited validators that use 0x01 withdrawal credentials will have their funds automatically withdrawn. Please see our dedicated guide for withdrawals for further information.","title":"When can I withdraw my funds, and what's the difference between exiting and withdrawing?"},{"location":"faq.html#how-are-validators-incentivized-to-stay-active-and-honest","text":"In addition to being penalized for being offline, validators are penalized for behaving maliciously (for example, attesting to invalid or contradicting blocks). On the other hand, they are rewarded for proposing / attesting to blocks that are included in the chain. The key concept is the following: Rewards are given for actions that help the network reach consensus. Minor penalties are given for inadvertent actions (or inactions) that hinder consensus. And major penalties \u2014 or slashings \u2014 are given for malicious actions. In other words, validators that maximize their rewards also provide the greatest benefit to the network as a whole.","title":"How are validators incentivized to stay active and honest?"},{"location":"faq.html#how-are-rewardspenalties-issued","text":"Remember that each validator has its own balance, with the initial balance outlined in the deposit contract. This balance is updated periodically by the Ethereum network rules as the validator carries (or fails to carry) out his or her responsibilities. Put another way, rewards and penalties are reflected in the validator's balance over time.","title":"How are rewards/penalties issued?"},{"location":"faq.html#how-often-are-rewardspenalties-issued","text":"Approximately every six and a half minutes \u2014 a period of time known as an epoch. Every epoch, the network measures the actions of each validator and issues rewards or penalties appropriately.","title":"How often are rewards/penalties issued?"},{"location":"faq.html#how-large-are-the-rewardspenalties","text":"There is no easy answer to this question as there are many factors that go into this calculation. Arguably the most impactful factor on rewards earned for validating transactions is the total amount of stake in the network. In other words, the total amount of validators. Depending on this figure the max annual return rate for a validator can be anywhere between 2 and 20%. Given a fixed total number of validators, the rewards/penalties predominantly scale with the balance of the validator: attesting with a higher balance results in larger rewards/penalties whereas attesting with a lower balance results in lower rewards/penalties. Note however that this scaling mechanism works in a non-obvious way. To understand the precise details of how it works requires understanding a concept called effective balance . If you're not yet familiar with this concept, we recommend you read through this excellent post .","title":"How large are the rewards/penalties?"},{"location":"faq.html#why-do-rewards-depend-on-the-total-number-of-validators-in-the-network","text":"Block rewards are calculated using a sliding scale based on the total amount of ETH staked on the network. In plain English: if the total amount of ETH staked is low, the reward (interest rate) is high, but as the total stake rises, the reward (interest) paid out to each validator starts to fall. Why a sliding scale? While we won't get into the gory details here, the basic intuition is that there needs to be a minimum number of validators (and hence a minimum amount of ETH staked) for the network to function properly. So, to incentivize more validators to join, it's important that the interest rate remains high until this minimum number is reached. Afterwards, validators are still encouraged to join (the more validators the more decentralized the network), but it's not absolutely essential that they do so (so the interest rate can fall).","title":"Why do rewards depend on the total number of validators in the network?"},{"location":"faq.html#how-badly-will-a-validator-be-penalized-for-being-offline","text":"It depends. In addition to the impact of effective balance , there are two important scenarios to be aware of: Being offline while a supermajority (2/3) of validators is still online leads to relatively small penalties as there are still enough validators online for the chain to finalize. This is the expected scenario. Being offline at the same time as more than 1/3 of the total number of validators leads to harsher penalties, since blocks do not finalize anymore. This scenario is very extreme and unlikely to happen. Note that in the second (unlikely) scenario, validators stand to progressively lose up to 50% (16 ETH) of their stake over 21 days. After 21 days they are ejected out of the validator pool. This ensures that blocks start finalizing again at some point.","title":"How badly will a validator be penalized for being offline?"},{"location":"faq.html#how-great-does-an-honest-validators-uptime-need-to-be-for-it-to-be-net-profitable","text":"Overall, validators are expected to be net profitable as long as their uptime is greater than 50% . This means that validators don't need to go to extreme lengths with backup clients or redundant internet connections as the repercussions of being offline are not so severe.","title":"How great does an honest validator's uptime need to be for it to be net profitable?"},{"location":"faq.html#how-much-will-a-validator-be-penalized-for-acting-maliciously","text":"Again, it depends. Behaving maliciously, e.g. attesting to invalid or contradicting blocks, will lead to a validator's stake being slashed. If a malicious behavior is detected, 1/32 of validator's staked ether (up to a maximum of 1 ETH) is immediately slashed and a 36-day removal period begins. During this period, the validator's stake is gradually slashed and at day 18 an additional penalty is applied: the amount depends on the number of other slashed validators \u2014 the more validators are slashed, the magnitude of the slash increases. The idea behind this is to minimize the losses from honest mistakes, but strongly discouraging coordinated attacks.","title":"How much will a validator be penalized for acting maliciously?"},{"location":"faq.html#what-exactly-is-slashing","text":"Slashing has two purposes: to make it prohibitively expensive to attack eth2, and to stop validators from being lazy by checking that they actually perform their duties. Slashing a validator is to destroy (a portion of) the validator\u2019s stake if they act in a provably destructive manner. Validators that are slashed are prevented from participating in the protocol further and are forcibly exited.","title":"What exactly is slashing?"},{"location":"faq.html#what-happens-i-lose-my-signing-key","text":"If the signing key is lost, the validator can no longer propose or attest. However, all is not lost. Assuming validators derive their keys using EIP2334 (as per the default onboarding flow) then validators can always recalculate their signing key from their withdrawal key .","title":"What happens I lose my signing key?"},{"location":"faq.html#what-happens-if-i-lose-my-withdrawal-key","text":"If the withdrawal key is lost, there is no way to obtain access to the funds held by the validator. As such, it's a good idea to create your keys from mnemonics which act as another backup. This will be the default for validators who join via this site's onboarding process. If the validator can no longer propose or attest, their balance will decrease over time as they are punished for not participating in the consensus process. When the validator's balance reaches 16 ETH, they will be automatically exited from the validator pool, and 16 ETH will be transferred to their withdrawal address (as long it's specified). Note After the Capella hard-fork, activated on 12th of April 2023, all exited validators that use 0x01 withdrawal credentials will have their funds automatically withdrawn. Please see our dedicated guide for withdrawals for further information.","title":"What happens if I lose my withdrawal key?"},{"location":"faq.html#what-happens-if-my-withdrawal-key-is-stolen","text":"If the withdrawal key is stolen, the thief can transfer the validator\u2019s balance, but only once the validator has exited. If the signing key is not under the thief\u2019s control, the thief cannot exit the validator. The user with the signing key could attempt to quickly exit the validator and then transfer the funds \u2014 with the withdrawal key \u2014 before the thief.","title":"What happens if my withdrawal key is stolen?"},{"location":"faq.html#why-two-keys-instead-of-one","text":"In a nutshell, security. The signing key must be available at all times. As such, it will need to be held online. Since anything online is vulnerable to being hacked, it's not a good idea to use the same key for withdrawals.","title":"Why two keys instead of one?"},{"location":"goerli-eth.html","text":"Obtain Goerli ETH To participate in an eth2 testnet, you need to stake 32 testnet ETH. You can request this testnet ETH by joining the ethstaker discord - look for the #request-goerli-eth channel.","title":"Obtain Goerli ETH"},{"location":"goerli-eth.html#obtain-goerli-eth","text":"To participate in an eth2 testnet, you need to stake 32 testnet ETH. You can request this testnet ETH by joining the ethstaker discord - look for the #request-goerli-eth channel.","title":"Obtain Goerli ETH"},{"location":"graffiti.html","text":"Set up Graffiti You can use your node's graffiti flag to include a short text in the blocks that your node creates. You will be able to see it using the block explorer. The graffiti can be either a string or, if you want to specify raw bytes, you can use 0x-prefixed hex value. Command line Mainnet Holesky ./run-mainnet-beacon-node.sh --graffiti = \"<YOUR_WORDS>\" ./run-holesky-beacon-node.sh --graffiti = \"<YOUR_WORDS>\"","title":"Set up Graffiti"},{"location":"graffiti.html#set-up-graffiti","text":"You can use your node's graffiti flag to include a short text in the blocks that your node creates. You will be able to see it using the block explorer. The graffiti can be either a string or, if you want to specify raw bytes, you can use 0x-prefixed hex value.","title":"Set up Graffiti"},{"location":"graffiti.html#command-line","text":"Mainnet Holesky ./run-mainnet-beacon-node.sh --graffiti = \"<YOUR_WORDS>\" ./run-holesky-beacon-node.sh --graffiti = \"<YOUR_WORDS>\"","title":"Command line"},{"location":"hardware.html","text":"System requirements The recommended system requirements for running the Nimbus beacon node are: What Recommended Operating system Linux 64-bit , Windows 64-bit, macOS 11+ Memory 4GB (running) or 8GB (building) Disk space 200GB Network Reliable broadband Note While the consensus client will work with a classic, spinning, hard disks, if you plan to run an execution client make sure you use an SSD, either SATA or NVMe. Execution client In addition to the beacon node, you will need to run an execution client . Check the documentation of the client of choice and add them to the above requirements. Broadly, to run both an execution and a consensus client on the same machine, we recommend a 2 TB SSD and 16 GB RAM . Minimal requirements Nimbus has been optimized to also run well on hardware significantly less powerful than the recommended system requirements \u2014 the more validators you run on the same node, the more hardware resources and network bandwidth will it will use.","title":"System requirements"},{"location":"hardware.html#system-requirements","text":"The recommended system requirements for running the Nimbus beacon node are: What Recommended Operating system Linux 64-bit , Windows 64-bit, macOS 11+ Memory 4GB (running) or 8GB (building) Disk space 200GB Network Reliable broadband Note While the consensus client will work with a classic, spinning, hard disks, if you plan to run an execution client make sure you use an SSD, either SATA or NVMe.","title":"System requirements"},{"location":"hardware.html#execution-client","text":"In addition to the beacon node, you will need to run an execution client . Check the documentation of the client of choice and add them to the above requirements. Broadly, to run both an execution and a consensus client on the same machine, we recommend a 2 TB SSD and 16 GB RAM .","title":"Execution client"},{"location":"hardware.html#minimal-requirements","text":"Nimbus has been optimized to also run well on hardware significantly less powerful than the recommended system requirements \u2014 the more validators you run on the same node, the more hardware resources and network bandwidth will it will use.","title":"Minimal requirements"},{"location":"health.html","text":"Monitor the health of your node The most important thing for the health, performance and stability of your node and the overall network is the strength of your node's network connectivity / peer count. See here for our networking related tips and tricks. Keep track of your attestation effectiveness Attestation effectiveness is a metric that directly affects your validator rewards. The interval between a validator performing its duty and an attestation is called the inclusion distance of an attestation. As long as your validator is within the allowed inclusion distance, you will get the full reward. You can verify your validator's effectiveness on the beaconcha.in website. Ideally you want to see a value above 95%. While attestation effectiveness depends on a variety of factors \u2014 attestation network propagation, your network connectivity, and the peers you are connected to \u2014 your network connectivity is likely the most important factors you can control to improve this metric. Apart from the tips outlined on this guide, you could also experiment with subscribing to all subnets . Monitor your system's network I/O usage If you're a Linux user and want to track how much network I/O your system uses over time, you can install a nice utility called vnstat . To install, run: sudo apt install vnstat To run it: TBC - See here for more info","title":"Monitor the health of your node"},{"location":"health.html#monitor-the-health-of-your-node","text":"The most important thing for the health, performance and stability of your node and the overall network is the strength of your node's network connectivity / peer count. See here for our networking related tips and tricks.","title":"Monitor the health of your node"},{"location":"health.html#keep-track-of-your-attestation-effectiveness","text":"Attestation effectiveness is a metric that directly affects your validator rewards. The interval between a validator performing its duty and an attestation is called the inclusion distance of an attestation. As long as your validator is within the allowed inclusion distance, you will get the full reward. You can verify your validator's effectiveness on the beaconcha.in website. Ideally you want to see a value above 95%. While attestation effectiveness depends on a variety of factors \u2014 attestation network propagation, your network connectivity, and the peers you are connected to \u2014 your network connectivity is likely the most important factors you can control to improve this metric. Apart from the tips outlined on this guide, you could also experiment with subscribing to all subnets .","title":"Keep track of your attestation effectiveness"},{"location":"health.html#monitor-your-systems-network-io-usage","text":"If you're a Linux user and want to track how much network I/O your system uses over time, you can install a nice utility called vnstat . To install, run: sudo apt install vnstat To run it: TBC - See here for more info","title":"Monitor your system's network I/O usage"},{"location":"history.html","text":"Historical data This feature is available from Nimbus v23.1.0 onwards. Ethereum consensus nodes are required to keep a minimum of 5 months of historical block data ensuring the health of the network. Nimbus can be configured to either retain or remove historical data past that point using the --history option. By default, Nimbus prunes historical data. EIP-4844 blob archival In the default prune mode, EIP-4844 blobs are retained for ~18 days. To retain blobs beyond that, enable --history=archive which also archives blob data in the Nimbus database. Future versions of Nimbus will allow exporting retained blobs to erb files. History modes The history mode controls how far back Nimbus supports answering historical queries in the REST API . It does not affect the ability to perform validator duties. In prune mode, blocks and states past that point are removed from the database continuously and the freed space is reused for more recent data. Database size Although blocks and states are pruned, the database will not shrink in size: instead, the freed space is reused for new data. In archive mode, queries can be as far back as the state that the database was created with \u2014 the checkpoint state in the case of trusted node sync or genesis. Switching between modes It is possible to switch between prune and archive modes. When switching to prune mode, deep history will be removed from the database and the prune point will be updated continuously as usual. As noted above, the database will not shrink in size. To reclaim space, perform a trusted node sync using a fresh database. When switching to archive mode, the node will start keeping history from the most recent prune point, but will not recreate deep history. In order to recreate deep history in a pruned node, download the era archive of deep history and reindex the database \u2014 this operation may take several hours. Command line Mainnet Holesky ./run-mainnet-beacon-node.sh --history = prune ... ./run-holesky-beacon-node.sh --history = prune ...","title":"Historical data"},{"location":"history.html#historical-data","text":"This feature is available from Nimbus v23.1.0 onwards. Ethereum consensus nodes are required to keep a minimum of 5 months of historical block data ensuring the health of the network. Nimbus can be configured to either retain or remove historical data past that point using the --history option. By default, Nimbus prunes historical data. EIP-4844 blob archival In the default prune mode, EIP-4844 blobs are retained for ~18 days. To retain blobs beyond that, enable --history=archive which also archives blob data in the Nimbus database. Future versions of Nimbus will allow exporting retained blobs to erb files.","title":"Historical data"},{"location":"history.html#history-modes","text":"The history mode controls how far back Nimbus supports answering historical queries in the REST API . It does not affect the ability to perform validator duties. In prune mode, blocks and states past that point are removed from the database continuously and the freed space is reused for more recent data. Database size Although blocks and states are pruned, the database will not shrink in size: instead, the freed space is reused for new data. In archive mode, queries can be as far back as the state that the database was created with \u2014 the checkpoint state in the case of trusted node sync or genesis.","title":"History modes"},{"location":"history.html#switching-between-modes","text":"It is possible to switch between prune and archive modes. When switching to prune mode, deep history will be removed from the database and the prune point will be updated continuously as usual. As noted above, the database will not shrink in size. To reclaim space, perform a trusted node sync using a fresh database. When switching to archive mode, the node will start keeping history from the most recent prune point, but will not recreate deep history. In order to recreate deep history in a pruned node, download the era archive of deep history and reindex the database \u2014 this operation may take several hours.","title":"Switching between modes"},{"location":"history.html#command-line","text":"Mainnet Holesky ./run-mainnet-beacon-node.sh --history = prune ... ./run-holesky-beacon-node.sh --history = prune ...","title":"Command line"},{"location":"holesky.html","text":"Hole\u0161ky testnet holesky is the main long-running Ethereum staking, infrastructure and protocol-developer testnet. For testing decentralized applications, smart contracts, and other EVM functionality, please use Sepolia testnet! holesky replaces the Prater/G\u00f6rli network which has been deprecated since early 2023. It provides an opportunity to verify your setup works as expected through the proof-of-stake transition and in a post-merge context as well as to safely practice node operations such as adding and removing validators, migrating between clients, and performing upgrades and backups. If you come across any issues, please report them here . General Preparation Generate the JWT secret with openssl rand -hex 32 | tr -d \"\\n\" > \"/opt/jwtsecret\" . This file needs to be passed to both the execution client and the consensus client. Choose an Ethereum address to receive transaction fees. This ETH will be immediately available, not part of the staking contract. Download the latest release and install it by unpacking the archive. Choose one of Nethermind, Besu, Erigon, or Geth as an execution client. Download, install, and run it . Nethermind Erigon Besu cd nethermind/src/Nethermind/Nethermind.Runner dotnet run -c Release -- --config holesky \\ --JsonRpc.Host = 0 .0.0.0 \\ --JsonRpc.JwtSecretFile = /opt/jwtsecret ./build/bin/erigon --chain = holesky \\ --datadir holesky-testnet \\ --authrpc.jwtsecret = /opt/jwtsecret \\ --http --http.api = engine,net,eth build/install/besu/bin/besu \\ --network = holesky \\ --rpc-http-enabled = true \\ --rpc-http-host = \"0.0.0.0\" \\ --rpc-http-cors-origins = \"*\" \\ --sync-mode = \"X_SNAP\" \\ --data-storage-format = \"BONSAI\" \\ --Xmerge-support = true \\ --rpc-ws-host = \"0.0.0.0\" \\ --host-allowlist = \"*\" \\ --engine-rpc-enabled = true \\ --engine-host-allowlist = \"*\" \\ --engine-jwt-enabled = true \\ --engine-jwt-secret = /opt/jwtsecret Sync the beacon node and execution client Start syncing the node consisting of Nimbus and chosen execution client, for example by running: nimbus-eth2/build/nimbus_beacon_node \\ --network = holesky \\ --web3-url = http://127.0.0.1:8551 \\ --rest \\ --metrics \\ --jwt-secret = \"/opt/jwtsecret\" \\ --suggested-fee-recipient = <Enter-eth-address-here> Tip If you want the syncing process to complete much faster, you can sync from a trusted node . One might consider here to set up a systemd service to ensure this runs automatically, including after restarts. Obtaining genesis file (optional) By default, Nimbus will automatically download the genesis state of Hole\u0161ky from Github through the HTTPS protocol. If something prevents you from using this method, you may be able to work-around the issue by either instructing Nimbus to use a different URL by specifying the --genesis-state-url command-line parameter (for example, you can point it to the /eth/v2/debug/beacon/states/genesis endpoint of a trusted beacon node or a checkpoint provider) or by downloading the genesis.ssz file of the network through some other means and then supplying its path through the --genesis-state command-line parameter. Begin validating Once this Hole\u0161ky node is completely synced , use the Holesky launchpad to obtain Holesky validators. It might require some time before these enter and are activated on the beacon chain. If one does this before the node which will attest and propose using those validators has synced, one might miss attestations and block proposals. Follow our validating guide from step 2 (import the validator keys) onward . Useful resources Holesky landing page : view block explorers, request funds from the faucet, and connect to a JSON RPC endpoint. Holesky EF launchpad notes : how to run a node; contains instructions for how to build Nimbus from source for this purpose Holesky consensus layer beacon chain explorer Holesky execution layer transaction explorer","title":"Hole\u0161ky testnet"},{"location":"holesky.html#holesky-testnet","text":"holesky is the main long-running Ethereum staking, infrastructure and protocol-developer testnet. For testing decentralized applications, smart contracts, and other EVM functionality, please use Sepolia testnet! holesky replaces the Prater/G\u00f6rli network which has been deprecated since early 2023. It provides an opportunity to verify your setup works as expected through the proof-of-stake transition and in a post-merge context as well as to safely practice node operations such as adding and removing validators, migrating between clients, and performing upgrades and backups. If you come across any issues, please report them here .","title":"Hole\u0161ky testnet"},{"location":"holesky.html#general-preparation","text":"Generate the JWT secret with openssl rand -hex 32 | tr -d \"\\n\" > \"/opt/jwtsecret\" . This file needs to be passed to both the execution client and the consensus client. Choose an Ethereum address to receive transaction fees. This ETH will be immediately available, not part of the staking contract. Download the latest release and install it by unpacking the archive. Choose one of Nethermind, Besu, Erigon, or Geth as an execution client. Download, install, and run it . Nethermind Erigon Besu cd nethermind/src/Nethermind/Nethermind.Runner dotnet run -c Release -- --config holesky \\ --JsonRpc.Host = 0 .0.0.0 \\ --JsonRpc.JwtSecretFile = /opt/jwtsecret ./build/bin/erigon --chain = holesky \\ --datadir holesky-testnet \\ --authrpc.jwtsecret = /opt/jwtsecret \\ --http --http.api = engine,net,eth build/install/besu/bin/besu \\ --network = holesky \\ --rpc-http-enabled = true \\ --rpc-http-host = \"0.0.0.0\" \\ --rpc-http-cors-origins = \"*\" \\ --sync-mode = \"X_SNAP\" \\ --data-storage-format = \"BONSAI\" \\ --Xmerge-support = true \\ --rpc-ws-host = \"0.0.0.0\" \\ --host-allowlist = \"*\" \\ --engine-rpc-enabled = true \\ --engine-host-allowlist = \"*\" \\ --engine-jwt-enabled = true \\ --engine-jwt-secret = /opt/jwtsecret","title":"General Preparation"},{"location":"holesky.html#sync-the-beacon-node-and-execution-client","text":"Start syncing the node consisting of Nimbus and chosen execution client, for example by running: nimbus-eth2/build/nimbus_beacon_node \\ --network = holesky \\ --web3-url = http://127.0.0.1:8551 \\ --rest \\ --metrics \\ --jwt-secret = \"/opt/jwtsecret\" \\ --suggested-fee-recipient = <Enter-eth-address-here> Tip If you want the syncing process to complete much faster, you can sync from a trusted node . One might consider here to set up a systemd service to ensure this runs automatically, including after restarts.","title":"Sync the beacon node and execution client"},{"location":"holesky.html#obtaining-genesis-file-optional","text":"By default, Nimbus will automatically download the genesis state of Hole\u0161ky from Github through the HTTPS protocol. If something prevents you from using this method, you may be able to work-around the issue by either instructing Nimbus to use a different URL by specifying the --genesis-state-url command-line parameter (for example, you can point it to the /eth/v2/debug/beacon/states/genesis endpoint of a trusted beacon node or a checkpoint provider) or by downloading the genesis.ssz file of the network through some other means and then supplying its path through the --genesis-state command-line parameter.","title":"Obtaining genesis file (optional)"},{"location":"holesky.html#begin-validating","text":"Once this Hole\u0161ky node is completely synced , use the Holesky launchpad to obtain Holesky validators. It might require some time before these enter and are activated on the beacon chain. If one does this before the node which will attest and propose using those validators has synced, one might miss attestations and block proposals. Follow our validating guide from step 2 (import the validator keys) onward .","title":"Begin validating"},{"location":"holesky.html#useful-resources","text":"Holesky landing page : view block explorers, request funds from the faucet, and connect to a JSON RPC endpoint. Holesky EF launchpad notes : how to run a node; contains instructions for how to build Nimbus from source for this purpose Holesky consensus layer beacon chain explorer Holesky execution layer transaction explorer","title":"Useful resources"},{"location":"infura-guide.html","text":"This page has been removed - following the merge it is no longer possible to use Infura for validation duties.","title":"Infura guide"},{"location":"install.html","text":"Prepare your machine The Nimbus beacon node runs on Linux, macOS, Windows, and Android. System requirements Check that your machine matches the minimal system requirements . Build prerequisites Tip If you are planning to use the precompiled binaries, you can skip this section and go straight to the binaries ! When building from source, you will need additional build dependencies to be installed: Developer tools (C compiler, Make, Bash, Git) CMake Linux macOS Windows Android On common Linux distributions the dependencies can be installed with: # Debian and Ubuntu sudo apt-get install build-essential git-lfs cmake # Fedora dnf install @development-tools cmake # Arch Linux, using an AUR manager yourAURmanager -S base-devel cmake With Homebrew : brew install cmake To build Nimbus on Windows, the MinGW-w64 build environment is recommended. Install Mingw-w64 for your architecture using the \" MinGW-W64 Online Installer \": Select your architecture in the setup menu ( i686 on 32-bit, x86_64 on 64-bit). Set threads to win32 . Set exceptions to \"dwarf\" on 32-bit and \"seh\" on 64-bit. Change the installation directory to C:\\mingw-w64 and add it to your system PATH in \"My Computer\"/\"This PC\" -> Properties -> Advanced system settings -> Environment Variables -> Path -> Edit -> New -> C:\\mingw-w64\\mingw64\\bin ( C:\\mingw-w64\\mingw32\\bin on 32-bit). Note If the online installer isn't working you can try installing mingw-w64 through MSYS2 . Install Git for Windows and use a \"Git Bash\" shell to clone and build nimbus-eth2 . Install the Termux app from FDroid or the Google Play store Install a PRoot of your choice following the instructions for your preferred distribution. Note, the Ubuntu PRoot is known to contain all Nimbus prerequisites compiled on Arm64 architecture (the most common architecture for Android devices). Assuming you use Ubuntu PRoot: apt install build-essential git-lfs Time The beacon chain relies on your computer having the correct time set (\u00b10.5 seconds). It is important that you periodically synchronize the time with an NTP server. If the above sounds like Latin to you, don't worry. You should be fine as long as you haven't changed the time and date settings on your computer (they should be set automatically). Linux Windows, macOS On Linux, it is recommended to install chrony . To install it: # Debian and Ubuntu sudo apt-get install -y chrony # Fedora sudo dnf install chrony # Archlinux, using an AUR manager yourAURmanager chrony Make sure that the options for setting time automatically are enabled.","title":"Prepare your machine"},{"location":"install.html#prepare-your-machine","text":"The Nimbus beacon node runs on Linux, macOS, Windows, and Android.","title":"Prepare your machine"},{"location":"install.html#system-requirements","text":"Check that your machine matches the minimal system requirements .","title":"System requirements"},{"location":"install.html#build-prerequisites","text":"Tip If you are planning to use the precompiled binaries, you can skip this section and go straight to the binaries ! When building from source, you will need additional build dependencies to be installed: Developer tools (C compiler, Make, Bash, Git) CMake Linux macOS Windows Android On common Linux distributions the dependencies can be installed with: # Debian and Ubuntu sudo apt-get install build-essential git-lfs cmake # Fedora dnf install @development-tools cmake # Arch Linux, using an AUR manager yourAURmanager -S base-devel cmake With Homebrew : brew install cmake To build Nimbus on Windows, the MinGW-w64 build environment is recommended. Install Mingw-w64 for your architecture using the \" MinGW-W64 Online Installer \": Select your architecture in the setup menu ( i686 on 32-bit, x86_64 on 64-bit). Set threads to win32 . Set exceptions to \"dwarf\" on 32-bit and \"seh\" on 64-bit. Change the installation directory to C:\\mingw-w64 and add it to your system PATH in \"My Computer\"/\"This PC\" -> Properties -> Advanced system settings -> Environment Variables -> Path -> Edit -> New -> C:\\mingw-w64\\mingw64\\bin ( C:\\mingw-w64\\mingw32\\bin on 32-bit). Note If the online installer isn't working you can try installing mingw-w64 through MSYS2 . Install Git for Windows and use a \"Git Bash\" shell to clone and build nimbus-eth2 . Install the Termux app from FDroid or the Google Play store Install a PRoot of your choice following the instructions for your preferred distribution. Note, the Ubuntu PRoot is known to contain all Nimbus prerequisites compiled on Arm64 architecture (the most common architecture for Android devices). Assuming you use Ubuntu PRoot: apt install build-essential git-lfs","title":"Build prerequisites"},{"location":"install.html#time","text":"The beacon chain relies on your computer having the correct time set (\u00b10.5 seconds). It is important that you periodically synchronize the time with an NTP server. If the above sounds like Latin to you, don't worry. You should be fine as long as you haven't changed the time and date settings on your computer (they should be set automatically). Linux Windows, macOS On Linux, it is recommended to install chrony . To install it: # Debian and Ubuntu sudo apt-get install -y chrony # Fedora sudo dnf install chrony # Archlinux, using an AUR manager yourAURmanager chrony Make sure that the options for setting time automatically are enabled.","title":"Time"},{"location":"intro.html","text":"Moved","title":"Intro"},{"location":"keep-an-eye.html","text":"Keep an eye on your validator Once your validator has been activated, you can set up validator monitoring together with a dashboard to keep track of its performance. Another way of keeping track is using an online service such as beaconcha.in: Mainnet or Holesky . Both online services and dashboards allow setting up alerts for when the validator is offline. Troubleshooting Make sure your validator is attached On startup, you should see a log message that reads Local validator attached . This has a pubkey field which should be the public key of your validator. Keep track of your syncing progress To keep track of your sync progress, pay attention to the Slot start messages in your logs: INF 2022-06-16 13:23:11.008+02:00 Slot start topics=\"beacnde\" slot=4046214 epoch=126444 sync=\"00h37m (99.38%) 11.0476slots/s (DDQQDDDPDD:4021215)\" peers=55 head=5d59aba3:4021234 finalized=125661:82616f78 delay=8ms245us608ns Where: slot is the current time on the beacon chain, measured in \"slots\" epoch shows the current epoch: each epoch has 32 slots, and each validator performs one attestation per epoch peers tells you how many peers you're currently connected to: depending on the number of attached validators, you may need anywhere from 10 to 60 peers connected sync tells you if your client is synced and can perform duties, or how long it will take to get there /opt means that the node is optimistically synced : it is waiting for the execution client to finish syncing in the case of trusted node sync it may also show backfill in which case duties are being performed but more bandwidth than usual is being used to download historical blocks head tells you the most recent block you've synced to so far ( 5d59aba3 is the first part of the block hash, 4021234 is the slot number) finalized tells you the most recent finalized epoch you've synced to so far ( 125661 is the epoch, 82616f78 is the checkpoint hash) The string of letters -- what we call the sync worker map (in the above case represented by DDQQDDDPDD ) represents the peers you are syncing from, where: s - sleeping (idle), w - waiting for a peer from PeerPool, R - requesting blocks from peer D - downloading blocks from peer Q - queued/waiting for ancestor blocks P - processing/verifying blocks U - updating peer's status information Tip You can also use you calls outlined in the REST API page to retrieve similar information.","title":"Keep an eye on your validator"},{"location":"keep-an-eye.html#keep-an-eye-on-your-validator","text":"Once your validator has been activated, you can set up validator monitoring together with a dashboard to keep track of its performance. Another way of keeping track is using an online service such as beaconcha.in: Mainnet or Holesky . Both online services and dashboards allow setting up alerts for when the validator is offline.","title":"Keep an eye on your validator"},{"location":"keep-an-eye.html#troubleshooting","text":"","title":"Troubleshooting"},{"location":"keep-an-eye.html#make-sure-your-validator-is-attached","text":"On startup, you should see a log message that reads Local validator attached . This has a pubkey field which should be the public key of your validator.","title":"Make sure your validator is attached"},{"location":"keep-an-eye.html#keep-track-of-your-syncing-progress","text":"To keep track of your sync progress, pay attention to the Slot start messages in your logs: INF 2022-06-16 13:23:11.008+02:00 Slot start topics=\"beacnde\" slot=4046214 epoch=126444 sync=\"00h37m (99.38%) 11.0476slots/s (DDQQDDDPDD:4021215)\" peers=55 head=5d59aba3:4021234 finalized=125661:82616f78 delay=8ms245us608ns Where: slot is the current time on the beacon chain, measured in \"slots\" epoch shows the current epoch: each epoch has 32 slots, and each validator performs one attestation per epoch peers tells you how many peers you're currently connected to: depending on the number of attached validators, you may need anywhere from 10 to 60 peers connected sync tells you if your client is synced and can perform duties, or how long it will take to get there /opt means that the node is optimistically synced : it is waiting for the execution client to finish syncing in the case of trusted node sync it may also show backfill in which case duties are being performed but more bandwidth than usual is being used to download historical blocks head tells you the most recent block you've synced to so far ( 5d59aba3 is the first part of the block hash, 4021234 is the slot number) finalized tells you the most recent finalized epoch you've synced to so far ( 125661 is the epoch, 82616f78 is the checkpoint hash) The string of letters -- what we call the sync worker map (in the above case represented by DDQQDDDPDD ) represents the peers you are syncing from, where: s - sleeping (idle), w - waiting for a peer from PeerPool, R - requesting blocks from peer D - downloading blocks from peer Q - queued/waiting for ancestor blocks P - processing/verifying blocks U - updating peer's status information Tip You can also use you calls outlined in the REST API page to retrieve similar information.","title":"Keep track of your syncing progress"},{"location":"keep-updated.html","text":"Upgrade / downgrade Make sure you stay on the lookout for any critical updates to Nimbus. The best way to do so is through the announcements channel on our discord . The release page can be found here . Note If your beacon node is already running, you'll need to restart it for the changes to take effect. To update to the latest version, either download the binary or compile the beacon node release (see below), then restart the service. Tip To check which version of Nimbus you're currently running, run build/nimbus_beacon_node --version Upgrade to the latest version Manual installation Debian / Ubuntu Build from source Open the Nimbus release page and download the file that corresponds to your operation system and machine. Once downloaded, unpack the binaries in the same folder as your current version, overwriting the existing files. wget <insert download link here> tar -xzf nimbus-eth2_Linux_arm64v8*.tar.gz --strip-components 1 -C nimbus-eth2 rm nimbus-eth2_Linux_arm64v8*.tar.gz Update Nimbus via the package manager as usual sudo apt-get update && sudo apt-get upgrade Upgrading Nimbus when built from source is similar to the installation process. Run: # Download the updated source code git pull && make update # Build the newly downloaded version make -j4 nimbus_beacon_node Tip If you want to minimize downtime, you can build Nimbus while the node is running! Complete the upgrade by restarting the node! Urgency guidelines Nimbus releases are marked with the following tags: low-urgency : update at your own convenience, sometime within our normal update cycle of two weeks medium-urgency : may contain an important stability fix, it is better to update sooner rather than later high-urgency : update as soon as you can, this is a critical update required for Nimbus to function correctly Install a specific version Occasionally, you may need to either upgrade or downgrade to a specific version of Nimbus. Nimbus can safely be downgraded to any version targeting the current hard fork of the chain, unless otherwise noted among the release notes. Manual installation Debian / Ubuntu Build from source Download the desired version from Github and replace the binaries, similar to upgrading. Use the package manager to install a specific version: sudo apt-get install nimbus-beacon-node = 23 .2.0 To pull a specific version of Nimbus (e.g. v22.9.1 ), run: # Switch source code to the desired version git checkout v22.9.1 && make update # Run the build command as usual make -j4 nimbus_beacon_node When later you want to go back to the stable release: # Switch source code to the stable version git checkout stable && make update # Run the build command as usual make -j4 nimbus_beacon_node Now, restart your node.","title":"Upgrade / downgrade"},{"location":"keep-updated.html#upgrade-downgrade","text":"Make sure you stay on the lookout for any critical updates to Nimbus. The best way to do so is through the announcements channel on our discord . The release page can be found here . Note If your beacon node is already running, you'll need to restart it for the changes to take effect. To update to the latest version, either download the binary or compile the beacon node release (see below), then restart the service. Tip To check which version of Nimbus you're currently running, run build/nimbus_beacon_node --version","title":"Upgrade / downgrade"},{"location":"keep-updated.html#upgrade-to-the-latest-version","text":"Manual installation Debian / Ubuntu Build from source Open the Nimbus release page and download the file that corresponds to your operation system and machine. Once downloaded, unpack the binaries in the same folder as your current version, overwriting the existing files. wget <insert download link here> tar -xzf nimbus-eth2_Linux_arm64v8*.tar.gz --strip-components 1 -C nimbus-eth2 rm nimbus-eth2_Linux_arm64v8*.tar.gz Update Nimbus via the package manager as usual sudo apt-get update && sudo apt-get upgrade Upgrading Nimbus when built from source is similar to the installation process. Run: # Download the updated source code git pull && make update # Build the newly downloaded version make -j4 nimbus_beacon_node Tip If you want to minimize downtime, you can build Nimbus while the node is running! Complete the upgrade by restarting the node!","title":"Upgrade to the latest version"},{"location":"keep-updated.html#urgency-guidelines","text":"Nimbus releases are marked with the following tags: low-urgency : update at your own convenience, sometime within our normal update cycle of two weeks medium-urgency : may contain an important stability fix, it is better to update sooner rather than later high-urgency : update as soon as you can, this is a critical update required for Nimbus to function correctly","title":"Urgency guidelines"},{"location":"keep-updated.html#install-a-specific-version","text":"Occasionally, you may need to either upgrade or downgrade to a specific version of Nimbus. Nimbus can safely be downgraded to any version targeting the current hard fork of the chain, unless otherwise noted among the release notes. Manual installation Debian / Ubuntu Build from source Download the desired version from Github and replace the binaries, similar to upgrading. Use the package manager to install a specific version: sudo apt-get install nimbus-beacon-node = 23 .2.0 To pull a specific version of Nimbus (e.g. v22.9.1 ), run: # Switch source code to the desired version git checkout v22.9.1 && make update # Run the build command as usual make -j4 nimbus_beacon_node When later you want to go back to the stable release: # Switch source code to the stable version git checkout stable && make update # Run the build command as usual make -j4 nimbus_beacon_node Now, restart your node.","title":"Install a specific version"},{"location":"keymanager-api.html","text":"Keymanager API The standardized Keymanager API can be used to add, remove, or migrate validators on the fly while the beacon node is running. Configuration By default, we disable the Keymanager API. To enable it, start the beacon node with the --keymanager option enabled: ./run-holesky-beacon-node.sh --keymanager Once the node is running, you'll be able to access the API from http://localhost:5052/ . Authorization: Bearer scheme All requests must be authorized through the Authorization: Bearer scheme with a token matching the contents of a file provided at the start of the node through the --keymanager-token-file parameter. Enabling connections from outside machines By default, only connections from the same machine are entertained. If you wish to change this you can configure the port and listening address with the --keymanager-port and --keymanager-address options respectively. Warning The Keymanager API port should only be exposed through a secure channel (e.g. HTTPS, an SSH tunnel, a VPN, etc.) Specification The specification is documented here . The README is also extremely useful and is documented here .","title":"Keymanager API"},{"location":"keymanager-api.html#keymanager-api","text":"The standardized Keymanager API can be used to add, remove, or migrate validators on the fly while the beacon node is running.","title":"Keymanager API"},{"location":"keymanager-api.html#configuration","text":"By default, we disable the Keymanager API. To enable it, start the beacon node with the --keymanager option enabled: ./run-holesky-beacon-node.sh --keymanager Once the node is running, you'll be able to access the API from http://localhost:5052/ .","title":"Configuration"},{"location":"keymanager-api.html#authorization-bearer-scheme","text":"All requests must be authorized through the Authorization: Bearer scheme with a token matching the contents of a file provided at the start of the node through the --keymanager-token-file parameter.","title":"Authorization: Bearer scheme"},{"location":"keymanager-api.html#enabling-connections-from-outside-machines","text":"By default, only connections from the same machine are entertained. If you wish to change this you can configure the port and listening address with the --keymanager-port and --keymanager-address options respectively. Warning The Keymanager API port should only be exposed through a secure channel (e.g. HTTPS, an SSH tunnel, a VPN, etc.)","title":"Enabling connections from outside machines"},{"location":"keymanager-api.html#specification","text":"The specification is documented here . The README is also extremely useful and is documented here .","title":"Specification"},{"location":"keys.html","text":"This page has been removed. Follow our validating guide .","title":"Keys"},{"location":"light-client-data.html","text":"Light client data Nimbus is configured by default to serve data that allows light clients to stay in sync with the Ethereum network. Light client data is imported incrementally and does not affect validator performance. Information about the light client sync protocol can be found in the Ethereum consensus specs . Note Nimbus also implements a standalone light client that may be used to sync an execution layer (EL) client. Configuration The following configuration options adjust the import and serving of light client data: Option Description --light-client-data-serve false : Disable light client data serving true (default): Provide imported light client data to others --light-client-data-import-mode none : Do not import new light client data only-new (default): Incrementally import new light client data full : Import historic light client data (slow startup) on-demand : Like full , but import on demand instead of on start --light-client-data-max-periods Controls the maximum number of sync committee periods to retain light client data When unspecified (default), light client data is never pruned Warning Setting --light-client-data-import-mode to full or on-demand imports historic light client data which is computationally expensive. While importing historic light client data, validator duties may be missed.","title":"Light client data"},{"location":"light-client-data.html#light-client-data","text":"Nimbus is configured by default to serve data that allows light clients to stay in sync with the Ethereum network. Light client data is imported incrementally and does not affect validator performance. Information about the light client sync protocol can be found in the Ethereum consensus specs . Note Nimbus also implements a standalone light client that may be used to sync an execution layer (EL) client.","title":"Light client data"},{"location":"light-client-data.html#configuration","text":"The following configuration options adjust the import and serving of light client data: Option Description --light-client-data-serve false : Disable light client data serving true (default): Provide imported light client data to others --light-client-data-import-mode none : Do not import new light client data only-new (default): Incrementally import new light client data full : Import historic light client data (slow startup) on-demand : Like full , but import on demand instead of on start --light-client-data-max-periods Controls the maximum number of sync committee periods to retain light client data When unspecified (default), light client data is never pruned Warning Setting --light-client-data-import-mode to full or on-demand imports historic light client data which is computationally expensive. While importing historic light client data, validator duties may be missed.","title":"Configuration"},{"location":"log-levels.html","text":"This information has moved to logging .","title":"Log levels"},{"location":"log-rotate.html","text":"Set up log rotation Nimbus logs are written to stdout , and can be redirected to a file. Writing to a file for a long-running process may lead to difficulties when the file grows large. This is typically solved with a log rotator . A log rotator is responsible for switching the written-to file, as well as compressing and removing old logs. Using logrotate logrotate provides log rotation and compression. The corresponding package will install its Cron hooks (or Systemd timer) -- all you have to do is add a configuration file for Nimbus in /etc/logrotate.d/nimbus-eth2 : /var/log/nimbus-eth2/*.log { compress missingok copytruncate } The above assumes you've configured Nimbus to write its logs to /var/log/nimbus-eth2/ (usually by redirecting stdout and stderr from your init script). copytruncate is required because, when it comes to moving the log file, logrotate 's default behaviour requires application support for re-opening that log file at runtime (something which is currently lacking). So, instead of a move, we tell logrotate to do a copy and a truncation of the existing file. A few log lines may be lost in the process. You can control rotation frequency and the maximum number of log files kept by using the global configuration file, /etc/logrotate.conf : # rotate daily daily # only keep logs from the last 7 days rotate 7 Using rotatelogs rotatelogs captures stdout logging and redirects it to a file, rotating and compressing on the fly. It is available on most servers and can be used with Docker , Systemd and manual setups to write rotated logs files. In particular, when systemd and its accompanying journald log daemon are used, this setup avoids clogging the system log by keeping the Nimbus logs in a separate location. Compression rotatelogs works by reading stdin and redirecting it to a file based on a name pattern. Whenever the log is about to be rotated, the application invokes a shell script with the old and new log files. Our aim is to compress the log file to save space. The Nimbus-eth2 repo provides a helper script that does this: # Create a rotation script for rotatelogs cat << EOF > rotatelogs-compress.sh #!/bin/sh # Helper script for Apache rotatelogs to compress log files on rotation - `$2` contains the old log file name if [ -f \"$2\" ]; then # \"nice\" prevents hogging the CPU with this low-priority task nice gzip -9 \"$2\" fi EOF chmod +x rotatelogs-compress.sh Run The final step is to redirect logs to rotatelogs using a pipe when starting Nimbus: build/nimbus_beacon_node \\ --network:holesky \\ --web3-url = \" $WEB3URL \" \\ --data-dir: $DATADIR 2 > & 1 | rotatelogs -L \" $DATADIR /nbc_bn.log\" -p \"/path/to/rotatelogs-compress.sh\" -D -f -c \" $DATADIR /log/nbc_bn_%Y%m%d%H%M%S.log\" 3600 The options used in this example do the following: -L nbc_bn.log - symlinks to the latest log file, for use with tail -F -p \"/path/to/rotatelogs-compress.sh\" - runs rotatelogs-compress.sh when rotation is about to happen -D - creates the log directory if needed -f - opens the log immediately when starting rotatelogs -c \"$DATADIR/log/nbc_bn_%Y%m%d%H%M%S.log\" - includes timestamp in log filename 3600 - rotates logs every hour (3600 seconds) Deleting old logs rotatelogs will not do this for you, so you'll need a Cron script (or Systemd timer): # delete log files older than 7 days find \" $DATADIR /log\" -name 'nbc_bn_*.log' -mtime +7 -exec rm '{}' \\+","title":"Set up log rotation"},{"location":"log-rotate.html#set-up-log-rotation","text":"Nimbus logs are written to stdout , and can be redirected to a file. Writing to a file for a long-running process may lead to difficulties when the file grows large. This is typically solved with a log rotator . A log rotator is responsible for switching the written-to file, as well as compressing and removing old logs.","title":"Set up log rotation"},{"location":"log-rotate.html#using-logrotate","text":"logrotate provides log rotation and compression. The corresponding package will install its Cron hooks (or Systemd timer) -- all you have to do is add a configuration file for Nimbus in /etc/logrotate.d/nimbus-eth2 : /var/log/nimbus-eth2/*.log { compress missingok copytruncate } The above assumes you've configured Nimbus to write its logs to /var/log/nimbus-eth2/ (usually by redirecting stdout and stderr from your init script). copytruncate is required because, when it comes to moving the log file, logrotate 's default behaviour requires application support for re-opening that log file at runtime (something which is currently lacking). So, instead of a move, we tell logrotate to do a copy and a truncation of the existing file. A few log lines may be lost in the process. You can control rotation frequency and the maximum number of log files kept by using the global configuration file, /etc/logrotate.conf : # rotate daily daily # only keep logs from the last 7 days rotate 7","title":"Using logrotate"},{"location":"log-rotate.html#using-rotatelogs","text":"rotatelogs captures stdout logging and redirects it to a file, rotating and compressing on the fly. It is available on most servers and can be used with Docker , Systemd and manual setups to write rotated logs files. In particular, when systemd and its accompanying journald log daemon are used, this setup avoids clogging the system log by keeping the Nimbus logs in a separate location.","title":"Using rotatelogs"},{"location":"log-rotate.html#compression","text":"rotatelogs works by reading stdin and redirecting it to a file based on a name pattern. Whenever the log is about to be rotated, the application invokes a shell script with the old and new log files. Our aim is to compress the log file to save space. The Nimbus-eth2 repo provides a helper script that does this: # Create a rotation script for rotatelogs cat << EOF > rotatelogs-compress.sh #!/bin/sh # Helper script for Apache rotatelogs to compress log files on rotation - `$2` contains the old log file name if [ -f \"$2\" ]; then # \"nice\" prevents hogging the CPU with this low-priority task nice gzip -9 \"$2\" fi EOF chmod +x rotatelogs-compress.sh","title":"Compression"},{"location":"log-rotate.html#run","text":"The final step is to redirect logs to rotatelogs using a pipe when starting Nimbus: build/nimbus_beacon_node \\ --network:holesky \\ --web3-url = \" $WEB3URL \" \\ --data-dir: $DATADIR 2 > & 1 | rotatelogs -L \" $DATADIR /nbc_bn.log\" -p \"/path/to/rotatelogs-compress.sh\" -D -f -c \" $DATADIR /log/nbc_bn_%Y%m%d%H%M%S.log\" 3600 The options used in this example do the following: -L nbc_bn.log - symlinks to the latest log file, for use with tail -F -p \"/path/to/rotatelogs-compress.sh\" - runs rotatelogs-compress.sh when rotation is about to happen -D - creates the log directory if needed -f - opens the log immediately when starting rotatelogs -c \"$DATADIR/log/nbc_bn_%Y%m%d%H%M%S.log\" - includes timestamp in log filename 3600 - rotates logs every hour (3600 seconds)","title":"Run"},{"location":"log-rotate.html#deleting-old-logs","text":"rotatelogs will not do this for you, so you'll need a Cron script (or Systemd timer): # delete log files older than 7 days find \" $DATADIR /log\" -name 'nbc_bn_*.log' -mtime +7 -exec rm '{}' \\+","title":"Deleting old logs"},{"location":"logging.html","text":"Logging Nimbus offers several options for logging. By default, logs are written to stdout using the chronicles textlines format which is convenient to read and can be used with tooling for heroku/logfmt . Change log level You can customise Nimbus' verbosity with the --log-level option. For example: ./run-mainnet-beacon-node.sh --log-level=WARN The default value is INFO . Possible values (in order of decreasing verbosity) are: TRACE DEBUG INFO NOTICE WARN ERROR FATAL NONE Change logging style Nimbus supports three log formats: colors , nocolors and json . In auto mode, logs will be printed using either colors or nocolors . You can choose a log format with the --log-format option, which also understands auto and none : ./run-mainnet-beacon-node.sh --log-format=none # disable logging to std out ./run-mainnet-beacon-node.sh --log-format=json # print json logs, one line per item Logging to a file To send logs to a file, you can redirect the stdout logs: # log json to filename.jsonl ./run-mainnet-beacon-node.sh --log-format=json > filename.jsonl We recommend keeping an eye on the growth of this file with a log rotator . Logs are written in the \"JSON Lines\" format - one json entry per line.","title":"Logging"},{"location":"logging.html#logging","text":"Nimbus offers several options for logging. By default, logs are written to stdout using the chronicles textlines format which is convenient to read and can be used with tooling for heroku/logfmt .","title":"Logging"},{"location":"logging.html#change-log-level","text":"You can customise Nimbus' verbosity with the --log-level option. For example: ./run-mainnet-beacon-node.sh --log-level=WARN The default value is INFO . Possible values (in order of decreasing verbosity) are: TRACE DEBUG INFO NOTICE WARN ERROR FATAL NONE","title":"Change log level"},{"location":"logging.html#change-logging-style","text":"Nimbus supports three log formats: colors , nocolors and json . In auto mode, logs will be printed using either colors or nocolors . You can choose a log format with the --log-format option, which also understands auto and none : ./run-mainnet-beacon-node.sh --log-format=none # disable logging to std out ./run-mainnet-beacon-node.sh --log-format=json # print json logs, one line per item","title":"Change logging style"},{"location":"logging.html#logging-to-a-file","text":"To send logs to a file, you can redirect the stdout logs: # log json to filename.jsonl ./run-mainnet-beacon-node.sh --log-format=json > filename.jsonl We recommend keeping an eye on the growth of this file with a log rotator . Logs are written in the \"JSON Lines\" format - one json entry per line.","title":"Logging to a file"},{"location":"merge.html","text":"This page has been removed; all Ethereum Foundation-affiliated Ethereum networks have merged.","title":"Merge"},{"location":"metrics-pretty-pictures.html","text":"Grafana and Prometheus In this page we'll cover how to use Grafana and Prometheus to help you visualize important real-time metrics concerning your validator and/or beacon node. Prometheus is an open-source systems monitoring and alerting toolkit. It runs as a service on your computer and its job is to capture metrics. You can find more information about Prometheus here . Grafana is a tool for beautiful dashboard monitoring that works well with Prometheus. You can learn more about Grafana here . Simple metrics To enable the metrics server, run the beacon node with the --metrics flag: ./run-holesky-beacon-node.sh --metrics Visit http://127.0.0.1:8008/metrics with a browser or curl . You should see a plaintext page that looks something like this: # HELP nim_runtime_info Nim runtime info # TYPE nim_runtime_info gauge nim_gc_mem_bytes 6275072.0 nim_gc_mem_occupied_bytes 1881384.0 nim_gc_heap_instance_occupied_bytes{type_name=\"KeyValuePairSeq[digest.Eth2Digest, block_pools_types.BlockRef]\"} 25165856.0 nim_gc_heap_instance_occupied_bytes{type_name=\"BlockRef\"} 17284608.0 nim_gc_heap_instance_occupied_bytes{type_name=\"string\"} 6264507.0 nim_gc_heap_instance_occupied_bytes{type_name=\"seq[SelectorKey[asyncdispatch.AsyncData]]\"} 409632.0 nim_gc_heap_instance_occupied_bytes{type_name=\"OrderedKeyValuePairSeq[Labels, seq[Metric]]\"} 122720.0 nim_gc_heap_instance_occupied_bytes{type_name=\"Future[system.void]\"} 79848.0 nim_gc_heap_instance_occupied_bytes{type_name=\"anon ref object from /Users/hackingresearch/nimbus/clone/nim-beacon-chain/vendor/nimbus-build-system/vendor/Nim/lib/pure/asyncmacro.nim(319, 33)\"} 65664.0 nim_gc_heap_instance_occupied_bytes{type_name=\"anon ref object from /Users/hackingresearch/nimbus/clone/nim-beacon-chain/vendor/nimbus-build-system/vendor/Nim/lib/pure/asyncnet.nim(506, 11)\"} 43776.0 nim_gc_heap_instance_occupied_bytes{type_name=\"seq[byte]\"} 37236.0 nim_gc_heap_instance_occupied_bytes{type_name=\"seq[TrustedAttestation]\"} 29728.0 ... Note Metrics are by default only accessible from the same machine as the beacon node is running on. To fetch metrics from a remote machine, an SSH tunnel is recommended. The metrics server offers one snapshot in time of the state of the beacon node. Metrics, however, are at their most useful when collected over time \u2014 for this, we'll need to set up two more pieces of software: Prometheus and Grafana. Prometheus and Grafana The following steps will take you through how to use Prometheus and Grafana to spin up a beautiful and useful monitoring dashboard for your validator and beacon node. Steps 1. Download Prometheus Use your favourite package manager to download Prometheus: for example apt-get install prometheus on Ubuntu, or brew install prometheus on MacOS, should do the trick. Note If you don't use a package manager, you can download the latest release of directly from Prometheus website. To extract it, run: tar xvfz prometheus-*.tar.gz cd prometheus-* 2. Copy the binary The Prometheus server is a single binary called prometheus (or prometheus.exe on Microsoft Windows). Copy it over to /usr/local/bin : cp prometheus-2.20.1.linux-amd64/prometheus /usr/local/bin/ 3. Run Prometheus with the default configuration file Prometheus relies on a YAML configuration file to let it know where, and how often, to scrape data. Example config file: global: scrape_interval: 12s scrape_configs: - job_name: \"nimbus\" static_configs: - targets: ['127.0.0.1:8008'] Save the above as prometheus.yml in the nimbus-eth2 repo. Then run Prometheus: prometheus --config.file=./prometheus.yml --storage.tsdb.path=./prometheus You should see the following confirmation in the logs: level=info ts=2021-01-22T14:52:10.604Z caller=main.go:673 msg=\"Server is ready to receive web requests.\" 4. Download Grafana Download the latest release of Grafana for your platform. You need version 7.2 or newer. Note If you use a package manager, you can also download Grafana that way -- for example apt-get install grafana on Ubuntu, or brew install grafana on MacOS, should do the trick. 5. Install and start Grafana Follow the instructions for your platform to install and start Grafana. 6. Configure login Go to http://localhost:3000/ , you should see a Grafana login screen that looks like this: Type in admin for both the username and password. You'll be asked to change the password (and we recommend you do so). 7. Add a data source Hover your mouse over the gear icon in the left menu bar, and click on the Data Sources option in the sub-menu that pops up. Now click on the Add Data Source button in the center of the screen Select Prometheus Enter http://localhost:9090 in the URL field Set the \"Scrape interval\" field to the same value you used in the Prometheus config (\"15s\" in our example below). Scroll to the bottom and click on Save and Test If everything is working correctly you should see a green Data source is working box pop up 8. Import a dashboard Now, let's import a dashboard; hover your mouse over the + icon in the left menu bar and select import from the pop-up menu Click on Upload JSON file Select the beacon_nodes_Grafana_dashboard.json from the nimbus-eth2/grafana/ folder and click on Import You'll be directed to the dashboard where you'll be able to gain insights into the performance of nimbus-eth2 and your validators Note The dashboard is very much a work in progress. Some of the highlights right now include received and proposed blocks, received and sent attestations, peers, memory and cpu usage stats. But keep an eye out for additional metrics in the near future. And voil\u00e0! That's all there is to it :) Community dashboards Joe Clapis Joe \u2014 who\u2019s done some brilliant work integrating Nimbus with Rocket Pool \u2014 has created a wonderful guide where he takes you through how to set up a Grafana server on your Pi, using his dashboard as an example. In his words: This captures just about every metric I think I\u2019d like to see at a glance. Whether or not you're running a Pi, we recommend you check out his guide . Metanull A dashboard aimed primarily at users rather than developers. Note that this dashboard does rely heavily on three prometheus exporter tools: node_exporter for system metrics, json_exporter for ETH price, and blackbox_exporter for ping times. The good news is that you don't need to use all these tools, as long as you take care of removing the related panels. See here for a detailed guide explaining how to use it.","title":"Grafana and Prometheus"},{"location":"metrics-pretty-pictures.html#grafana-and-prometheus","text":"In this page we'll cover how to use Grafana and Prometheus to help you visualize important real-time metrics concerning your validator and/or beacon node. Prometheus is an open-source systems monitoring and alerting toolkit. It runs as a service on your computer and its job is to capture metrics. You can find more information about Prometheus here . Grafana is a tool for beautiful dashboard monitoring that works well with Prometheus. You can learn more about Grafana here .","title":"Grafana and Prometheus"},{"location":"metrics-pretty-pictures.html#simple-metrics","text":"To enable the metrics server, run the beacon node with the --metrics flag: ./run-holesky-beacon-node.sh --metrics Visit http://127.0.0.1:8008/metrics with a browser or curl . You should see a plaintext page that looks something like this: # HELP nim_runtime_info Nim runtime info # TYPE nim_runtime_info gauge nim_gc_mem_bytes 6275072.0 nim_gc_mem_occupied_bytes 1881384.0 nim_gc_heap_instance_occupied_bytes{type_name=\"KeyValuePairSeq[digest.Eth2Digest, block_pools_types.BlockRef]\"} 25165856.0 nim_gc_heap_instance_occupied_bytes{type_name=\"BlockRef\"} 17284608.0 nim_gc_heap_instance_occupied_bytes{type_name=\"string\"} 6264507.0 nim_gc_heap_instance_occupied_bytes{type_name=\"seq[SelectorKey[asyncdispatch.AsyncData]]\"} 409632.0 nim_gc_heap_instance_occupied_bytes{type_name=\"OrderedKeyValuePairSeq[Labels, seq[Metric]]\"} 122720.0 nim_gc_heap_instance_occupied_bytes{type_name=\"Future[system.void]\"} 79848.0 nim_gc_heap_instance_occupied_bytes{type_name=\"anon ref object from /Users/hackingresearch/nimbus/clone/nim-beacon-chain/vendor/nimbus-build-system/vendor/Nim/lib/pure/asyncmacro.nim(319, 33)\"} 65664.0 nim_gc_heap_instance_occupied_bytes{type_name=\"anon ref object from /Users/hackingresearch/nimbus/clone/nim-beacon-chain/vendor/nimbus-build-system/vendor/Nim/lib/pure/asyncnet.nim(506, 11)\"} 43776.0 nim_gc_heap_instance_occupied_bytes{type_name=\"seq[byte]\"} 37236.0 nim_gc_heap_instance_occupied_bytes{type_name=\"seq[TrustedAttestation]\"} 29728.0 ... Note Metrics are by default only accessible from the same machine as the beacon node is running on. To fetch metrics from a remote machine, an SSH tunnel is recommended. The metrics server offers one snapshot in time of the state of the beacon node. Metrics, however, are at their most useful when collected over time \u2014 for this, we'll need to set up two more pieces of software: Prometheus and Grafana.","title":"Simple metrics"},{"location":"metrics-pretty-pictures.html#prometheus-and-grafana","text":"The following steps will take you through how to use Prometheus and Grafana to spin up a beautiful and useful monitoring dashboard for your validator and beacon node.","title":"Prometheus and Grafana"},{"location":"metrics-pretty-pictures.html#steps","text":"","title":"Steps"},{"location":"metrics-pretty-pictures.html#community-dashboards","text":"","title":"Community dashboards"},{"location":"metrics-pretty-pictures.html#joe-clapis","text":"Joe \u2014 who\u2019s done some brilliant work integrating Nimbus with Rocket Pool \u2014 has created a wonderful guide where he takes you through how to set up a Grafana server on your Pi, using his dashboard as an example. In his words: This captures just about every metric I think I\u2019d like to see at a glance. Whether or not you're running a Pi, we recommend you check out his guide .","title":"Joe Clapis"},{"location":"metrics-pretty-pictures.html#metanull","text":"A dashboard aimed primarily at users rather than developers. Note that this dashboard does rely heavily on three prometheus exporter tools: node_exporter for system metrics, json_exporter for ETH price, and blackbox_exporter for ping times. The good news is that you don't need to use all these tools, as long as you take care of removing the related panels. See here for a detailed guide explaining how to use it.","title":"Metanull"},{"location":"migration-options.html","text":"Client migration (advanced) The main migration guide is located here . Here we document a couple of advanced options you can use if you wish to have more fine-grained control. Export validators The default command for exporting your slashing protection history is: build/nimbus_beacon_node slashingdb export database.json This will export your history in the correct format to database.json . On success you will have a message similar to: Exported slashing protection DB to 'database.json' Export finished: '$HOME/.cache/nimbus/BeaconNode/validators/slashing_protection.sqlite3' into 'interchange.json' Export from a specific validators directory The validator directory contains your validator's setup. build/nimbus_beacon_node slashingdb export database.json --validators-dir = path/to/validatorsdir/ Export from a specific data directory The data directory ( data-dir ) contains your beacon node setup. build/nimbus_beacon_node slashingdb export database.json --data-dir = path/to/datadir/ Partial exports You can perform a partial export by specifying the public key of the relevant validator you wish to export. build/nimbus_beacon_node slashingdb export database.json --validator = 0xb5da853a51d935da6f3bd46934c719fcca1bbf0b493264d3d9e7c35a1023b73c703b56d598edf0239663820af36ec615 If you wish to export multiple validators, you must specify the --validator option multiple times. Import validators The default command for importing your validator's slashing protection history into the database is: build/nimbus_beacon_node slashingdb import database.json Import to a specific validators directory The validator directory contains your validator's setup. build/nimbus_beacon_node slashingdb import database.json --validators-dir = path/to/validatorsdir/ Import to a specific data directory The data directory contains your beacon node's setup. build/nimbus_beacon_node slashingdb import database.json --data-dir = path/to/datadir/","title":"Client migration (advanced)"},{"location":"migration-options.html#client-migration-advanced","text":"The main migration guide is located here . Here we document a couple of advanced options you can use if you wish to have more fine-grained control.","title":"Client migration (advanced)"},{"location":"migration-options.html#export-validators","text":"The default command for exporting your slashing protection history is: build/nimbus_beacon_node slashingdb export database.json This will export your history in the correct format to database.json . On success you will have a message similar to: Exported slashing protection DB to 'database.json' Export finished: '$HOME/.cache/nimbus/BeaconNode/validators/slashing_protection.sqlite3' into 'interchange.json'","title":"Export validators"},{"location":"migration-options.html#export-from-a-specific-validators-directory","text":"The validator directory contains your validator's setup. build/nimbus_beacon_node slashingdb export database.json --validators-dir = path/to/validatorsdir/","title":"Export from a specific validators directory"},{"location":"migration-options.html#export-from-a-specific-data-directory","text":"The data directory ( data-dir ) contains your beacon node setup. build/nimbus_beacon_node slashingdb export database.json --data-dir = path/to/datadir/","title":"Export from a specific data directory"},{"location":"migration-options.html#partial-exports","text":"You can perform a partial export by specifying the public key of the relevant validator you wish to export. build/nimbus_beacon_node slashingdb export database.json --validator = 0xb5da853a51d935da6f3bd46934c719fcca1bbf0b493264d3d9e7c35a1023b73c703b56d598edf0239663820af36ec615 If you wish to export multiple validators, you must specify the --validator option multiple times.","title":"Partial exports"},{"location":"migration-options.html#import-validators","text":"The default command for importing your validator's slashing protection history into the database is: build/nimbus_beacon_node slashingdb import database.json","title":"Import validators"},{"location":"migration-options.html#import-to-a-specific-validators-directory","text":"The validator directory contains your validator's setup. build/nimbus_beacon_node slashingdb import database.json --validators-dir = path/to/validatorsdir/","title":"Import to a specific validators directory"},{"location":"migration-options.html#import-to-a-specific-data-directory","text":"The data directory contains your beacon node's setup. build/nimbus_beacon_node slashingdb import database.json --data-dir = path/to/datadir/","title":"Import to a specific data directory"},{"location":"migration.html","text":"Migrate from another client This guide will take you through the basics of how to migrate to Nimbus from another client. See here for advanced options. Please take your time to get this right. Don't hesitate to reach out to us in the #helpdesk channel of our discord if you come across a stumbling block. We are more than happy to help guide you through the migration process. Given what's at stake, there is no such thing as a stupid question. Unlike other clients, Nimbus does not require a separate validator client. Instead, validators run in the beacon node process. Warning The most important takeaway is that you ensure that two clients will never validate with the same keys at the same time. In other words, you must ensure that your original client is stopped, and no longer validating, before importing your keys into Nimbus. Steps 1. Sync the Nimbus beacon node No matter which client you are migrating over from, the first step is to sync the Nimbus beacon node. The easiest and fastest way to do this is to follow the beacon node quick start guide and perform a trusted node sync from the source client. Once your Nimbus beacon node has synced and you're satisfied that it's working, move to Step 2 . Tip You can keep track of your syncing progress with the following command: curl -X GET http://localhost:5052/eth/v1/node/syncing Look for an \"is_syncing\":false in the response to confirm that your node has synced. 2. Stop your existing client and export your slashing protection history As part of the migration process, you need to stop your existing client and export its slashing protection database . Prysm Lighthouse Teku Nimbus 1. Disable the Prysm validator client Stop and disable the Prysm validator client (you can also stop the Prysm beacon node if you wish). If you're using systemd and your service is called prysmvalidator , run the following commands to stop and disable the service: sudo systemctl stop prysmvalidator.service sudo systemctl disable prysmvalidator.service It is important that you disable the Prysm validator as well as stopping it, to prevent it from starting up again on reboot. 2. Export slashing protection history Run the following to export your Prysm validator's slashing protection history: prysm.sh validator slashing-protection-history export \\ --datadir = /your/prysm/wallet \\ --slashing-protection-export-dir = /path/to/export_dir You will then find the slashing-protection.json file in your specified /path/to/export_dir folder. 1. Disable the Lighthouse validator client The validator client needs to be stopped in order to export, to guarantee that the data exported is up to date. If you're using systemd and your service is called lighthousevalidator , run the following command to stop and disable the service: sudo systemctl stop lighthousevalidator sudo systemctl disable lighthousevalidator You may also wish to stop the beacon node: sudo systemctl stop lighthousebeacon sudo systemctl disable lighthousebeacon It is important that you disable the service as well as stopping it, to prevent it from starting up again on reboot. 2. Export slashing protection history You can export Lighthouse's database with this command: lighthouse account validator slashing-protection export slashing-protection.json This will export your history in the correct format to slashing-protection.json . 1. Disable Teku If you're using systemd and your service is called teku , run the following command to stop and disable the service: sudo systemctl stop teku sudo systemctl disable teku It is important that you disable the service as well as stopping it, to prevent it from starting up again on reboot. 2. Export slashing protection history You can export Teku's database with this command: teku slashing-protection export --data-path = /home/me/me_node --to = /home/slash/slashing-protection.json Where: --data-path specifies the location of the Teku data directory. --to specifies the file to export the slashing-protection data to (in this case /home/slash/slashing-protection.json ). 1. Disable the Nimbus validator client Once your Nimbus beacon node on your new setup has synced and you're satisfied that it's working, stop and disable the Nimbus validator client on your current setup. If you're using systemd and your service is called nimbus-eth2-mainnet , run the following commands to stop and disable the service: sudo systemctl stop nimbus-eth2-mainnet.service sudo systemctl disable nimbus-eth2-mainnet.service It is important that you disable the service as well as stopping it, to prevent it from starting up again on reboot. 2. Export slashing protection history Run the following to export your Nimbus validator's slashing protection history: build/nimbus_beacon_node slashingdb export slashing-protection.json This will export your history in the correct format to slashing-protection.json . Tip To be extra sure that your validator has stopped, wait a few epochs and confirm that your validator has stopped attesting (check its recent history on beaconcha.in ). Only after that, continue with the next step of this guide. 3. Import your validator key(s) into Nimbus To import your validator key(s), follow the instructions in our validator guide . Tip To check that your key(s) has been successfully imported, look for a file named after your public key in build/data/shared_mainet_0/secrets/ . If you run into an error at this stage, it's probably because the wrong permissions have been set on either a folder or file. See here for how to fix this. 4. Import your slashing protection history To import the slashing protection history you exported in step 2 , from the nimbus-eth2 directory run: build/nimbus_beacon_node slashingdb import path/to/export_dir/slashing-protection.json Replacing /path/to/export_dir with the file/directory you specified when you exported your slashing protection history. Tip Additional slashing protection information can be safely added to slashing protection databases. 5. Start the Nimbus validator Follow the instructions in our validator guide to start your validator using our pre-built binaries . If you prefer to use Docker, see our Docker guide . For a quick guide on how to set up a systemd service, see our systemd guide . Final thoughts If you are unsure of the safety of a step, please get in touch with us directly on discord . Additionally, we recommend testing the migration works correctly on a testnet before going ahead on mainnet.","title":"Migrate from another client"},{"location":"migration.html#migrate-from-another-client","text":"This guide will take you through the basics of how to migrate to Nimbus from another client. See here for advanced options. Please take your time to get this right. Don't hesitate to reach out to us in the #helpdesk channel of our discord if you come across a stumbling block. We are more than happy to help guide you through the migration process. Given what's at stake, there is no such thing as a stupid question. Unlike other clients, Nimbus does not require a separate validator client. Instead, validators run in the beacon node process. Warning The most important takeaway is that you ensure that two clients will never validate with the same keys at the same time. In other words, you must ensure that your original client is stopped, and no longer validating, before importing your keys into Nimbus.","title":"Migrate from another client"},{"location":"migration.html#steps","text":"","title":"Steps"},{"location":"migration.html#1-sync-the-nimbus-beacon-node","text":"No matter which client you are migrating over from, the first step is to sync the Nimbus beacon node. The easiest and fastest way to do this is to follow the beacon node quick start guide and perform a trusted node sync from the source client. Once your Nimbus beacon node has synced and you're satisfied that it's working, move to Step 2 . Tip You can keep track of your syncing progress with the following command: curl -X GET http://localhost:5052/eth/v1/node/syncing Look for an \"is_syncing\":false in the response to confirm that your node has synced.","title":"1. Sync the Nimbus beacon node"},{"location":"migration.html#2-stop-your-existing-client-and-export-your-slashing-protection-history","text":"As part of the migration process, you need to stop your existing client and export its slashing protection database . Prysm Lighthouse Teku Nimbus","title":"2. Stop your existing client and export your slashing protection history"},{"location":"migration.html#3-import-your-validator-keys-into-nimbus","text":"To import your validator key(s), follow the instructions in our validator guide . Tip To check that your key(s) has been successfully imported, look for a file named after your public key in build/data/shared_mainet_0/secrets/ . If you run into an error at this stage, it's probably because the wrong permissions have been set on either a folder or file. See here for how to fix this.","title":"3. Import your validator key(s) into Nimbus"},{"location":"migration.html#4-import-your-slashing-protection-history","text":"To import the slashing protection history you exported in step 2 , from the nimbus-eth2 directory run: build/nimbus_beacon_node slashingdb import path/to/export_dir/slashing-protection.json Replacing /path/to/export_dir with the file/directory you specified when you exported your slashing protection history. Tip Additional slashing protection information can be safely added to slashing protection databases.","title":"4. Import your slashing protection history"},{"location":"migration.html#5-start-the-nimbus-validator","text":"Follow the instructions in our validator guide to start your validator using our pre-built binaries . If you prefer to use Docker, see our Docker guide . For a quick guide on how to set up a systemd service, see our systemd guide .","title":"5. Start the Nimbus validator"},{"location":"migration.html#final-thoughts","text":"If you are unsure of the safety of a step, please get in touch with us directly on discord . Additionally, we recommend testing the migration works correctly on a testnet before going ahead on mainnet.","title":"Final thoughts"},{"location":"more-keys.html","text":"Recover lost keys and generate new ones When generating your first deposit , you will be asked to save a mnemonic in a safe location. This mnemonic can be used to recover lost keys and generate new ones. Every time you generate a keystore from your mnemonic, that keystore is assigned an index. The first keystore you generate has index 0, the second index 1, etc. You can recover any key using your mnemonic and that key's index. For more on how keys are derived, see this excellent post . To stay consistent with the rest of the book, we'll take you though how to do this using the deposit-cli's binary executable . Specifically, we'll be using the existing-mnemonic command. Here's a description of the command from the deposit-cli's README : This command is used to re-generate or derive new keys from your existing mnemonic. Use this command, if (i) you have already generated keys with this CLI before, (ii) you want to reuse your mnemonic that you know is secure that you generated elsewhere (reusing your eth1 mnemonic .etc), or (iii) you lost your keystores and need to recover your keys. Recover existing key Warning Recovering validator keys from a mnemonic should only be used as a last resort. Exposing your mnemonic to a computer at any time puts it at risk of being compromised. Your mnemonic is not encrypted and if leaked, can be used to steal your funds. Note The commands below assume you are trying to recover the first key you created, hence --validator_start_index has been set to 0 . Run the following command from the directory which contains the deposit executable: Mainnet Holesky ./deposit existing-mnemonic \\ --validator_start_index 0 \\ --num_validators 1 \\ --chain mainnet ./deposit existing-mnemonic \\ --validator_start_index 0 \\ --num_validators 1 \\ --chain holesky You'll be prompted to enter your mnemonic, and a new password for your keystore. Check that the validator_keys directory contains your keystore. Copy the validator_keys directory to nimbus-eth2 and then follow the key import instructions of our validator guide. Your key will be added to your node on next restart. Generate another key Warning If you wish to use your new key with a separate client instance, make sure not to include your first key in the second setup \u2014 doing so will lead to it being slashed! Note The commands below assume you already have one key and wish to generate a second, hence --validator_start_index has been set to 1 (as 0 would be the original key) Run the following command from the directory which contains the deposit executable: Mainnet Holesky ./deposit existing-mnemonic \\ --validator_start_index 1 \\ --num_validators 1 \\ --chain mainnet ./deposit existing-mnemonic \\ --validator_start_index 1 \\ --num_validators 1 \\ --chain holesky You'll be prompted to enter your mnemonic and a new password for your keystore. Check that the validator_keys directory contains an extra keystore. Copy the validator_keys directory to nimbus-eth2 . Make sure you've made a deposit for your new keystore, and then follow the key import instructions of our validator guide. Your key will be added to your node on the next restart.","title":"Recover lost keys and generate new ones"},{"location":"more-keys.html#recover-lost-keys-and-generate-new-ones","text":"When generating your first deposit , you will be asked to save a mnemonic in a safe location. This mnemonic can be used to recover lost keys and generate new ones. Every time you generate a keystore from your mnemonic, that keystore is assigned an index. The first keystore you generate has index 0, the second index 1, etc. You can recover any key using your mnemonic and that key's index. For more on how keys are derived, see this excellent post . To stay consistent with the rest of the book, we'll take you though how to do this using the deposit-cli's binary executable . Specifically, we'll be using the existing-mnemonic command. Here's a description of the command from the deposit-cli's README : This command is used to re-generate or derive new keys from your existing mnemonic. Use this command, if (i) you have already generated keys with this CLI before, (ii) you want to reuse your mnemonic that you know is secure that you generated elsewhere (reusing your eth1 mnemonic .etc), or (iii) you lost your keystores and need to recover your keys.","title":"Recover lost keys and generate new ones"},{"location":"more-keys.html#recover-existing-key","text":"Warning Recovering validator keys from a mnemonic should only be used as a last resort. Exposing your mnemonic to a computer at any time puts it at risk of being compromised. Your mnemonic is not encrypted and if leaked, can be used to steal your funds. Note The commands below assume you are trying to recover the first key you created, hence --validator_start_index has been set to 0 . Run the following command from the directory which contains the deposit executable: Mainnet Holesky ./deposit existing-mnemonic \\ --validator_start_index 0 \\ --num_validators 1 \\ --chain mainnet ./deposit existing-mnemonic \\ --validator_start_index 0 \\ --num_validators 1 \\ --chain holesky You'll be prompted to enter your mnemonic, and a new password for your keystore. Check that the validator_keys directory contains your keystore. Copy the validator_keys directory to nimbus-eth2 and then follow the key import instructions of our validator guide. Your key will be added to your node on next restart.","title":"Recover existing key"},{"location":"more-keys.html#generate-another-key","text":"Warning If you wish to use your new key with a separate client instance, make sure not to include your first key in the second setup \u2014 doing so will lead to it being slashed! Note The commands below assume you already have one key and wish to generate a second, hence --validator_start_index has been set to 1 (as 0 would be the original key) Run the following command from the directory which contains the deposit executable: Mainnet Holesky ./deposit existing-mnemonic \\ --validator_start_index 1 \\ --num_validators 1 \\ --chain mainnet ./deposit existing-mnemonic \\ --validator_start_index 1 \\ --num_validators 1 \\ --chain holesky You'll be prompted to enter your mnemonic and a new password for your keystore. Check that the validator_keys directory contains an extra keystore. Copy the validator_keys directory to nimbus-eth2 . Make sure you've made a deposit for your new keystore, and then follow the key import instructions of our validator guide. Your key will be added to your node on the next restart.","title":"Generate another key"},{"location":"networking.html","text":"Networking Nimbus will automatically connect to peers based on the health and quality of peers that it's already connected to. Depending on the network and the number of validators attached to the node, Nimbus may need anywhere from 10 to 60 peers connected to operate well. In addition to making outgoing connections, the beacon node node works best when others can connect to it \u2014 this speeds up the process of finding good peers. To allow incoming connections, the node must be reachable via a public IP address. It must also be aware of this address, so that it can advertise it to its peers. UPnP By default, Nimbus uses UPnP to set up port forwarding and detect your external IP address. If you do not have UPnP enabled, you may need to pass additional command-line options to the node, as explained in the subsequent sections. Enabling UPnP is usually as simple as checking a box in your router's configuration. Monitor your Peer count Note The --max-peers setting should not be set below 70. Lowering max-peers does not significantly improve bandwidth usage, but does increase the risk of missed attestations. If your Peer count is low (less than 15 ) and/or you repeatedly see either of the following warnings: Peer count low, no new peers discovered... or No peers for topic, skipping publish... It means that Nimbus is unable to find a sufficient number of peers to guarantee stable operation, and you may miss attestations and blocks as a result. Most commonly, this happens when your computer is not reachable from the outside and therefore won't be able to accept any incoming peer connections. If you're on a home network, the fix here is to set up port forwarding (this may require you to pass the extip option and set enr-auto-update ). The first step however, is to check for incoming connections. Check for incoming connections To check if you have incoming connections set, run: curl -s http://localhost:8008/metrics | grep libp2p_open_streams In the output, look for a line that looks like: libp2p_open_streams{type=\"ChronosStream\",dir=\"in\"} If there are no dir=in ChronosStreams, incoming connections are not working. Note You need to run the client with the --metrics option enabled in order for this to work Set an explicit external IP If you have a static public IP address, use the --nat:extip:$EXT_IP_ADDRESS option to pass it to the client, where $EXT_IP_ADDRESS is your public IP. See here for how to determine your public IP address. Note If you have a dynamic IP, you can use extip the initial setting, but should also enable --enr-auto-update to keep it up-to-date. Set ENR auto update The --enr-auto-update feature keeps your external IP address up to date based on information received from other peers on the network. This option is useful with ISPs that assign IP addresses dynamically. In practice this means relaunching the beacon node with --enr-auto-update:true (pass it as an option in the command line). Set up port forwarding If you're running on a home network and want to ensure you are able to receive incoming connections you may need to set up port forwarding (though some routers automagically set this up for you). Note If you are running your node on a virtual public server (VPS) instance, you can safely ignore this section. While the specific steps required vary based on your router, they can be summarised as follows: Determine your public IP address Determine your private IP address Browse to the management website for your home router ( http://192.168.1.1 for most routers) Log in as admin Find the section to configure port forwarding Configure a port forwarding rule with the following values: External port: 9000 Internal port: 9000 Protocol: TCP IP Address: Private IP address of the computer running Nimbus Configure a second port forwarding rule with the following values: External port: 9000 Internal port: 9000 Protocol: UDP IP Address: Private IP address of the computer running Nimbus Determine your public IP address To determine your public IP address, visit http://v4.ident.me/ or run this command: curl v4.ident.me Determine your private IP address To determine your private IP address, run the appropriate command for your OS: Linux Windows macOS ip addr show | grep \"inet \" | grep -v 127 .0.0.1 ipconfig | findstr /i \"IPv4 Address\" ifconfig | grep \"inet \" | grep -v 127 .0.0.1 Check open ports on your connection Use the open ports tool to check your external (public) IP address and detect open ports on your connection (Nimbus TCP and UDP ports are both set to 9000 by default). Reading the logs No peers for topic, skipping publish... This is printed when the client lacks quality peers to publish attestations to - this is the most important indication that the node is having trouble keeping up. If you see this, you are missing attestations. Peer count low, no new peers discovered... This is a sign that you may be missing attestations. No external IP provided for the ENR... This message basically means that the software did not manage to find a public IP address (by either looking at your routed interface IP address, and/or by attempting to get it from your gateway through UPnP or NAT-PMP). Discovered new external address but ENR auto update is off... It's possible that your ISP has changed your IP address without you knowing. The first thing to do it to try relaunching the beacon node with with --enr-auto-update:true (pass it as an option in the command line). If this doesn't fix the problem, the next thing to do is to check your external (public) IP address and detect open ports on your connection - you can use this site . Note that Nimbus TCP and UDP ports are both set to 9000 by default. See above for how to set up port forwarding.","title":"Networking"},{"location":"networking.html#networking","text":"Nimbus will automatically connect to peers based on the health and quality of peers that it's already connected to. Depending on the network and the number of validators attached to the node, Nimbus may need anywhere from 10 to 60 peers connected to operate well. In addition to making outgoing connections, the beacon node node works best when others can connect to it \u2014 this speeds up the process of finding good peers. To allow incoming connections, the node must be reachable via a public IP address. It must also be aware of this address, so that it can advertise it to its peers.","title":"Networking"},{"location":"networking.html#upnp","text":"By default, Nimbus uses UPnP to set up port forwarding and detect your external IP address. If you do not have UPnP enabled, you may need to pass additional command-line options to the node, as explained in the subsequent sections. Enabling UPnP is usually as simple as checking a box in your router's configuration.","title":"UPnP"},{"location":"networking.html#monitor-your-peer-count","text":"Note The --max-peers setting should not be set below 70. Lowering max-peers does not significantly improve bandwidth usage, but does increase the risk of missed attestations. If your Peer count is low (less than 15 ) and/or you repeatedly see either of the following warnings: Peer count low, no new peers discovered... or No peers for topic, skipping publish... It means that Nimbus is unable to find a sufficient number of peers to guarantee stable operation, and you may miss attestations and blocks as a result. Most commonly, this happens when your computer is not reachable from the outside and therefore won't be able to accept any incoming peer connections. If you're on a home network, the fix here is to set up port forwarding (this may require you to pass the extip option and set enr-auto-update ). The first step however, is to check for incoming connections.","title":"Monitor your Peer count"},{"location":"networking.html#check-for-incoming-connections","text":"To check if you have incoming connections set, run: curl -s http://localhost:8008/metrics | grep libp2p_open_streams In the output, look for a line that looks like: libp2p_open_streams{type=\"ChronosStream\",dir=\"in\"} If there are no dir=in ChronosStreams, incoming connections are not working. Note You need to run the client with the --metrics option enabled in order for this to work","title":"Check for incoming connections"},{"location":"networking.html#set-an-explicit-external-ip","text":"If you have a static public IP address, use the --nat:extip:$EXT_IP_ADDRESS option to pass it to the client, where $EXT_IP_ADDRESS is your public IP. See here for how to determine your public IP address. Note If you have a dynamic IP, you can use extip the initial setting, but should also enable --enr-auto-update to keep it up-to-date.","title":"Set an explicit external IP"},{"location":"networking.html#set-enr-auto-update","text":"The --enr-auto-update feature keeps your external IP address up to date based on information received from other peers on the network. This option is useful with ISPs that assign IP addresses dynamically. In practice this means relaunching the beacon node with --enr-auto-update:true (pass it as an option in the command line).","title":"Set ENR auto update"},{"location":"networking.html#set-up-port-forwarding","text":"If you're running on a home network and want to ensure you are able to receive incoming connections you may need to set up port forwarding (though some routers automagically set this up for you). Note If you are running your node on a virtual public server (VPS) instance, you can safely ignore this section. While the specific steps required vary based on your router, they can be summarised as follows: Determine your public IP address Determine your private IP address Browse to the management website for your home router ( http://192.168.1.1 for most routers) Log in as admin Find the section to configure port forwarding Configure a port forwarding rule with the following values: External port: 9000 Internal port: 9000 Protocol: TCP IP Address: Private IP address of the computer running Nimbus Configure a second port forwarding rule with the following values: External port: 9000 Internal port: 9000 Protocol: UDP IP Address: Private IP address of the computer running Nimbus","title":"Set up port forwarding"},{"location":"networking.html#determine-your-public-ip-address","text":"To determine your public IP address, visit http://v4.ident.me/ or run this command: curl v4.ident.me","title":"Determine your public IP address"},{"location":"networking.html#determine-your-private-ip-address","text":"To determine your private IP address, run the appropriate command for your OS: Linux Windows macOS ip addr show | grep \"inet \" | grep -v 127 .0.0.1 ipconfig | findstr /i \"IPv4 Address\" ifconfig | grep \"inet \" | grep -v 127 .0.0.1","title":"Determine your private IP address"},{"location":"networking.html#check-open-ports-on-your-connection","text":"Use the open ports tool to check your external (public) IP address and detect open ports on your connection (Nimbus TCP and UDP ports are both set to 9000 by default).","title":"Check open ports on your connection"},{"location":"networking.html#reading-the-logs","text":"No peers for topic, skipping publish... This is printed when the client lacks quality peers to publish attestations to - this is the most important indication that the node is having trouble keeping up. If you see this, you are missing attestations. Peer count low, no new peers discovered... This is a sign that you may be missing attestations. No external IP provided for the ENR... This message basically means that the software did not manage to find a public IP address (by either looking at your routed interface IP address, and/or by attempting to get it from your gateway through UPnP or NAT-PMP). Discovered new external address but ENR auto update is off... It's possible that your ISP has changed your IP address without you knowing. The first thing to do it to try relaunching the beacon node with with --enr-auto-update:true (pass it as an option in the command line). If this doesn't fix the problem, the next thing to do is to check your external (public) IP address and detect open ports on your connection - you can use this site . Note that Nimbus TCP and UDP ports are both set to 9000 by default. See above for how to set up port forwarding.","title":"Reading the logs"},{"location":"optimistic-sync.html","text":"Optimistic sync Optimistic sync is the process of syncing an execution and consensus client concurrently, without having the consensus client wait for the execution client. During optimistic sync, the consensus client quickly syncs up to the latest consensus but delays verifying block execution payloads: it continuously informs the execution client of the latest consensus head, allowing the execution client to perform a snapshot sync directly to the latest state. Once the execution client has caught up, the consensus and execution clients work in lock-step each validating the block. Both execution and consensus clients must be fully synced to perform validation duties: while optimistically synced, validator duties (attestation, sync committee and block production work) are skipped. Running without execution client Nimbus continues to sync optimistically when the execution client is not available thanks to its built-in execution payload verifier. Identifying optimistic sync An optimistically synced node can be identified by examining the \"Slot start\" log message. When optimistically synced, the sync key will have a /opt suffix, indicating that it's waiting for the execution client to catch up: INF 2022-10-26 18:57:35.000+02:00 Slot start topics=\"beacnde\" slot=4998286 epoch=156196 sync=synced/opt peers=29 head=f21d399e:4998285 finalized=156194:91e2ebaf delay=467us953ns","title":"Optimistic sync"},{"location":"optimistic-sync.html#optimistic-sync","text":"Optimistic sync is the process of syncing an execution and consensus client concurrently, without having the consensus client wait for the execution client. During optimistic sync, the consensus client quickly syncs up to the latest consensus but delays verifying block execution payloads: it continuously informs the execution client of the latest consensus head, allowing the execution client to perform a snapshot sync directly to the latest state. Once the execution client has caught up, the consensus and execution clients work in lock-step each validating the block. Both execution and consensus clients must be fully synced to perform validation duties: while optimistically synced, validator duties (attestation, sync committee and block production work) are skipped. Running without execution client Nimbus continues to sync optimistically when the execution client is not available thanks to its built-in execution payload verifier.","title":"Optimistic sync"},{"location":"optimistic-sync.html#identifying-optimistic-sync","text":"An optimistically synced node can be identified by examining the \"Slot start\" log message. When optimistically synced, the sync key will have a /opt suffix, indicating that it's waiting for the execution client to catch up: INF 2022-10-26 18:57:35.000+02:00 Slot start topics=\"beacnde\" slot=4998286 epoch=156196 sync=synced/opt peers=29 head=f21d399e:4998285 finalized=156194:91e2ebaf delay=467us953ns","title":"Identifying optimistic sync"},{"location":"options.html","text":"Command line Command line options allow you to customize the way your beacon node operates. You pass options to the beacon node by adding them to the command line. For example, if you want to launch Nimbus on mainnet with different base ports than the default 9000/udp and 9000/tcp , say 9100/udp and 9100/tcp , run: ./run-mainnet-beacon-node.sh --tcp-port = 9100 --udp-port = 9100 Available options To see the full list of command line options available to you, with descriptions, run: build/nimbus_beacon_node --help You should see the following output: Usage: nimbus_beacon_node [OPTIONS]... command The following options are available: --config-file Loads the configuration from a TOML file. --log-level Sets the log level for process and topics (e.g. \"DEBUG; TRACE:discv5,libp2p; REQUIRED:none; DISABLED:none\") [=INFO]. --log-file Specifies a path for the written JSON log file (deprecated). --network The Eth2 network to join [=mainnet]. -d, --data-dir The directory where nimbus will store all blockchain data. --validators-dir A directory containing validator keystores. --verifying-web3-signer-url Remote Web3Signer URL that will be used as a source of validators. --proven-block-property The field path of a block property that will be sent for verification to the verifying Web3Signer (for example \".execution_payload.fee_recipient\"). --web3-signer-url Remote Web3Signer URL that will be used as a source of validators. --web3-signer-update-interval Number of seconds between validator list updates [=3600]. --secrets-dir A directory containing validator keystore passwords. --wallets-dir A directory containing wallet files. --web3-url One or more execution layer Engine API URLs. --el One or more execution layer Engine API URLs. --no-el Don't use an EL. The node will remain optimistically synced and won't be able to perform validator duties [=false]. --non-interactive Do not display interactive prompts. Quit on missing configuration. --netkey-file Source of network (secp256k1) private key file (random|<path>) [=random]. --insecure-netkey-password Use pre-generated INSECURE password for network private key file [=false]. --agent-string Node agent string which is used as identifier in network [=nimbus]. --subscribe-all-subnets Subscribe to all subnet topics when gossiping [=false]. --num-threads Number of worker threads (\"0\" = use as many threads as there are CPU cores available) [=0]. --jwt-secret A file containing the hex-encoded 256 bit secret key to be used for verifying/generating JWT tokens. -b, --bootstrap-node Specifies one or more bootstrap nodes to use when connecting to the network. --bootstrap-file Specifies a line-delimited file of bootstrap Ethereum network addresses. --listen-address Listening address for the Ethereum LibP2P and Discovery v5 traffic [=*]. --tcp-port Listening TCP port for Ethereum LibP2P traffic [=9000]. --udp-port Listening UDP port for node discovery [=9000]. --max-peers The target number of peers to connect to [=160]. --hard-max-peers The maximum number of peers to connect to. Defaults to maxPeers * 1.5. --nat Specify method to use for determining public address. Must be one of: any, none, upnp, pmp, extip:<IP> [=any]. --enr-auto-update Discovery can automatically update its ENR with the IP address and UDP port as seen by other nodes it communicates with. This option allows to enable/disable this functionality [=false]. --weak-subjectivity-checkpoint Weak subjectivity checkpoint in the format block_root:epoch_number. --external-beacon-api-url External beacon API to use for syncing (on empty database). --sync-light-client Accelerate sync using light client [=true]. --trusted-block-root Recent trusted finalized block root to sync from external beacon API (with `--external-beacon-api-url`). Uses the light client sync protocol to obtain the latest finalized checkpoint (LC is initialized from trusted block root). --trusted-state-root Recent trusted finalized state root to sync from external beacon API (with `--external-beacon-api-url`). --finalized-checkpoint-state SSZ file specifying a recent finalized state. --genesis-state SSZ file specifying the genesis state of the network (for networks without a built-in genesis state). --genesis-state-url URL for obtaining the genesis state of the network (for networks without a built-in genesis state). --finalized-deposit-tree-snapshot SSZ file specifying a recent finalized EIP-4881 deposit tree snapshot. --node-name A name for this node that will appear in the logs. If you set this to 'auto', a persistent automatically generated ID will be selected for each --data-dir folder. --graffiti The graffiti value that will appear in proposed blocks. You can use a 0x-prefixed hex encoded string to specify raw bytes. --metrics Enable the metrics server [=false]. --metrics-address Listening address of the metrics server [=127.0.0.1]. --metrics-port Listening HTTP port of the metrics server [=8008]. --status-bar Display a status bar at the bottom of the terminal screen [=true]. --status-bar-contents Textual template for the contents of the status bar. --rest Enable the REST server [=false]. --rest-port Port for the REST server [=5052]. --rest-address Listening address of the REST server [=127.0.0.1]. --rest-allow-origin Limit the access to the REST API to a particular hostname (for CORS-enabled clients such as browsers). --rest-statecache-size The maximum number of recently accessed states that are kept in memory. Speeds up requests obtaining information for consecutive slots or epochs. [=3]. --rest-statecache-ttl The number of seconds to keep recently accessed states in memory [=60]. --rest-request-timeout The number of seconds to wait until complete REST request will be received [=infinite]. --rest-max-body-size Maximum size of REST request body (kilobytes) [=16384]. --rest-max-headers-size Maximum size of REST request headers (kilobytes) [=128]. --keymanager Enable the REST keymanager API [=false]. --keymanager-port Listening port for the REST keymanager API [=5052]. --keymanager-address Listening port for the REST keymanager API [=127.0.0.1]. --keymanager-allow-origin Limit the access to the Keymanager API to a particular hostname (for CORS-enabled clients such as browsers). --keymanager-token-file A file specifying the authorization token required for accessing the keymanager API. --light-client-data-serve Serve data for enabling light clients to stay in sync with the network [=true]. --light-client-data-import-mode Which classes of light client data to import. Must be one of: none, only-new, full (slow startup), on-demand (may miss validator duties) [=only-new]. --light-client-data-max-periods Maximum number of sync committee periods to retain light client data. --long-range-sync Enable long-range syncing (genesis sync) [=LongRangeSyncMode.Light]. --in-process-validators Disable the push model (the beacon node tells a signing process with the private keys of the validators what to sign and when) and load the validators in the beacon node itself [=true]. --discv5 Enable Discovery v5 [=true]. --dump Write SSZ dumps of blocks, attestations and states to data dir [=false]. --direct-peer The list of privileged, secure and known peers to connect and maintain the connection to. This requires a not random netkey-file. In the multiaddress format like: /ip4/<address>/tcp/<port>/p2p/<peerId-public-key>, or enr format (enr:-xx). Peering agreements are established out of band and must be reciprocal. --doppelganger-detection If enabled, the beacon node prudently listens for 2 epochs for attestations from a validator with the same index (a doppelganger), before sending an attestation itself. This protects against slashing (due to double-voting) but means you will miss two attestations when restarting. [=true]. --validator-monitor-auto Monitor validator activity automatically for validators active on this beacon node [=true]. --validator-monitor-pubkey One or more validators to monitor - works best when --subscribe-all-subnets is enabled. --validator-monitor-details Publish detailed metrics for each validator individually - may incur significant overhead with large numbers of validators [=false]. --suggested-fee-recipient Suggested fee recipient. --suggested-gas-limit Suggested gas limit [=defaultGasLimit]. --payload-builder Enable external payload builder [=false]. --payload-builder-url Payload builder URL. --local-block-value-boost Increase execution layer block values for builder bid comparison by a percentage [=10]. --history Retention strategy for historical data (archive/prune) [=HistoryMode.Prune]. ... Any debug -prefixed flags are considered ephemeral and subject to removal without notice. Configuration files All command line options can also be provided in a TOML config file specified through the --config-file flag. Within the config file, you need to use the long names of all options. Please note that certain options such as web3-url , bootstrap-node , direct-peer , and validator-monitor-pubkey can be supplied more than once on the command line: in the TOML file, you need to supply them as arrays. There are also some minor differences in the parsing of certain option values in the TOML files in order to conform more closely to existing TOML standards. For example, you can freely use keywords such as on , off , yes and no on the command-line as synonyms for the canonical values true and false which are mandatory to use in TOML. Options affecting Nimbus sub-commands should appear in a section of the file matching the sub-command name. Here is an example config file illustrating all of the above: nimbus-eth2.toml # Comments look like this doppelganger-detection = true web3-url = [ \"http://127.0.0.1:8551\" ] num-threads = 0 [trustedNodeSync] trusted-node-url = \"http://192.168.1.20:5052\" Exit Codes Exit code Description 0 Successful exit 1 Generic failure or unspecified error 129 Doppelganger detection; one might prefer not to restart automatically","title":"Command line"},{"location":"options.html#command-line","text":"Command line options allow you to customize the way your beacon node operates. You pass options to the beacon node by adding them to the command line. For example, if you want to launch Nimbus on mainnet with different base ports than the default 9000/udp and 9000/tcp , say 9100/udp and 9100/tcp , run: ./run-mainnet-beacon-node.sh --tcp-port = 9100 --udp-port = 9100","title":"Command line"},{"location":"options.html#available-options","text":"To see the full list of command line options available to you, with descriptions, run: build/nimbus_beacon_node --help You should see the following output: Usage: nimbus_beacon_node [OPTIONS]... command The following options are available: --config-file Loads the configuration from a TOML file. --log-level Sets the log level for process and topics (e.g. \"DEBUG; TRACE:discv5,libp2p; REQUIRED:none; DISABLED:none\") [=INFO]. --log-file Specifies a path for the written JSON log file (deprecated). --network The Eth2 network to join [=mainnet]. -d, --data-dir The directory where nimbus will store all blockchain data. --validators-dir A directory containing validator keystores. --verifying-web3-signer-url Remote Web3Signer URL that will be used as a source of validators. --proven-block-property The field path of a block property that will be sent for verification to the verifying Web3Signer (for example \".execution_payload.fee_recipient\"). --web3-signer-url Remote Web3Signer URL that will be used as a source of validators. --web3-signer-update-interval Number of seconds between validator list updates [=3600]. --secrets-dir A directory containing validator keystore passwords. --wallets-dir A directory containing wallet files. --web3-url One or more execution layer Engine API URLs. --el One or more execution layer Engine API URLs. --no-el Don't use an EL. The node will remain optimistically synced and won't be able to perform validator duties [=false]. --non-interactive Do not display interactive prompts. Quit on missing configuration. --netkey-file Source of network (secp256k1) private key file (random|<path>) [=random]. --insecure-netkey-password Use pre-generated INSECURE password for network private key file [=false]. --agent-string Node agent string which is used as identifier in network [=nimbus]. --subscribe-all-subnets Subscribe to all subnet topics when gossiping [=false]. --num-threads Number of worker threads (\"0\" = use as many threads as there are CPU cores available) [=0]. --jwt-secret A file containing the hex-encoded 256 bit secret key to be used for verifying/generating JWT tokens. -b, --bootstrap-node Specifies one or more bootstrap nodes to use when connecting to the network. --bootstrap-file Specifies a line-delimited file of bootstrap Ethereum network addresses. --listen-address Listening address for the Ethereum LibP2P and Discovery v5 traffic [=*]. --tcp-port Listening TCP port for Ethereum LibP2P traffic [=9000]. --udp-port Listening UDP port for node discovery [=9000]. --max-peers The target number of peers to connect to [=160]. --hard-max-peers The maximum number of peers to connect to. Defaults to maxPeers * 1.5. --nat Specify method to use for determining public address. Must be one of: any, none, upnp, pmp, extip:<IP> [=any]. --enr-auto-update Discovery can automatically update its ENR with the IP address and UDP port as seen by other nodes it communicates with. This option allows to enable/disable this functionality [=false]. --weak-subjectivity-checkpoint Weak subjectivity checkpoint in the format block_root:epoch_number. --external-beacon-api-url External beacon API to use for syncing (on empty database). --sync-light-client Accelerate sync using light client [=true]. --trusted-block-root Recent trusted finalized block root to sync from external beacon API (with `--external-beacon-api-url`). Uses the light client sync protocol to obtain the latest finalized checkpoint (LC is initialized from trusted block root). --trusted-state-root Recent trusted finalized state root to sync from external beacon API (with `--external-beacon-api-url`). --finalized-checkpoint-state SSZ file specifying a recent finalized state. --genesis-state SSZ file specifying the genesis state of the network (for networks without a built-in genesis state). --genesis-state-url URL for obtaining the genesis state of the network (for networks without a built-in genesis state). --finalized-deposit-tree-snapshot SSZ file specifying a recent finalized EIP-4881 deposit tree snapshot. --node-name A name for this node that will appear in the logs. If you set this to 'auto', a persistent automatically generated ID will be selected for each --data-dir folder. --graffiti The graffiti value that will appear in proposed blocks. You can use a 0x-prefixed hex encoded string to specify raw bytes. --metrics Enable the metrics server [=false]. --metrics-address Listening address of the metrics server [=127.0.0.1]. --metrics-port Listening HTTP port of the metrics server [=8008]. --status-bar Display a status bar at the bottom of the terminal screen [=true]. --status-bar-contents Textual template for the contents of the status bar. --rest Enable the REST server [=false]. --rest-port Port for the REST server [=5052]. --rest-address Listening address of the REST server [=127.0.0.1]. --rest-allow-origin Limit the access to the REST API to a particular hostname (for CORS-enabled clients such as browsers). --rest-statecache-size The maximum number of recently accessed states that are kept in memory. Speeds up requests obtaining information for consecutive slots or epochs. [=3]. --rest-statecache-ttl The number of seconds to keep recently accessed states in memory [=60]. --rest-request-timeout The number of seconds to wait until complete REST request will be received [=infinite]. --rest-max-body-size Maximum size of REST request body (kilobytes) [=16384]. --rest-max-headers-size Maximum size of REST request headers (kilobytes) [=128]. --keymanager Enable the REST keymanager API [=false]. --keymanager-port Listening port for the REST keymanager API [=5052]. --keymanager-address Listening port for the REST keymanager API [=127.0.0.1]. --keymanager-allow-origin Limit the access to the Keymanager API to a particular hostname (for CORS-enabled clients such as browsers). --keymanager-token-file A file specifying the authorization token required for accessing the keymanager API. --light-client-data-serve Serve data for enabling light clients to stay in sync with the network [=true]. --light-client-data-import-mode Which classes of light client data to import. Must be one of: none, only-new, full (slow startup), on-demand (may miss validator duties) [=only-new]. --light-client-data-max-periods Maximum number of sync committee periods to retain light client data. --long-range-sync Enable long-range syncing (genesis sync) [=LongRangeSyncMode.Light]. --in-process-validators Disable the push model (the beacon node tells a signing process with the private keys of the validators what to sign and when) and load the validators in the beacon node itself [=true]. --discv5 Enable Discovery v5 [=true]. --dump Write SSZ dumps of blocks, attestations and states to data dir [=false]. --direct-peer The list of privileged, secure and known peers to connect and maintain the connection to. This requires a not random netkey-file. In the multiaddress format like: /ip4/<address>/tcp/<port>/p2p/<peerId-public-key>, or enr format (enr:-xx). Peering agreements are established out of band and must be reciprocal. --doppelganger-detection If enabled, the beacon node prudently listens for 2 epochs for attestations from a validator with the same index (a doppelganger), before sending an attestation itself. This protects against slashing (due to double-voting) but means you will miss two attestations when restarting. [=true]. --validator-monitor-auto Monitor validator activity automatically for validators active on this beacon node [=true]. --validator-monitor-pubkey One or more validators to monitor - works best when --subscribe-all-subnets is enabled. --validator-monitor-details Publish detailed metrics for each validator individually - may incur significant overhead with large numbers of validators [=false]. --suggested-fee-recipient Suggested fee recipient. --suggested-gas-limit Suggested gas limit [=defaultGasLimit]. --payload-builder Enable external payload builder [=false]. --payload-builder-url Payload builder URL. --local-block-value-boost Increase execution layer block values for builder bid comparison by a percentage [=10]. --history Retention strategy for historical data (archive/prune) [=HistoryMode.Prune]. ... Any debug -prefixed flags are considered ephemeral and subject to removal without notice.","title":"Available options"},{"location":"options.html#configuration-files","text":"All command line options can also be provided in a TOML config file specified through the --config-file flag. Within the config file, you need to use the long names of all options. Please note that certain options such as web3-url , bootstrap-node , direct-peer , and validator-monitor-pubkey can be supplied more than once on the command line: in the TOML file, you need to supply them as arrays. There are also some minor differences in the parsing of certain option values in the TOML files in order to conform more closely to existing TOML standards. For example, you can freely use keywords such as on , off , yes and no on the command-line as synonyms for the canonical values true and false which are mandatory to use in TOML. Options affecting Nimbus sub-commands should appear in a section of the file matching the sub-command name. Here is an example config file illustrating all of the above: nimbus-eth2.toml # Comments look like this doppelganger-detection = true web3-url = [ \"http://127.0.0.1:8551\" ] num-threads = 0 [trustedNodeSync] trusted-node-url = \"http://192.168.1.20:5052\"","title":"Configuration files"},{"location":"options.html#exit-codes","text":"Exit code Description 0 Successful exit 1 Generic failure or unspecified error 129 Doppelganger detection; one might prefer not to restart automatically","title":"Exit Codes"},{"location":"pi-guide.html","text":"Running on a Raspberry Pi I expect the new Raspberry Pi 4 (4GB RAM option, external SSD) to handle an Eth2 validator node without breaking a sweat. That's $100 of hardware running at 10 Watts to support a 32 ETH node (currently ~$10K stake). \u2014 Justin \u00d0rake (@drakefjustin) June 24, 2019 In addition to this guide, we highly recommend this wonderful and complementary resource by community member Joe Clapis. Introduction This page will take you through how to use your laptop to program your Raspberry Pi. One of the most important aspects of the Raspberry Pi experience is trying to make it as easy as possible to get started. As such, we try our best to explain things from first-principles. Prerequisites Raspberry Pi 4 4GB (8GB recommended if also running execution client) 64GB microSD Card microSD USB adapter 5V 3A USB-C charger Reliable Wi-Fi connection Laptop Basic understanding of the command line 200GB SSD (2TB recommended if also running execution client) Note You will need an SSD to run the Nimbus: mechanical hard drives are typically too slow to run an Ethereum node. You have two options: Use an USB portable SSD disk such as the Samsung T5 Portable SSD. Use an USB 3.0 External Hard Drive Case with a SSD Disk. For example, Ethereum on Arm use an Inateck 2.5 Hard Drive Enclosure FE2011. Make sure to buy a case with an UASP compliant chip, particularly, one of these: JMicron (JMS567 or JMS578) or ASMedia (ASM1153E). In both cases, avoid low quality SSD disks (the SSD is a key component of your node and can drastically affect both the performance and sync time). Keep in mind that you need to plug the disk to an USB 3.0 port (the blue port). Note If you have a Raspberry Pi 4 and are getting bad speeds transferring data to/from USB3.0 SSDs, please read this recommended fix . Steps 1. Download Raspberry Pi Imager Raspberry Pi Imager is an imaging utility that makes it simple to manage your microSD card with Raspberry Pi OS (the free Pi operating system based on Debian, previously called Raspbian). You can find the download link for your operating system here: Windows , macOS , Ubuntu . 2. Download 64-bit Raspberry Pi OS You need to install the 64-bit version of Raspberry Pi OS. You can find the latest version, here . 3. Plug in SD card Use your microSD to USB adapter to plug the SD card into your computer. 4. Download Raspberry Pi OS Open Raspberry Pi Imager and click on CHOOSE OS : Scroll down and click on Use custom : Find the OS you downloaded in step 2: 4b. Write to SD card Click on CHOOSE SD CARD . You should see a menu pop-up with your SD card listed -- Select it Click on WRITE Click YES Make a cup of coffee :) 5. Set up wireless LAN Since you have loaded Raspberry Pi OS onto a blank SD card, you will have two partitions. The first one, which is the smaller one, is the boot partition. Create a wpa_supplicant configuration file in the boot partition with the following content: # wpa_supplicant.conf ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 country=<Insert 2 letter ISO 3166-1 country code here> network={ ssid=\"<Insert your Wifi network's name here>\" psk=\"<Insert your Wifi network's password here>\" } Note Don't forget to replace the placeholder country , ssid , and psk values. See Wikipedia for a list of 2 letter ISO 3166-1 country codes. 6. Enable SSH (using Linux or macOS) You can access the command line of a Raspberry Pi remotely from another computer or device on the same network using SSH . While SSH is not enabled by default, you can enable it by placing a file named ssh , without any extension, onto the boot partition of the SD card. When the Pi boots, it will look for the ssh file. If it is found, SSH is enabled and the file is deleted. The content of the file does not matter; it can contain text, or nothing at all. To create an empty ssh file, from the home directory of the boot partition file, run: touch ssh 7. Find your Pi's IP address Since Raspberry Pi OS supports Multicast_DNS out of the box, you can reach your Raspberry Pi by using its hostname and the .local suffix. The default hostname on a fresh Raspberry Pi OS install is raspberrypi , so any Raspberry Pi running Raspberry Pi OS should respond to: ping raspberrypi.local The output should look more or less as follows: PING raspberrypi.local ( 195 .177.101.93 ) : 56 data bytes 64 bytes from 195 .177.101.93: icmp_seq = 0 ttl = 64 time = 13 .272 ms 64 bytes from 195 .177.101.93: icmp_seq = 1 ttl = 64 time = 16 .773 ms 64 bytes from 195 .177.101.93: icmp_seq = 2 ttl = 64 time = 10 .828 ms ... Keep note of your Pi's IP address. In the above case, that's 195.177.101.93 8. SSH (using Linux or macOS) Connect to your Pi by running: ssh pi@195.177.101.93 You'll be prompted to enter a password: pi@195.177.101.93's password: Enter the Pi's default password: raspberry You should see a message that looks like the following: Linux raspberrypi 5.4.51-v8+ #1333 SMP PREEMPT Mon Aug 10 16:58:35 BST 2020 aarch64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Thu Aug 20 12:59:01 2020 SSH is enabled and the default password for the 'pi' user has not been changed. This is a security risk - please login as the 'pi' user and type 'passwd' to set a new password. Followed by a command-line prompt indicating a successful connection: pi@raspberrypi:~ $ 9. Increase swap size to 2GB The first step is to increase the swap size to 2GB (2048MB). Note Swap acts as a breather to your system when the RAM is exhausted. When the RAM is exhausted, your Linux system uses part of the hard disk memory and allocates it to the running application. Use the Pi's built-in text editor nano to open up the swap file: sudo nano /etc/dphys-swapfile Change the value assigned to CONF_SWAPSIZE from 100 to 2048 : ... # set size to absolute value, leaving empty (default) then uses computed value # you most likely don't want this, unless you have a special disk situation CONF_SWAPSIZE=2048 ... Save ( Ctrl+S ) and exit ( Ctrl+X ). 10. Reboot Reboot your Pi to have the above changes take effect: sudo reboot This will cause your connection to close. So you'll need to ssh into your Pi again: ssh pi@195.177.101.93 Note Remember to replace 195.177.101.93 with the IP address of your Pi. 10b. Boot from external SSD Follow this RPi4 guide to copy the contents of your SD card over to your SSD, and boot your Pi from your SSD. Tip Make sure you connect your SSD the Pi's USB 3 port (the blue port). If your Pi is headless (no monitor attached) you can use the rpi-clone repository to copy the contents of the SD over to the SSD; in a nutshell, replace steps 14 and 15 of the above guide with the following commands (which you should run from the Pi's home directory): git clone https://github.com/billw2/rpi-clone.git cd rpi-clone sudo cp rpi-clone rpi-clone-setup /usr/local/sbin sudo rpi-clone-setup -t testhostname rpi-clone sda For more on raspi-config , see here . Tip To shutdown your Pi safely, run sudo shutdown -h now Once you're done, ssh back into your Pi. 11. Overclocking Nimbus requires the Raspberry Pi to be overclocked. To overclock your Raspberry Pi, you need to add two lines to the /boot/firmware/usercfg.txt file: sudo nano /boot/firmware/usercfg.txt Add the following two lines to the end of the file: arm_freq=1800 over_voltage=3 Save the file and reboot. This increases the CPU clock from 1500 MHz to 1800 MHz and raises the CPU voltage from 0.88 V to 0.93 V. To read more about testing the stability of an overclock and benchmarking, follow the RPi overclocking guide by Joe Clapis. 12. Install the beacon node Using package manager Manual installation Add Status APT repository to your system. echo 'deb https://apt.status.im/nimbus all main' | sudo tee /etc/apt/sources.list.d/nimbus.list # Import the GPG key used to sign the releases: sudo curl https://apt.status.im/pubkey.asc -o /etc/apt/trusted.gpg.d/apt-status-im.asc Install Nimbus using APT: sudo apt-get update sudo apt-get install nimbus-beacon-node nimbus-validator-client Open the Nimbus eth2 releases page , go to the Assets on the bottom of the page, and copy the link for the file that starts with nimbus-eth2_Linux_arm64v8 . Run this in your home directory to download nimbus-eth2: mkdir nimbus-eth2 wget <insert download link here> tar -xzf nimbus-eth2_Linux_arm64v8*.tar.gz -C nimbus-eth2 rm nimbus-eth2_Linux_arm64v8*.tar.gz Now you can find the software in the nimbus-eth2 directory. 13. Copy signing key over to Pi Note If you haven't generated your validator key(s) and/or made your deposit yet, follow the deposit instructions of our validator guide before carrying on. We'll use the scp command to send files over SSH. It allows you to copy files between computers, say from your Raspberry Pi to your desktop/laptop, or vice-versa. Copy the folder containing your validator key(s) from your computer to your pi 's home folder by opening up a new terminal window and running the following command: scp -r <VALIDATOR_KEYS_DIRECTORY> pi@195.177.101.93: Note Don't forget the colon (:) at the end of the command! As usual, replace 195.177.101.93 with your Pi's IP address, and <VALIDATOR_KEYS_DIRECTORY> with the full pathname of your validator_keys directory (if you used the Launchpad command line app this would have been created for you when you generated your keys). Tip Run pwd in your validator_keys directory to print the full pathname to the console. 14. Import signing key into Nimbus Depending on your installation method, run these commands to import your signing key into Nimbus: Using package manager Manual installation # Run import command as the `nimbus` user sudo -u nimbus /usr/bin/nimbus_beacon_node deposits import --data-dir = /var/lib/nimbus/shared_holesky_0 /path/to/keys To import your signing key into Nimbus, from the nimbus-eth2 directory run. build/nimbus_beacon_node deposits import --data-dir = build/data/shared_holesky_0 ../validator_keys You'll be asked to enter the password you created to encrypt your keystore(s). Don't worry, this is entirely normal. Your validator client needs both your signing keystore(s) and the password encrypting it to import your key (since it needs to decrypt the keystore in order to be able to use it to sign on your behalf). 15. Connect to Holesky We're finally ready to connect to the Holesky testnet! Note If you haven't already, we recommend registering for, and running, your own eth1 node in parallel. For instructions on how to do so, see the eth1 page . To connect to Holesky, run: Using package manager Manual installation sudo -u nimbus /usr/bin/nimbus_beacon_node --network = holesky --data-dir = /var/lib/nimbus/shared_holesky_0 ./run-holesky-beacon-node.sh 16. Check for successful connection If you look near the top of the logs printed to your console, you should see confirmation that your beacon node has started, with your local validator attached: INF 2023-10-01 11:25:33.487+01:00 Launching beacon node ... INF 2023-10-01 11:25:34.556+01:00 Loading block dag from database topics=\"beacnde\" tid=19985314 file=nimbus_beacon_node.nim:198 path=build/data/shared_holesky_0/db INF 2023-10-01 11:25:35.921+01:00 Block dag initialized INF 2023-10-01 11:25:37.073+01:00 Generating new networking key ... NTC 2023-10-01 11:25:45.267+00:00 Local validator attached tid=22009 file=validator_pool.nim:33 pubkey=95e3cbe88c71ab2d0e3053b7b12ead329a37e9fb8358bdb4e56251993ab68e46b9f9fa61035fe4cf2abf4c07dfad6c45 validator=95e3cbe8 ... NTC 2023-10-01 11:25:59.512+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 blockNumber=3836397 depositsProcessed=106147 NTC 2023-10-01 11:26:02.574+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 blockNumber=3841412 depositsProcessed=106391 ... INF 2023-10-01 11:26:31.000+00:00 Slot start topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:505 lastSlot=96566 scheduledSlot=96567 beaconTime=1w6d9h53m24s944us774ns peers=7 head=b54486c4:96563 headEpoch=3017 finalized=2f5d12e4:96479 finalizedEpoch=3014 INF 2023-10-01 11:26:36.285+00:00 Slot end topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:593 slot=96567 nextSlot=96568 head=b54486c4:96563 headEpoch=3017 finalizedHead=2f5d12e4:96479 finalizedEpoch=3014 To keep track of your syncing progress, have a look at the output at the very bottom of the terminal window in which your validator is running. You should see something like: peers: 15 \u276f finalized: ada7228a:8765 \u276f head: b2fe11cd:8767:2 \u276f time: 9900:7 (316807) \u276f sync: wPwwwwwDwwDPwPPPwwww:7:1.2313:1.0627:12h01m(280512) Keep an eye on the number of peers you're currently connected to (in the above case that's 15 ), as well as your sync progress . Note 15 - 20 peers and an average sync speed of 0.5 - 1.0 blocks per second is normal on Holesky with a Pi. If your sync speed is much slower than this, the root of the problem may be your USB3.0 to SSD adapter. See this post for a recommended workaround. Mainnet advice Whether or not your Pi is up to the task will depend on a number of factors such as SSD speed, network connectivity, etc. As such, it's best to verify performance on a testnet first. The best thing you can do is to set your Pi to run Holesky. If you have no trouble syncing and attesting on Holesky, your setup should good enough for mainnet as well. We've been running lots of PIs and NanoPCs 24/7 for 3 years and never got a hardware fail. It is easy (and cheap) to get redundancy of components (even spare PIs in different locations, more of this to come). \u2014 Ethereum on ARM (@EthereumOnARM) November 28, 2020 Although we don't expect a modern Pi to fail, we recommend buying a spare Pi, and enterprise grade SSD, on the off-chance it does; keep your original SD around, to make it easy for you to copy the image over. Systemd Now that you have Nimbus up and running, we recommend setting up a systemd service with an autorestart on boot (should you experience an unexpected power outage, this will ensure your validator restarts correctly). Systemd will also ensure your validator keeps running when you exit your ssh session ( Ctrl-C ) and/or switch off your laptop. For the details on how to do this, see our systemd guide .","title":"Running on a Raspberry Pi"},{"location":"pi-guide.html#running-on-a-raspberry-pi","text":"I expect the new Raspberry Pi 4 (4GB RAM option, external SSD) to handle an Eth2 validator node without breaking a sweat. That's $100 of hardware running at 10 Watts to support a 32 ETH node (currently ~$10K stake). \u2014 Justin \u00d0rake (@drakefjustin) June 24, 2019 In addition to this guide, we highly recommend this wonderful and complementary resource by community member Joe Clapis.","title":"Running on a Raspberry Pi"},{"location":"pi-guide.html#introduction","text":"This page will take you through how to use your laptop to program your Raspberry Pi. One of the most important aspects of the Raspberry Pi experience is trying to make it as easy as possible to get started. As such, we try our best to explain things from first-principles.","title":"Introduction"},{"location":"pi-guide.html#prerequisites","text":"Raspberry Pi 4 4GB (8GB recommended if also running execution client) 64GB microSD Card microSD USB adapter 5V 3A USB-C charger Reliable Wi-Fi connection Laptop Basic understanding of the command line 200GB SSD (2TB recommended if also running execution client) Note You will need an SSD to run the Nimbus: mechanical hard drives are typically too slow to run an Ethereum node. You have two options: Use an USB portable SSD disk such as the Samsung T5 Portable SSD. Use an USB 3.0 External Hard Drive Case with a SSD Disk. For example, Ethereum on Arm use an Inateck 2.5 Hard Drive Enclosure FE2011. Make sure to buy a case with an UASP compliant chip, particularly, one of these: JMicron (JMS567 or JMS578) or ASMedia (ASM1153E). In both cases, avoid low quality SSD disks (the SSD is a key component of your node and can drastically affect both the performance and sync time). Keep in mind that you need to plug the disk to an USB 3.0 port (the blue port). Note If you have a Raspberry Pi 4 and are getting bad speeds transferring data to/from USB3.0 SSDs, please read this recommended fix .","title":"Prerequisites"},{"location":"pi-guide.html#steps","text":"","title":"Steps"},{"location":"pi-guide.html#1-download-raspberry-pi-imager","text":"Raspberry Pi Imager is an imaging utility that makes it simple to manage your microSD card with Raspberry Pi OS (the free Pi operating system based on Debian, previously called Raspbian). You can find the download link for your operating system here: Windows , macOS , Ubuntu .","title":"1. Download Raspberry Pi Imager"},{"location":"pi-guide.html#2-download-64-bit-raspberry-pi-os","text":"You need to install the 64-bit version of Raspberry Pi OS. You can find the latest version, here .","title":"2. Download 64-bit Raspberry Pi OS"},{"location":"pi-guide.html#3-plug-in-sd-card","text":"Use your microSD to USB adapter to plug the SD card into your computer.","title":"3. Plug in SD card"},{"location":"pi-guide.html#4-download-raspberry-pi-os","text":"Open Raspberry Pi Imager and click on CHOOSE OS : Scroll down and click on Use custom : Find the OS you downloaded in step 2:","title":"4. Download Raspberry Pi OS"},{"location":"pi-guide.html#4b-write-to-sd-card","text":"Click on CHOOSE SD CARD . You should see a menu pop-up with your SD card listed -- Select it Click on WRITE Click YES Make a cup of coffee :)","title":"4b. Write to SD card"},{"location":"pi-guide.html#5-set-up-wireless-lan","text":"Since you have loaded Raspberry Pi OS onto a blank SD card, you will have two partitions. The first one, which is the smaller one, is the boot partition. Create a wpa_supplicant configuration file in the boot partition with the following content: # wpa_supplicant.conf ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 country=<Insert 2 letter ISO 3166-1 country code here> network={ ssid=\"<Insert your Wifi network's name here>\" psk=\"<Insert your Wifi network's password here>\" } Note Don't forget to replace the placeholder country , ssid , and psk values. See Wikipedia for a list of 2 letter ISO 3166-1 country codes.","title":"5. Set up wireless LAN"},{"location":"pi-guide.html#6-enable-ssh-using-linux-or-macos","text":"You can access the command line of a Raspberry Pi remotely from another computer or device on the same network using SSH . While SSH is not enabled by default, you can enable it by placing a file named ssh , without any extension, onto the boot partition of the SD card. When the Pi boots, it will look for the ssh file. If it is found, SSH is enabled and the file is deleted. The content of the file does not matter; it can contain text, or nothing at all. To create an empty ssh file, from the home directory of the boot partition file, run: touch ssh","title":"6. Enable SSH (using Linux or macOS)"},{"location":"pi-guide.html#7-find-your-pis-ip-address","text":"Since Raspberry Pi OS supports Multicast_DNS out of the box, you can reach your Raspberry Pi by using its hostname and the .local suffix. The default hostname on a fresh Raspberry Pi OS install is raspberrypi , so any Raspberry Pi running Raspberry Pi OS should respond to: ping raspberrypi.local The output should look more or less as follows: PING raspberrypi.local ( 195 .177.101.93 ) : 56 data bytes 64 bytes from 195 .177.101.93: icmp_seq = 0 ttl = 64 time = 13 .272 ms 64 bytes from 195 .177.101.93: icmp_seq = 1 ttl = 64 time = 16 .773 ms 64 bytes from 195 .177.101.93: icmp_seq = 2 ttl = 64 time = 10 .828 ms ... Keep note of your Pi's IP address. In the above case, that's 195.177.101.93","title":"7. Find your Pi's IP address"},{"location":"pi-guide.html#8-ssh-using-linux-or-macos","text":"Connect to your Pi by running: ssh pi@195.177.101.93 You'll be prompted to enter a password: pi@195.177.101.93's password: Enter the Pi's default password: raspberry You should see a message that looks like the following: Linux raspberrypi 5.4.51-v8+ #1333 SMP PREEMPT Mon Aug 10 16:58:35 BST 2020 aarch64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Thu Aug 20 12:59:01 2020 SSH is enabled and the default password for the 'pi' user has not been changed. This is a security risk - please login as the 'pi' user and type 'passwd' to set a new password. Followed by a command-line prompt indicating a successful connection: pi@raspberrypi:~ $","title":"8. SSH (using Linux or macOS)"},{"location":"pi-guide.html#9-increase-swap-size-to-2gb","text":"The first step is to increase the swap size to 2GB (2048MB). Note Swap acts as a breather to your system when the RAM is exhausted. When the RAM is exhausted, your Linux system uses part of the hard disk memory and allocates it to the running application. Use the Pi's built-in text editor nano to open up the swap file: sudo nano /etc/dphys-swapfile Change the value assigned to CONF_SWAPSIZE from 100 to 2048 : ... # set size to absolute value, leaving empty (default) then uses computed value # you most likely don't want this, unless you have a special disk situation CONF_SWAPSIZE=2048 ... Save ( Ctrl+S ) and exit ( Ctrl+X ).","title":"9. Increase swap size to 2GB"},{"location":"pi-guide.html#10-reboot","text":"Reboot your Pi to have the above changes take effect: sudo reboot This will cause your connection to close. So you'll need to ssh into your Pi again: ssh pi@195.177.101.93 Note Remember to replace 195.177.101.93 with the IP address of your Pi.","title":"10. Reboot"},{"location":"pi-guide.html#10b-boot-from-external-ssd","text":"Follow this RPi4 guide to copy the contents of your SD card over to your SSD, and boot your Pi from your SSD. Tip Make sure you connect your SSD the Pi's USB 3 port (the blue port). If your Pi is headless (no monitor attached) you can use the rpi-clone repository to copy the contents of the SD over to the SSD; in a nutshell, replace steps 14 and 15 of the above guide with the following commands (which you should run from the Pi's home directory): git clone https://github.com/billw2/rpi-clone.git cd rpi-clone sudo cp rpi-clone rpi-clone-setup /usr/local/sbin sudo rpi-clone-setup -t testhostname rpi-clone sda For more on raspi-config , see here . Tip To shutdown your Pi safely, run sudo shutdown -h now Once you're done, ssh back into your Pi.","title":"10b. Boot from external SSD"},{"location":"pi-guide.html#11-overclocking","text":"Nimbus requires the Raspberry Pi to be overclocked. To overclock your Raspberry Pi, you need to add two lines to the /boot/firmware/usercfg.txt file: sudo nano /boot/firmware/usercfg.txt Add the following two lines to the end of the file: arm_freq=1800 over_voltage=3 Save the file and reboot. This increases the CPU clock from 1500 MHz to 1800 MHz and raises the CPU voltage from 0.88 V to 0.93 V. To read more about testing the stability of an overclock and benchmarking, follow the RPi overclocking guide by Joe Clapis.","title":"11. Overclocking"},{"location":"pi-guide.html#12-install-the-beacon-node","text":"Using package manager Manual installation Add Status APT repository to your system. echo 'deb https://apt.status.im/nimbus all main' | sudo tee /etc/apt/sources.list.d/nimbus.list # Import the GPG key used to sign the releases: sudo curl https://apt.status.im/pubkey.asc -o /etc/apt/trusted.gpg.d/apt-status-im.asc Install Nimbus using APT: sudo apt-get update sudo apt-get install nimbus-beacon-node nimbus-validator-client Open the Nimbus eth2 releases page , go to the Assets on the bottom of the page, and copy the link for the file that starts with nimbus-eth2_Linux_arm64v8 . Run this in your home directory to download nimbus-eth2: mkdir nimbus-eth2 wget <insert download link here> tar -xzf nimbus-eth2_Linux_arm64v8*.tar.gz -C nimbus-eth2 rm nimbus-eth2_Linux_arm64v8*.tar.gz Now you can find the software in the nimbus-eth2 directory.","title":"12. Install the beacon node"},{"location":"pi-guide.html#13-copy-signing-key-over-to-pi","text":"Note If you haven't generated your validator key(s) and/or made your deposit yet, follow the deposit instructions of our validator guide before carrying on. We'll use the scp command to send files over SSH. It allows you to copy files between computers, say from your Raspberry Pi to your desktop/laptop, or vice-versa. Copy the folder containing your validator key(s) from your computer to your pi 's home folder by opening up a new terminal window and running the following command: scp -r <VALIDATOR_KEYS_DIRECTORY> pi@195.177.101.93: Note Don't forget the colon (:) at the end of the command! As usual, replace 195.177.101.93 with your Pi's IP address, and <VALIDATOR_KEYS_DIRECTORY> with the full pathname of your validator_keys directory (if you used the Launchpad command line app this would have been created for you when you generated your keys). Tip Run pwd in your validator_keys directory to print the full pathname to the console.","title":"13. Copy signing key over to Pi"},{"location":"pi-guide.html#14-import-signing-key-into-nimbus","text":"Depending on your installation method, run these commands to import your signing key into Nimbus: Using package manager Manual installation # Run import command as the `nimbus` user sudo -u nimbus /usr/bin/nimbus_beacon_node deposits import --data-dir = /var/lib/nimbus/shared_holesky_0 /path/to/keys To import your signing key into Nimbus, from the nimbus-eth2 directory run. build/nimbus_beacon_node deposits import --data-dir = build/data/shared_holesky_0 ../validator_keys You'll be asked to enter the password you created to encrypt your keystore(s). Don't worry, this is entirely normal. Your validator client needs both your signing keystore(s) and the password encrypting it to import your key (since it needs to decrypt the keystore in order to be able to use it to sign on your behalf).","title":"14. Import signing key into Nimbus"},{"location":"pi-guide.html#15-connect-to-holesky","text":"We're finally ready to connect to the Holesky testnet! Note If you haven't already, we recommend registering for, and running, your own eth1 node in parallel. For instructions on how to do so, see the eth1 page . To connect to Holesky, run: Using package manager Manual installation sudo -u nimbus /usr/bin/nimbus_beacon_node --network = holesky --data-dir = /var/lib/nimbus/shared_holesky_0 ./run-holesky-beacon-node.sh","title":"15. Connect to Holesky"},{"location":"pi-guide.html#16-check-for-successful-connection","text":"If you look near the top of the logs printed to your console, you should see confirmation that your beacon node has started, with your local validator attached: INF 2023-10-01 11:25:33.487+01:00 Launching beacon node ... INF 2023-10-01 11:25:34.556+01:00 Loading block dag from database topics=\"beacnde\" tid=19985314 file=nimbus_beacon_node.nim:198 path=build/data/shared_holesky_0/db INF 2023-10-01 11:25:35.921+01:00 Block dag initialized INF 2023-10-01 11:25:37.073+01:00 Generating new networking key ... NTC 2023-10-01 11:25:45.267+00:00 Local validator attached tid=22009 file=validator_pool.nim:33 pubkey=95e3cbe88c71ab2d0e3053b7b12ead329a37e9fb8358bdb4e56251993ab68e46b9f9fa61035fe4cf2abf4c07dfad6c45 validator=95e3cbe8 ... NTC 2023-10-01 11:25:59.512+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 blockNumber=3836397 depositsProcessed=106147 NTC 2023-10-01 11:26:02.574+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 blockNumber=3841412 depositsProcessed=106391 ... INF 2023-10-01 11:26:31.000+00:00 Slot start topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:505 lastSlot=96566 scheduledSlot=96567 beaconTime=1w6d9h53m24s944us774ns peers=7 head=b54486c4:96563 headEpoch=3017 finalized=2f5d12e4:96479 finalizedEpoch=3014 INF 2023-10-01 11:26:36.285+00:00 Slot end topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:593 slot=96567 nextSlot=96568 head=b54486c4:96563 headEpoch=3017 finalizedHead=2f5d12e4:96479 finalizedEpoch=3014 To keep track of your syncing progress, have a look at the output at the very bottom of the terminal window in which your validator is running. You should see something like: peers: 15 \u276f finalized: ada7228a:8765 \u276f head: b2fe11cd:8767:2 \u276f time: 9900:7 (316807) \u276f sync: wPwwwwwDwwDPwPPPwwww:7:1.2313:1.0627:12h01m(280512) Keep an eye on the number of peers you're currently connected to (in the above case that's 15 ), as well as your sync progress . Note 15 - 20 peers and an average sync speed of 0.5 - 1.0 blocks per second is normal on Holesky with a Pi. If your sync speed is much slower than this, the root of the problem may be your USB3.0 to SSD adapter. See this post for a recommended workaround.","title":"16. Check for successful connection"},{"location":"pi-guide.html#mainnet-advice","text":"Whether or not your Pi is up to the task will depend on a number of factors such as SSD speed, network connectivity, etc. As such, it's best to verify performance on a testnet first. The best thing you can do is to set your Pi to run Holesky. If you have no trouble syncing and attesting on Holesky, your setup should good enough for mainnet as well. We've been running lots of PIs and NanoPCs 24/7 for 3 years and never got a hardware fail. It is easy (and cheap) to get redundancy of components (even spare PIs in different locations, more of this to come). \u2014 Ethereum on ARM (@EthereumOnARM) November 28, 2020 Although we don't expect a modern Pi to fail, we recommend buying a spare Pi, and enterprise grade SSD, on the off-chance it does; keep your original SD around, to make it easy for you to copy the image over.","title":"Mainnet advice"},{"location":"pi-guide.html#systemd","text":"Now that you have Nimbus up and running, we recommend setting up a systemd service with an autorestart on boot (should you experience an unexpected power outage, this will ensure your validator restarts correctly). Systemd will also ensure your validator keeps running when you exit your ssh session ( Ctrl-C ) and/or switch off your laptop. For the details on how to do this, see our systemd guide .","title":"Systemd"},{"location":"prater.html","text":"This page has been removed. Use the Hole\u0161ky testnet .","title":"Prater"},{"location":"preparation.html","text":"Mainnet checklist Latest software Please check that you are running the latest stable Nimbus software release . Tip In order to stay on top of new releases you should subscribe to our mailing list . More than 15 peers Please check that your node has at least 15 peers. To monitor your peer count, pay attention to the Slot start messages in your logs . See the networking page for more tips. Validator attached Please check that your validator is attached to your node. Systemd We recommend setting up a systemd service with an autorestart on boot. Should you experience an unexpected power outage, this will ensure your validator restarts correctly. Systemd will also ensure your validator keeps running when you exit your ssh session ( Ctrl-C ) and/or switch off your laptop. Ethereum Foundation's Checklist As a final check, we recommend you also go through the EF'S staker checklist .","title":"Mainnet checklist"},{"location":"preparation.html#mainnet-checklist","text":"","title":"Mainnet checklist"},{"location":"preparation.html#latest-software","text":"Please check that you are running the latest stable Nimbus software release . Tip In order to stay on top of new releases you should subscribe to our mailing list .","title":"Latest software"},{"location":"preparation.html#more-than-15-peers","text":"Please check that your node has at least 15 peers. To monitor your peer count, pay attention to the Slot start messages in your logs . See the networking page for more tips.","title":"More than 15 peers"},{"location":"preparation.html#validator-attached","text":"Please check that your validator is attached to your node.","title":"Validator attached"},{"location":"preparation.html#systemd","text":"We recommend setting up a systemd service with an autorestart on boot. Should you experience an unexpected power outage, this will ensure your validator restarts correctly. Systemd will also ensure your validator keeps running when you exit your ssh session ( Ctrl-C ) and/or switch off your laptop.","title":"Systemd"},{"location":"preparation.html#ethereum-foundations-checklist","text":"As a final check, we recommend you also go through the EF'S staker checklist .","title":"Ethereum Foundation's Checklist"},{"location":"profits.html","text":"Optimize for profitability Key insights: Profitability depends heavily on the network and peer quality. While block proposals are more lucrative than attestations, they are much rarer. Check for next action before restarting To see when your validator is next due to make an attestation or proposal pay attention to the Slot end messages in your logs: INF 2021-05-31 17:46:11.094+02:00 Slot end topics=\"beacnde\" tid=213670 file=nimbus_beacon_node.nim:932 slot=1304329 nextSlot=1304330 head=cffee454:38460 headEpoch=1201 finalizedHead=077da232:38368 finalizedEpoch=1199 nextAttestationSlot=338638 nextProposalSlot=-1 nextActionWait=4m35s874ms405us837ns Specifically, have a look at nextActionWait time. If you're concerned about missing an attestation or proposal, wait until nextActionWait is greater than 4 minutes or so before restarting Nimbus. You can also use the nimbus-eth2 API . For example, to check if your validator has a next Proposal slot assigned, run: curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_duties_proposer\",\"params\":[${HEAD_EPOCH_NUMBER}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq \".result[]\" | grep ${PATTERN_WHICH_MATCHES_VALIDATOR_PUBLIC_KEYS} Subscribe to all subnets Launching the beacon node with the --subscribe-all-subnets option increases bandwidth and cpu usage, but helps the network and makes the block production algorithm perform slightly better. To elaborate a little, without this option enabled Nimbus only listens to a subset of the attestation traffic: in particular, Nimbus doesn't listen to all unaggregated traffic but instead relies on peers to aggregate attestations on the subnets it doesn't subscribe to. With this option enabled, Nimbus listens to all unaggregated channels (subscribes to all subnets). Practically speaking, this means that when producing a block, Nimbus can \"top up\" the aggregates that other peers have made with it's own unaggregated attestations. This can lead to better packing in some cases, which can lead to slightly greater rewards. Useful resources The journey of a validator balance Validator rewards in practice","title":"Optimize for profitability"},{"location":"profits.html#optimize-for-profitability","text":"Key insights: Profitability depends heavily on the network and peer quality. While block proposals are more lucrative than attestations, they are much rarer.","title":"Optimize for profitability"},{"location":"profits.html#check-for-next-action-before-restarting","text":"To see when your validator is next due to make an attestation or proposal pay attention to the Slot end messages in your logs: INF 2021-05-31 17:46:11.094+02:00 Slot end topics=\"beacnde\" tid=213670 file=nimbus_beacon_node.nim:932 slot=1304329 nextSlot=1304330 head=cffee454:38460 headEpoch=1201 finalizedHead=077da232:38368 finalizedEpoch=1199 nextAttestationSlot=338638 nextProposalSlot=-1 nextActionWait=4m35s874ms405us837ns Specifically, have a look at nextActionWait time. If you're concerned about missing an attestation or proposal, wait until nextActionWait is greater than 4 minutes or so before restarting Nimbus. You can also use the nimbus-eth2 API . For example, to check if your validator has a next Proposal slot assigned, run: curl -d '{\"jsonrpc\":\"2.0\",\"method\":\"get_v1_validator_duties_proposer\",\"params\":[${HEAD_EPOCH_NUMBER}],\"id\":1}' -H 'Content-Type: application/json' localhost:9190 -s | jq \".result[]\" | grep ${PATTERN_WHICH_MATCHES_VALIDATOR_PUBLIC_KEYS}","title":"Check for next action before restarting"},{"location":"profits.html#subscribe-to-all-subnets","text":"Launching the beacon node with the --subscribe-all-subnets option increases bandwidth and cpu usage, but helps the network and makes the block production algorithm perform slightly better. To elaborate a little, without this option enabled Nimbus only listens to a subset of the attestation traffic: in particular, Nimbus doesn't listen to all unaggregated traffic but instead relies on peers to aggregate attestations on the subnets it doesn't subscribe to. With this option enabled, Nimbus listens to all unaggregated channels (subscribes to all subnets). Practically speaking, this means that when producing a block, Nimbus can \"top up\" the aggregates that other peers have made with it's own unaggregated attestations. This can lead to better packing in some cases, which can lead to slightly greater rewards.","title":"Subscribe to all subnets"},{"location":"profits.html#useful-resources","text":"The journey of a validator balance Validator rewards in practice","title":"Useful resources"},{"location":"quick-start.html","text":"Beacon node This page takes you through the steps of getting a standard installation of the Nimbus beacon node running. The quickstart setup involves running two nodes: an execution client and a beacon node. Both are needed to run a full Ethereum setup. To become a validator, you first need to set up a beacon node. The beacon node connects to the beacon chain network, syncs historical data, and provides API's to monitor and interact with the beacon chain. Running a beacon node is a worthwhile endeavor even if you are not planning on validating yourself! The guide assumes Ubuntu Linux is being used, and therefore some familiarity with the Linux command line is needed. Tip You can practice running the node safely on the Holesky testnet . Throughout, we'll provide instructions for both Holesky and Mainnet. Steps 1. Prepare Prepare your machine by installing Nimbus' dependencies . 2. Set up an execution client To run a beacon node, you need to have access to an execution client exposing the web3 API. Throughout, we'll assume an execution client is running on the same machine as the beacon node, but this is not required. See the execution client guide for instructions on how to pick and install an execution client. 3. Install Nimbus Download binaries Build from source Binary releases are available from GitHub and our APT repository (Debian/Ubuntu). We currently have binaries available for Linux AMD64 , ARM and ARM64 , Windows AMD64 and macOS ( AMD64 and ARM64 ). See the binaries guide on how to install them. Building Nimbus from source is simple and fully automated. Follow the build guide . 4. Sync from a trusted node While this step is not mandatory, since Nimbus will automatically start syncing process on the first start, we recommend doing it as it will allow you to get started in minutes instead of hours or even days. Follow our trusted node sync guide . 5. Start the node Once you've completed previous steps, it is time to start the beacon node. If you have skipped the syncing from a trusted node step, starting the node will initiate the syncing process . cd nimbus-eth2 Mainnet Holesky # Start a mainnet node ./run-mainnet-beacon-node.sh --web3-url = http://127.0.0.1:8551 --jwt-secret = /tmp/jwtsecret # Start a holesky testnet node ./run-holesky-beacon-node.sh --web3-url = http://127.0.0.1:8551 --jwt-secret = /tmp/jwtsecret Once the beacon node starts, you'll see it logging information to the console, like so: INF 2022 -07-19 15 :42:58.145+02:00 Launching beacon node topics = \"beacnde\" version = v22.10.1-97a1cdc4-stateofus ... Congratulations! Your beacon node is up and running! What next? If you will be running the node on a regular basis, it is recommended that you set up a systemd service that automatically restarts your node if the computer reboots. If you wish to stake, continue your journey by following the validator quick start . The monitoring page contains information about how to keep your node healthy.","title":"Beacon node"},{"location":"quick-start.html#beacon-node","text":"This page takes you through the steps of getting a standard installation of the Nimbus beacon node running. The quickstart setup involves running two nodes: an execution client and a beacon node. Both are needed to run a full Ethereum setup. To become a validator, you first need to set up a beacon node. The beacon node connects to the beacon chain network, syncs historical data, and provides API's to monitor and interact with the beacon chain. Running a beacon node is a worthwhile endeavor even if you are not planning on validating yourself! The guide assumes Ubuntu Linux is being used, and therefore some familiarity with the Linux command line is needed. Tip You can practice running the node safely on the Holesky testnet . Throughout, we'll provide instructions for both Holesky and Mainnet.","title":"Beacon node"},{"location":"quick-start.html#steps","text":"","title":"Steps"},{"location":"quick-start.html#1-prepare","text":"Prepare your machine by installing Nimbus' dependencies .","title":"1. Prepare"},{"location":"quick-start.html#2-set-up-an-execution-client","text":"To run a beacon node, you need to have access to an execution client exposing the web3 API. Throughout, we'll assume an execution client is running on the same machine as the beacon node, but this is not required. See the execution client guide for instructions on how to pick and install an execution client.","title":"2. Set up an execution client"},{"location":"quick-start.html#3-install-nimbus","text":"Download binaries Build from source Binary releases are available from GitHub and our APT repository (Debian/Ubuntu). We currently have binaries available for Linux AMD64 , ARM and ARM64 , Windows AMD64 and macOS ( AMD64 and ARM64 ). See the binaries guide on how to install them. Building Nimbus from source is simple and fully automated. Follow the build guide .","title":"3. Install Nimbus"},{"location":"quick-start.html#4-sync-from-a-trusted-node","text":"While this step is not mandatory, since Nimbus will automatically start syncing process on the first start, we recommend doing it as it will allow you to get started in minutes instead of hours or even days. Follow our trusted node sync guide .","title":"4. Sync from a trusted node"},{"location":"quick-start.html#5-start-the-node","text":"Once you've completed previous steps, it is time to start the beacon node. If you have skipped the syncing from a trusted node step, starting the node will initiate the syncing process . cd nimbus-eth2 Mainnet Holesky # Start a mainnet node ./run-mainnet-beacon-node.sh --web3-url = http://127.0.0.1:8551 --jwt-secret = /tmp/jwtsecret # Start a holesky testnet node ./run-holesky-beacon-node.sh --web3-url = http://127.0.0.1:8551 --jwt-secret = /tmp/jwtsecret Once the beacon node starts, you'll see it logging information to the console, like so: INF 2022 -07-19 15 :42:58.145+02:00 Launching beacon node topics = \"beacnde\" version = v22.10.1-97a1cdc4-stateofus ... Congratulations! Your beacon node is up and running! What next? If you will be running the node on a regular basis, it is recommended that you set up a systemd service that automatically restarts your node if the computer reboots. If you wish to stake, continue your journey by following the validator quick start . The monitoring page contains information about how to keep your node healthy.","title":"5. Start the node"},{"location":"resources.html","text":"Resources ethstaker discord : great place for tips and discussions Validator launchpad : to send deposits Beacon chain explorer : to monitor network health Nimbus discord : best place to ask questions and to stay up-to-date with critical updates Ethereum on ARM: Raspberry Pi 4 image + tutorial : turn your Raspberry Pi 4 into an eth1 or eth2 node just by flashing the MicroSD card","title":"Resources"},{"location":"resources.html#resources","text":"ethstaker discord : great place for tips and discussions Validator launchpad : to send deposits Beacon chain explorer : to monitor network health Nimbus discord : best place to ask questions and to stay up-to-date with critical updates Ethereum on ARM: Raspberry Pi 4 image + tutorial : turn your Raspberry Pi 4 into an eth1 or eth2 node just by flashing the MicroSD card","title":"Resources"},{"location":"rest-api.html","text":"Beacon API Nimbus exposes an extremely fast implementation of the standard Beacon API . The API allows you to use Nimbus together with third-party tooling such as validator clients, block explorers, as well as your own monitoring infrastructure. The Beacon API is a REST interface accessed via http . If you wish to expose the beacon node to the public internet, it is recommended to use a proxy such as nginx to provide caching and SSL support. Warning If you are running validators with your beacon node, do not expose the REST API to the public internet or use the same beacon node for deep historical queries: doing so may negatively affect validator performance. Test your tooling against our servers The API is available from: http://testing.mainnet.beacon-api.nimbus.team/ http://unstable.mainnet.beacon-api.nimbus.team/ http://unstable.holesky.beacon-api.nimbus.team/ You can make requests as follows (here we are requesting the version the Nimbus software version of the node in question): Mainnet testing branch Mainnet unstable branch Holesky unstable branch curl -X GET http://testing.mainnet.beacon-api.nimbus.team/eth/v1/node/version curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/node/version curl -X GET http://unstable.holesky.beacon-api.nimbus.team/eth/v1/node/version The test endpoints are part of pre-release testing and run an unstable version of Nimbus. We welcome reports about any problems you might have with them. They may also be unresponsive at times: please do not rely on them for validation . We may also disable them at any time without warning. Configure your node to run a local REST server By default, the REST interface is disabled. To enable it, start the beacon node with the --rest option: ./run-mainnet-beacon-node.sh --rest Then access the API from http://localhost:5052/ . For example, to get the version of the Nimbus software your node is running: curl -X GET http://localhost:5052/eth/v1/node/version By default, only connections from the same machine are entertained. The port and listening address can be further configured through the options --rest-port and --rest-address . Warning If you are using a validator client with a Nimbus beacon node, and running a Nimbus version prior to v1.5.5 , then you will need to launch the node with the --subscribe-all-subnets option enabled (in addition to the --rest option). Some useful commands Standard endpoints While these are all well documented in the official docs , here are a handful of simple examples to get you started: Genesis Retrieve details of the chain's genesis which can be used to identify chain. With our mainnet testing server With your own local server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/beacon/genesis curl -X GET http://localhost:5052/eth/v1/beacon/genesis Deposit contract Get deposit contract address (retrieve Eth1 deposit contract address and chain ID). With our mainnet testing server With your own local server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/config/deposit_contract curl -X GET http://localhost:5052/eth/v1/config/deposit_contract Peer count Get peer count: With our mainnet testing server With your own local server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/node/peer_count curl -X GET http://localhost:5052/eth/v1/node/peer_count Syncing status Get node syncing status (requests the beacon node to describe if it's currently syncing or not, and if it is, what block it is up to) With our mainnet testing server With your own local server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/node/syncing curl -X GET http://localhost:5052/eth/v1/node/syncing Fork schedule Get scheduled upcoming forks (retrieve all forks, past present and future, of which this node is aware) With our mainnet testing server With your own local server curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/config/fork_schedule curl -X GET http://localhost:5052/eth/v1/config/fork_schedule Nimbus specific endpoints In addition to supporting the standard endpoints, Nimbus has a set of specific endpoints which augment the standard API. Check Graffiti String With our mainnet testing server With your own local server curl -X GET http://testing.mainnet.beacon-api.nimbus.team/nimbus/v1/graffiti curl -X GET http://localhost:5052/nimbus/v1/graffiti Set Graffiti String With your own local server curl -X POST http://localhost:5052/nimbus/v1/graffiti -H \"Content-Type: text/plain\" -d \"new graffiti\" Set Log Level TBA Specification The complete API specification is well documented here See the repository Readme here","title":"Beacon API"},{"location":"rest-api.html#beacon-api","text":"Nimbus exposes an extremely fast implementation of the standard Beacon API . The API allows you to use Nimbus together with third-party tooling such as validator clients, block explorers, as well as your own monitoring infrastructure. The Beacon API is a REST interface accessed via http . If you wish to expose the beacon node to the public internet, it is recommended to use a proxy such as nginx to provide caching and SSL support. Warning If you are running validators with your beacon node, do not expose the REST API to the public internet or use the same beacon node for deep historical queries: doing so may negatively affect validator performance.","title":"Beacon API"},{"location":"rest-api.html#test-your-tooling-against-our-servers","text":"The API is available from: http://testing.mainnet.beacon-api.nimbus.team/ http://unstable.mainnet.beacon-api.nimbus.team/ http://unstable.holesky.beacon-api.nimbus.team/ You can make requests as follows (here we are requesting the version the Nimbus software version of the node in question): Mainnet testing branch Mainnet unstable branch Holesky unstable branch curl -X GET http://testing.mainnet.beacon-api.nimbus.team/eth/v1/node/version curl -X GET http://unstable.mainnet.beacon-api.nimbus.team/eth/v1/node/version curl -X GET http://unstable.holesky.beacon-api.nimbus.team/eth/v1/node/version The test endpoints are part of pre-release testing and run an unstable version of Nimbus. We welcome reports about any problems you might have with them. They may also be unresponsive at times: please do not rely on them for validation . We may also disable them at any time without warning.","title":"Test your tooling against our servers"},{"location":"rest-api.html#configure-your-node-to-run-a-local-rest-server","text":"By default, the REST interface is disabled. To enable it, start the beacon node with the --rest option: ./run-mainnet-beacon-node.sh --rest Then access the API from http://localhost:5052/ . For example, to get the version of the Nimbus software your node is running: curl -X GET http://localhost:5052/eth/v1/node/version By default, only connections from the same machine are entertained. The port and listening address can be further configured through the options --rest-port and --rest-address . Warning If you are using a validator client with a Nimbus beacon node, and running a Nimbus version prior to v1.5.5 , then you will need to launch the node with the --subscribe-all-subnets option enabled (in addition to the --rest option).","title":"Configure your node to run a local REST server"},{"location":"rest-api.html#some-useful-commands","text":"","title":"Some useful commands"},{"location":"rest-api.html#standard-endpoints","text":"While these are all well documented in the official docs , here are a handful of simple examples to get you started:","title":"Standard endpoints"},{"location":"rest-api.html#nimbus-specific-endpoints","text":"In addition to supporting the standard endpoints, Nimbus has a set of specific endpoints which augment the standard API.","title":"Nimbus specific endpoints"},{"location":"rest-api.html#specification","text":"The complete API specification is well documented here See the repository Readme here","title":"Specification"},{"location":"run-a-validator.html","text":"Validating Once your beacon node is running , the next step is to set up a validator. Nimbus doesn't require setting up a separate validator client process \u2014 the beacon node can itself perform validator duties. This is a simple, safe and efficient way to get started. Separate validator client While not needed, advanced users may want to use a separate validator client instead. Overview To start validating, you need to do these three steps, explained in more detail below: Make a deposit for your validator. Import your validator keys into Nimbus. Start performing validator duties by restarting the node. 1. Make a deposit for your validator To make a deposit, you will need to generate keys then submit a deposit transaction to the execution chain. Launchpad The process of setting up a validator is also documented at the Ethereum launchpad site: Mainnet Holesky EthStaker Launchpad or Holesky EF Launchpad Tip Before running your validator on Mainnet, you can (and should) verify that your setup works as expected by running it on the Holesky testnet . 1. Download the deposit tool Start by downloading and unpacking the deposit tool provided by the Ethereum Foundation: # Enter the nimbus folder cd nimbus-eth2 # Make sure to get the latest version from the download page wget https://github.com/ethereum/staking-deposit-cli/releases/download/v2.2.0/staking_deposit-cli-9ab0b05-linux-amd64.tar.gz # Unpack the archive tar xvf staking_deposit-cli-9ab0b05-linux-amd64.tar.gz --strip-components 2 2. Generate keys Live image You can increase the security of this process by downloading a Live Linux image . To do so, copy deposit to a USB stick, boot into the live image, and run the tool from inside the image. Make sure you don't enable Wi-Fi and unplug any Ethernet cables when using this process. The deposit tool generates a seed phrase, and uses this to create validator and withdrawal keys. Seed phrase If you lose you seed phrase and your withdrawal key, your funds will be lost forever! Mainnet Holesky # Run the deposit tool and follow the instructions on screen ./deposit new-mnemonic --chain mainnet # Run the deposit tool and follow the instructions on screen ./deposit new-mnemonic --chain holesky 3. Make the deposit Once created, the keys are used to create a deposit transaction on the Ethereum execution chain. Follow the instructions here to upload the deposit data. Warning If you are making a mainnet deposit make sure you verify that the deposit contract you are interacting with is the correct one. You should verify that the address is indeed: 0x00000000219ab540356cBB839Cbe05303d7705Fa Once you send off your transaction(s), before your validator starts producing blocks and attestations, there are two waiting periods. First, you wait for the beacon chain to recognize the block containing the deposit. This usually takes around 13 hours. Then, you wait in the queue for validator activation. Getting through the queue may take a few hours or days (assuming the chain is finalizing). No validators are accepted into the validator set while the chain isn't finalizing. The Pending Validators metric on the beaconcha.in will give you the size of the queue. With the keys created, you're ready for the next step: importing your validator keys. 2. Import your validator keys Tip systemd service file users will want to follow the service file guide instead! By finishing the first step, you will have a validator_keys folder containing several .json files in the nimbus-eth2 directory. We'll import the signing key of each validator to the data directory using the deposits import command: You'll be asked to enter the password you used when creating your keystore(s). Mainnet Holesky build/nimbus_beacon_node deposits import --data-dir = build/data/shared_mainnet_0 build/nimbus_beacon_node deposits import --data-dir = build/data/shared_holesky_0 On success, a message will be printed that your keys have been imported: NTC 2022-07-19 17:36:37.578+02:00 Keystore imported After importing keys, it is time to restart the node and check that the keys have been picked up by the beacon node. All the keys You can read more about the different types of keys here \u2014 the deposits import command will import the signing key only. Command line If your validator_keys folder is stored elsewhere, you can pass its location to the import command: Mainnet Holesky build/nimbus_beacon_node deposits import \\ --data-dir = build/data/shared_mainnet_0 \\ /path/to/keys build/nimbus_beacon_node deposits import \\ --data-dir = build/data/shared_holesky_0 \\ /path/to/keys Replacing /path/to/keys with the full pathname of where the validator_keys directory is found. Optimized import for a large number of validators If you plan to use a large number of validators (e.g. more than 100) on a single beacon node or a validator client, you might benefit from running the deposits import command with the option --method=single-salt . This will force Nimbus to use the same password and random salt value when encrypting all of the imported keystores which will later enable it to load the large number of validator keys almost instantly. The theoretical downside of using this approach is that it makes the brute-force cracking of all imported keystores computationally equivalent to cracking just one of them. Nevertheless, the security parameters used by Ethereum are such that cracking even a single keystore is considered computationally infeasible with current hardware. Troubleshooting If you come across an error, make sure that: You are using the correct data directory . For systemd users, look for the --data-dir option in the .service file. You are running the command as the correct user. For systemd users, look for the User= option in the .service . Assuming the user is called nimbus , prefix all commands with: sudo -u nimbus . Permissions for the data directory are wrong. See folder permissions for how to fix this. 3. Start validating Once your keys have been imported, it is time to configure a fee recipient and restart the beacon node to start validating. 1. Choose a fee recipient The fee recipient is an Ethereum address that receives transaction fees from the blocks that your validators produce. You can set up a separate address or reuse the address from which you funded your deposits. 2. (Re)start the node Press Ctrl-c to stop the beacon node if it's running, then use the same command as before to run it again, this time adding the --suggested-fee-recipient option in addition to --web3-url : Mainnet Holesky ./run-mainnet-beacon-node.sh --web3-url = http://127.0.0.1:8551 --suggested-fee-recipient = 0x... ./run-holesky-beacon-node.sh --web3-url = http://127.0.0.1:8551 --suggested-fee-recipient = 0x... 3. Check the logs Your beacon node will launch and connect your validator to the beacon chain network. To check that keys were imported correctly, look for Local validator attached in the logs: INF 2020-11-18 11:20:00.181+01:00 Launching beacon node ... NTC 2020-11-18 11:20:02.091+01:00 Local validator attached Congratulations! Your node is now ready to perform validator duties and earning a small amount of ETH every 6.4 minutes in return for keeping the Ethereum network secure! Depending on when the deposit was made, it may take a while before the first attestation is sent \u2014 this is normal. What next? While that's all there is to it, it is essential that you both keep an eye on your validator and keep Nimbus updated regularly. \ud83d\udcab","title":"Validating"},{"location":"run-a-validator.html#validating","text":"Once your beacon node is running , the next step is to set up a validator. Nimbus doesn't require setting up a separate validator client process \u2014 the beacon node can itself perform validator duties. This is a simple, safe and efficient way to get started. Separate validator client While not needed, advanced users may want to use a separate validator client instead.","title":"Validating"},{"location":"run-a-validator.html#overview","text":"To start validating, you need to do these three steps, explained in more detail below: Make a deposit for your validator. Import your validator keys into Nimbus. Start performing validator duties by restarting the node.","title":"Overview"},{"location":"run-a-validator.html#1-make-a-deposit-for-your-validator","text":"To make a deposit, you will need to generate keys then submit a deposit transaction to the execution chain. Launchpad The process of setting up a validator is also documented at the Ethereum launchpad site: Mainnet Holesky EthStaker Launchpad or Holesky EF Launchpad Tip Before running your validator on Mainnet, you can (and should) verify that your setup works as expected by running it on the Holesky testnet .","title":"1. Make a deposit for your validator"},{"location":"run-a-validator.html#1-download-the-deposit-tool","text":"Start by downloading and unpacking the deposit tool provided by the Ethereum Foundation: # Enter the nimbus folder cd nimbus-eth2 # Make sure to get the latest version from the download page wget https://github.com/ethereum/staking-deposit-cli/releases/download/v2.2.0/staking_deposit-cli-9ab0b05-linux-amd64.tar.gz # Unpack the archive tar xvf staking_deposit-cli-9ab0b05-linux-amd64.tar.gz --strip-components 2","title":"1. Download the deposit tool"},{"location":"run-a-validator.html#2-generate-keys","text":"Live image You can increase the security of this process by downloading a Live Linux image . To do so, copy deposit to a USB stick, boot into the live image, and run the tool from inside the image. Make sure you don't enable Wi-Fi and unplug any Ethernet cables when using this process. The deposit tool generates a seed phrase, and uses this to create validator and withdrawal keys. Seed phrase If you lose you seed phrase and your withdrawal key, your funds will be lost forever! Mainnet Holesky # Run the deposit tool and follow the instructions on screen ./deposit new-mnemonic --chain mainnet # Run the deposit tool and follow the instructions on screen ./deposit new-mnemonic --chain holesky","title":"2. Generate keys"},{"location":"run-a-validator.html#3-make-the-deposit","text":"Once created, the keys are used to create a deposit transaction on the Ethereum execution chain. Follow the instructions here to upload the deposit data. Warning If you are making a mainnet deposit make sure you verify that the deposit contract you are interacting with is the correct one. You should verify that the address is indeed: 0x00000000219ab540356cBB839Cbe05303d7705Fa Once you send off your transaction(s), before your validator starts producing blocks and attestations, there are two waiting periods. First, you wait for the beacon chain to recognize the block containing the deposit. This usually takes around 13 hours. Then, you wait in the queue for validator activation. Getting through the queue may take a few hours or days (assuming the chain is finalizing). No validators are accepted into the validator set while the chain isn't finalizing. The Pending Validators metric on the beaconcha.in will give you the size of the queue. With the keys created, you're ready for the next step: importing your validator keys.","title":"3. Make the deposit"},{"location":"run-a-validator.html#2-import-your-validator-keys","text":"Tip systemd service file users will want to follow the service file guide instead! By finishing the first step, you will have a validator_keys folder containing several .json files in the nimbus-eth2 directory. We'll import the signing key of each validator to the data directory using the deposits import command: You'll be asked to enter the password you used when creating your keystore(s). Mainnet Holesky build/nimbus_beacon_node deposits import --data-dir = build/data/shared_mainnet_0 build/nimbus_beacon_node deposits import --data-dir = build/data/shared_holesky_0 On success, a message will be printed that your keys have been imported: NTC 2022-07-19 17:36:37.578+02:00 Keystore imported After importing keys, it is time to restart the node and check that the keys have been picked up by the beacon node. All the keys You can read more about the different types of keys here \u2014 the deposits import command will import the signing key only.","title":"2. Import your validator keys"},{"location":"run-a-validator.html#command-line","text":"If your validator_keys folder is stored elsewhere, you can pass its location to the import command: Mainnet Holesky build/nimbus_beacon_node deposits import \\ --data-dir = build/data/shared_mainnet_0 \\ /path/to/keys build/nimbus_beacon_node deposits import \\ --data-dir = build/data/shared_holesky_0 \\ /path/to/keys Replacing /path/to/keys with the full pathname of where the validator_keys directory is found.","title":"Command line"},{"location":"run-a-validator.html#optimized-import-for-a-large-number-of-validators","text":"If you plan to use a large number of validators (e.g. more than 100) on a single beacon node or a validator client, you might benefit from running the deposits import command with the option --method=single-salt . This will force Nimbus to use the same password and random salt value when encrypting all of the imported keystores which will later enable it to load the large number of validator keys almost instantly. The theoretical downside of using this approach is that it makes the brute-force cracking of all imported keystores computationally equivalent to cracking just one of them. Nevertheless, the security parameters used by Ethereum are such that cracking even a single keystore is considered computationally infeasible with current hardware.","title":"Optimized import for a large number of validators"},{"location":"run-a-validator.html#troubleshooting","text":"If you come across an error, make sure that: You are using the correct data directory . For systemd users, look for the --data-dir option in the .service file. You are running the command as the correct user. For systemd users, look for the User= option in the .service . Assuming the user is called nimbus , prefix all commands with: sudo -u nimbus . Permissions for the data directory are wrong. See folder permissions for how to fix this.","title":"Troubleshooting"},{"location":"run-a-validator.html#3-start-validating","text":"Once your keys have been imported, it is time to configure a fee recipient and restart the beacon node to start validating.","title":"3. Start validating"},{"location":"run-a-validator.html#1-choose-a-fee-recipient","text":"The fee recipient is an Ethereum address that receives transaction fees from the blocks that your validators produce. You can set up a separate address or reuse the address from which you funded your deposits.","title":"1. Choose a fee recipient"},{"location":"run-a-validator.html#2-restart-the-node","text":"Press Ctrl-c to stop the beacon node if it's running, then use the same command as before to run it again, this time adding the --suggested-fee-recipient option in addition to --web3-url : Mainnet Holesky ./run-mainnet-beacon-node.sh --web3-url = http://127.0.0.1:8551 --suggested-fee-recipient = 0x... ./run-holesky-beacon-node.sh --web3-url = http://127.0.0.1:8551 --suggested-fee-recipient = 0x...","title":"2. (Re)start the node"},{"location":"run-a-validator.html#3-check-the-logs","text":"Your beacon node will launch and connect your validator to the beacon chain network. To check that keys were imported correctly, look for Local validator attached in the logs: INF 2020-11-18 11:20:00.181+01:00 Launching beacon node ... NTC 2020-11-18 11:20:02.091+01:00 Local validator attached Congratulations! Your node is now ready to perform validator duties and earning a small amount of ETH every 6.4 minutes in return for keeping the Ethereum network secure! Depending on when the deposit was made, it may take a while before the first attestation is sent \u2014 this is normal. What next? While that's all there is to it, it is essential that you both keep an eye on your validator and keep Nimbus updated regularly. \ud83d\udcab","title":"3. Check the logs"},{"location":"security_issues.html","text":"Security related issues For any security related issues, follow responsible disclosure standards. Do not file public issues. Please file a report at the Ethereum bug bounty program in order to receive a reward for your findings. When in doubt, please send an encrypted email to security@status.im and ask ( gpg key ). Security related issues are (sufficient but not necessary criteria): Soundness of protocols (consensus model, p2p protocols): consensus liveness and integrity. Errors and failures in the cryptographic primitives RCE vulnerabilities Any issues causing consensus splits from the rest of the network Denial of service (DOS) vectors Broken Access Control Memory Errors Security Misconfiguration Vulnerable Dependencies Authentication Failures Data Integrity Failures Logging and Monitoring Vulnerabilities","title":"Security issues"},{"location":"security_issues.html#security-related-issues","text":"For any security related issues, follow responsible disclosure standards. Do not file public issues. Please file a report at the Ethereum bug bounty program in order to receive a reward for your findings. When in doubt, please send an encrypted email to security@status.im and ask ( gpg key ). Security related issues are (sufficient but not necessary criteria): Soundness of protocols (consensus model, p2p protocols): consensus liveness and integrity. Errors and failures in the cryptographic primitives RCE vulnerabilities Any issues causing consensus splits from the rest of the network Denial of service (DOS) vectors Broken Access Control Memory Errors Security Misconfiguration Vulnerable Dependencies Authentication Failures Data Integrity Failures Logging and Monitoring Vulnerabilities","title":"Security related issues"},{"location":"start-syncing.html","text":"Sync your node Before you can use your node, it needs to sync with the network. Syncing starts automatically when you start your node, and may take several hours , or even days, depending on the performance of your hardware. Tip To get started more quickly, you can perform a trusted node sync instead. This requires access to a synced node or a third-party service. If you are planning to become a validator, you should ensure that your beacon node is completely synced before submitting your deposit; otherwise, you might miss attestations, proposal duties and sync committee duties until it has finished syncing. Note You need need to run an execution client ( web3 provider ) together with the beacon node. See here for instructions on how to do so. Networks Using Nimbus, you can connect either to a testnet or mainnet. Mainnet is the main Ethereum network where real assets are at stake, while testnets are used by users and developers alike to test their node and setup before committing real assets. If this is the first time you're setting up your node, it is recommended you run it on a testnet first. Later, when everything is working, you can easily switch to mainnet. Testnet Mainnet To start syncing the holesky testnet from the nimbus-eth2 repository, run: ./run-holesky-beacon-node.sh To start syncing the Ethereum beacon chain mainnet, run: ./run-mainnet-beacon-node.sh Log output You should see the following output: INF 2023-10-01 11:25:33.487+01:00 Launching beacon node ... INF 2023-10-01 11:25:34.556+01:00 Loading block dag from database topics=\"beacnde\" tid=19985314 path=build/data/shared_holesky_0/db INF 2023-10-01 11:25:35.921+01:00 Block dag initialized INF 2023-10-01 11:25:37.073+01:00 Generating new networking key ... NTC 2023-10-01 11:25:59.512+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 blockNumber=3836397 depositsProcessed=106147 NTC 2023-10-01 11:26:02.574+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 blockNumber=3841412 depositsProcessed=106391 ... INF 2023-10-01 11:26:31.000+00:00 Slot start topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:505 lastSlot=96566 scheduledSlot=96567 beaconTime=1w6d9h53m24s944us774ns peers=7 head=b54486c4:96563 headEpoch=3017 finalized=2f5d12e4:96479 finalizedEpoch=3014 INF 2023-10-01 11:26:36.285+00:00 Slot end topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:593 slot=96567 nextSlot=96568 head=b54486c4:96563 headEpoch=3017 finalizedHead=2f5d12e4:96479 finalizedEpoch=3014 ... Data directory While running, the beacon node will store chain data and other information its data directory, which by default is found in build/data . For more information, see the data directory guide . Command line options You can add command line options to the startup command. For example, to change the port to 9100, use: ./run-holesky-beacon-node.sh --tcp-port = 9100 --udp-port = 9100 To see a list of the command line options available to you, with descriptions, run: ./build/nimbus_beacon_node --help More information is available from the options page. Keep track of your sync progress See here for how to keep track of your sync progress. Checkpoint sync This feature is available from v23.11.0 onwards. You can use an existing synced node or a third-party service to accelerate sync significantly. Instead of downloading and verifying the entire blockchain, you can point Nimbus to a trusted block. Warning Selecting a block from an untrusted source or using an outdated block or state may lead to Nimbus syncing to an unexpected state. Especially when running a validator , it is vital to pick a recent trusted block for checkpoint sync, and to verify that Nimbus is synced to the correct state before starting validator duties. Note The Nimbus database must be empty to use checkpoint sync. When using a pre-existing database, checkpoint sync options are ignored. Tip A list of community-operated checkpoint sync nodes can be found here . To use checkpoint sync, run the following commands (inserting the checkpoint sync endpoint and your own trusted block root): Holesky Mainnet CHECKPOINT_SYNC_ENDPOINT = http://127.0.0.1:8551 TRUSTED_BLOCK_ROOT = 0x1234567890123456789012345678901234567890123456789012345678901234 ./run-holesky-beacon-node.sh \\ --external-beacon-api-url = $CHECKPOINT_SYNC_ENDPOINT \\ --trusted-block-root = $TRUSTED_BLOCK_ROOT TRUSTED_BLOCK_ROOT = 0x1234567890123456789012345678901234567890123456789012345678901234 ./run-mainnet-beacon-node.sh \\ --external-beacon-api-url = $CHECKPOINT_SYNC_ENDPOINT \\ --trusted-block-root = $TRUSTED_BLOCK_ROOT The following configuration options control checkpoint sync behaviour: Option Description --external-beacon-api-url External beacon API to use for checkpoint sync --trusted-block-root Recent trusted finalized block root to sync from external beacon API Uses the light client sync protocol to obtain the latest finalized checkpoint --trusted-state-root Recent trusted finalized state root to sync from external beacon API Takes precedence over --trusted-block-root if both are specified Info If the external beacon API does not support serving light client data , use the --trusted-state-root option instead of --trusted-block-root .","title":"Sync your node"},{"location":"start-syncing.html#sync-your-node","text":"Before you can use your node, it needs to sync with the network. Syncing starts automatically when you start your node, and may take several hours , or even days, depending on the performance of your hardware. Tip To get started more quickly, you can perform a trusted node sync instead. This requires access to a synced node or a third-party service. If you are planning to become a validator, you should ensure that your beacon node is completely synced before submitting your deposit; otherwise, you might miss attestations, proposal duties and sync committee duties until it has finished syncing. Note You need need to run an execution client ( web3 provider ) together with the beacon node. See here for instructions on how to do so.","title":"Sync your node"},{"location":"start-syncing.html#networks","text":"Using Nimbus, you can connect either to a testnet or mainnet. Mainnet is the main Ethereum network where real assets are at stake, while testnets are used by users and developers alike to test their node and setup before committing real assets. If this is the first time you're setting up your node, it is recommended you run it on a testnet first. Later, when everything is working, you can easily switch to mainnet. Testnet Mainnet To start syncing the holesky testnet from the nimbus-eth2 repository, run: ./run-holesky-beacon-node.sh To start syncing the Ethereum beacon chain mainnet, run: ./run-mainnet-beacon-node.sh","title":"Networks"},{"location":"start-syncing.html#log-output","text":"You should see the following output: INF 2023-10-01 11:25:33.487+01:00 Launching beacon node ... INF 2023-10-01 11:25:34.556+01:00 Loading block dag from database topics=\"beacnde\" tid=19985314 path=build/data/shared_holesky_0/db INF 2023-10-01 11:25:35.921+01:00 Block dag initialized INF 2023-10-01 11:25:37.073+01:00 Generating new networking key ... NTC 2023-10-01 11:25:59.512+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 blockNumber=3836397 depositsProcessed=106147 NTC 2023-10-01 11:26:02.574+00:00 Eth1 sync progress topics=\"eth1\" tid=21914 blockNumber=3841412 depositsProcessed=106391 ... INF 2023-10-01 11:26:31.000+00:00 Slot start topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:505 lastSlot=96566 scheduledSlot=96567 beaconTime=1w6d9h53m24s944us774ns peers=7 head=b54486c4:96563 headEpoch=3017 finalized=2f5d12e4:96479 finalizedEpoch=3014 INF 2023-10-01 11:26:36.285+00:00 Slot end topics=\"beacnde\" tid=21815 file=nimbus_beacon_node.nim:593 slot=96567 nextSlot=96568 head=b54486c4:96563 headEpoch=3017 finalizedHead=2f5d12e4:96479 finalizedEpoch=3014 ...","title":"Log output"},{"location":"start-syncing.html#data-directory","text":"While running, the beacon node will store chain data and other information its data directory, which by default is found in build/data . For more information, see the data directory guide .","title":"Data directory"},{"location":"start-syncing.html#command-line-options","text":"You can add command line options to the startup command. For example, to change the port to 9100, use: ./run-holesky-beacon-node.sh --tcp-port = 9100 --udp-port = 9100 To see a list of the command line options available to you, with descriptions, run: ./build/nimbus_beacon_node --help More information is available from the options page.","title":"Command line options"},{"location":"start-syncing.html#keep-track-of-your-sync-progress","text":"See here for how to keep track of your sync progress.","title":"Keep track of your sync progress"},{"location":"start-syncing.html#checkpoint-sync","text":"This feature is available from v23.11.0 onwards. You can use an existing synced node or a third-party service to accelerate sync significantly. Instead of downloading and verifying the entire blockchain, you can point Nimbus to a trusted block. Warning Selecting a block from an untrusted source or using an outdated block or state may lead to Nimbus syncing to an unexpected state. Especially when running a validator , it is vital to pick a recent trusted block for checkpoint sync, and to verify that Nimbus is synced to the correct state before starting validator duties. Note The Nimbus database must be empty to use checkpoint sync. When using a pre-existing database, checkpoint sync options are ignored. Tip A list of community-operated checkpoint sync nodes can be found here . To use checkpoint sync, run the following commands (inserting the checkpoint sync endpoint and your own trusted block root): Holesky Mainnet CHECKPOINT_SYNC_ENDPOINT = http://127.0.0.1:8551 TRUSTED_BLOCK_ROOT = 0x1234567890123456789012345678901234567890123456789012345678901234 ./run-holesky-beacon-node.sh \\ --external-beacon-api-url = $CHECKPOINT_SYNC_ENDPOINT \\ --trusted-block-root = $TRUSTED_BLOCK_ROOT TRUSTED_BLOCK_ROOT = 0x1234567890123456789012345678901234567890123456789012345678901234 ./run-mainnet-beacon-node.sh \\ --external-beacon-api-url = $CHECKPOINT_SYNC_ENDPOINT \\ --trusted-block-root = $TRUSTED_BLOCK_ROOT The following configuration options control checkpoint sync behaviour: Option Description --external-beacon-api-url External beacon API to use for checkpoint sync --trusted-block-root Recent trusted finalized block root to sync from external beacon API Uses the light client sync protocol to obtain the latest finalized checkpoint --trusted-state-root Recent trusted finalized state root to sync from external beacon API Takes precedence over --trusted-block-root if both are specified Info If the external beacon API does not support serving light client data , use the --trusted-state-root option instead of --trusted-block-root .","title":"Checkpoint sync"},{"location":"suggested-fee-recipient.html","text":"Set up suggested fee recipient The fee recipient is an Ethereum address that receives transaction fees from block production, separately from the proposer reward that accrues on the beacon chain. The fee recipient is forwarded to the execution client during block production. Each validator can have its own fee recipient set or a single recipient may be used. Warning The execution client is not required to follow the fee recipient suggestion and may instead send the fees to a different address \u2014 only use execution clients you trust! Setting the fee recipient Nimbus supports setting fee recipient per validator, or using defaults in both the validator client and beacon node. Per-validator fee recipients are set using the keymanager API . Any validator without a per-validator recipient set will fall back to the --suggested-fee-recipient option if configured or the withdrawal address of the validator. For each validator, it selects from the first available, in the following order: The keymanager API per-validator suggested fee recipient --suggested-fee-recipient in the validator client --suggested-fee-recipient in the beacon node If the validator has an associated withdrawal address , it will be used a final fallback option. Warning If none of the above are present, the transaction fees are sent to the zero address, effectively causing them to be lost. For example, nimbus_beacon_node --suggested-fee-recipient=0x70E47C843E0F6ab0991A3189c28F2957eb6d3842 suggests to the execution client that 0x70E47C843E0F6ab0991A3189c28F2957eb6d3842 might be the coinbase. If this Nimbus node has two validators, one of which has its own suggested fee recipient via the keymanager API and the other does not, the former would use its own per-validator suggested fee recipient, while the latter would fall back to 0x70E47C843E0F6ab0991A3189c28F2957eb6d3842 . Fee recipients are recorded publicly on-chain as part of proposed blocks, so suggested fee recipients should allow for this. Command line Mainnet Holesky Validator Client ./run-mainnet-beacon-node.sh --suggested-fee-recipient = 0x70E47C843E0F6ab0991A3189c28F2957eb6d3842 ./run-holesky-beacon-node.sh --suggested-fee-recipient = 0x70E47C843E0F6ab0991A3189c28F2957eb6d3842 ./nimbus_validator_client --suggested-fee-recipient = 0x70E47C843E0F6ab0991A3189c28F2957eb6d3842 Logs The configured fee recipient for every validator is logged at startup: NTC 2022-11-10 08:27:02.530+01:00 Local validator attached ... initial_fee_recipient=70E47C843E0F6ab0991A3189c28F2957eb6d3842","title":"Set up suggested fee recipient"},{"location":"suggested-fee-recipient.html#set-up-suggested-fee-recipient","text":"The fee recipient is an Ethereum address that receives transaction fees from block production, separately from the proposer reward that accrues on the beacon chain. The fee recipient is forwarded to the execution client during block production. Each validator can have its own fee recipient set or a single recipient may be used. Warning The execution client is not required to follow the fee recipient suggestion and may instead send the fees to a different address \u2014 only use execution clients you trust!","title":"Set up suggested fee recipient"},{"location":"suggested-fee-recipient.html#setting-the-fee-recipient","text":"Nimbus supports setting fee recipient per validator, or using defaults in both the validator client and beacon node. Per-validator fee recipients are set using the keymanager API . Any validator without a per-validator recipient set will fall back to the --suggested-fee-recipient option if configured or the withdrawal address of the validator. For each validator, it selects from the first available, in the following order: The keymanager API per-validator suggested fee recipient --suggested-fee-recipient in the validator client --suggested-fee-recipient in the beacon node If the validator has an associated withdrawal address , it will be used a final fallback option. Warning If none of the above are present, the transaction fees are sent to the zero address, effectively causing them to be lost. For example, nimbus_beacon_node --suggested-fee-recipient=0x70E47C843E0F6ab0991A3189c28F2957eb6d3842 suggests to the execution client that 0x70E47C843E0F6ab0991A3189c28F2957eb6d3842 might be the coinbase. If this Nimbus node has two validators, one of which has its own suggested fee recipient via the keymanager API and the other does not, the former would use its own per-validator suggested fee recipient, while the latter would fall back to 0x70E47C843E0F6ab0991A3189c28F2957eb6d3842 . Fee recipients are recorded publicly on-chain as part of proposed blocks, so suggested fee recipients should allow for this.","title":"Setting the fee recipient"},{"location":"suggested-fee-recipient.html#command-line","text":"Mainnet Holesky Validator Client ./run-mainnet-beacon-node.sh --suggested-fee-recipient = 0x70E47C843E0F6ab0991A3189c28F2957eb6d3842 ./run-holesky-beacon-node.sh --suggested-fee-recipient = 0x70E47C843E0F6ab0991A3189c28F2957eb6d3842 ./nimbus_validator_client --suggested-fee-recipient = 0x70E47C843E0F6ab0991A3189c28F2957eb6d3842","title":"Command line"},{"location":"suggested-fee-recipient.html#logs","text":"The configured fee recipient for every validator is logged at startup: NTC 2022-11-10 08:27:02.530+01:00 Local validator attached ... initial_fee_recipient=70E47C843E0F6ab0991A3189c28F2957eb6d3842","title":"Logs"},{"location":"troubleshooting.html","text":"Troubleshooting Note The commands on this page refer to mainnet. If you're running on holesky or another testnet, replace mainnet accordingly. We are continuously making improvements to both stability and resource usage. If you run into any problem with Nimbus and are not running the latest version, chances are they have already been fixed. See the update guide for instructions of how to upgrade. If you can't find a solution to your problem here, get in touch with us on our discord . Note When installing Nimbus, you will typically be using the latest stable release. However, the latest changes happen in the unstable branch. If you're looking to test the changes coming to the next Nimbus release, consider building Nimbus from source using the unstable branch. Networking A correctly configured network is key to getting good performance: the networking guide details everything you need to know! Low peer count If you see a message that looks like the following in your logs: Peer count low, no new peers discovered... Your node is finding it hard to find peers. It's possible that you may be behind a firewall. Try restarting your client and passing --nat:extip:$EXT_IP_ADDRESS as an option to ./run-mainnet-beacon-node.sh , where $EXT_IP_ADDRESS is your real IP. For example, if your real IP address is 1.2.3.4 , you'd run: ./run-mainnet-beacon-node.sh --nat:extip:1.2.3.4 If this doesn't improve things, you may need to set enr-auto-update and/or set up port forwarding . No peers for topic If you see a message that looks like the following in your logs: No peers for topic, skipping publish... This means you've missed an attestation because either your peer count is too low, or the quality of your peers is lacking. There can be several reasons behind why this is the case. The first thing to check is that your max peer count ( --max-peers ) hasn't been set too low. In order to ensure your attestations are published correctly, --max-peers should be set to 70, at the very least . Note Nimbus manages peers slightly differently to other clients (we automatically connect to more peers than we actually use, in order not to have to do costly reconnects). As such, --max-peers is set to 160 by default. If this doesn't fix the problem, please double check your node is able to receive incoming connections . Misc Console hanging for too long on update To update and restart, run git pull , make update , followed by make nimbus_beacon_node : cd nimbus-eth2 git pull make update # Update dependencies make nimbus_beacon_node # Rebuild beacon node ./run-mainnet-beacon-node.sh # Restart using same keys as last run If you find that make update causes the console to hang for too long, try running make update V=1 or make update V=2 instead (these will print a more verbose output to the console which may make it easier to diagnose the problem). Note Rest assured that when you restart the beacon node, the software will resume from where it left off, using the validator keys you have already imported. Starting over after importing wrong keys Your keys and secrets are stored in the data directory (usually build/data/shared_mainnet_0 ). If you imported the wrong keys, simply remove them from validators and secrets found in the data directory. Sync problems If you\u2019re experiencing sync problems, make sure that your network is healthy and that you have a recent version installed. In rare cases, such as after an unclean shutdown, it may happen that the database has been corrupted and you need to restart the sync. To do so, remove the db folder from the data directory and restart the node. You can get re-synced faster using trusted node sync . noCommand does not accept arguments If, on start, you see The command 'noCommand' does not accept arguments . Double check to see if your command line flags are in the correct format, e.g. --foo=bar , --baz , or --foo-bar=qux . Tip All options accepting values need a = between the option name and the value! Address already in use error If you're seeing an error that looks like: Error: unhandled exception: (98) Address already in use [TransportOsError] It means that you're running another node that is using the same port as the one you're trying to start or that you're trying to start a second instance of the same node. To change the base port, run: ./run-mainnet-beacon-node.sh --tcp-port=9100 --udp-port=9100 You can replace 9100 with a port of your choosing. Catching up on validator duties If you're being flooded with Catching up on validator duties messages, your CPU is probably too slow to run Nimbus. Please check that your setup matches our system requirements . Eth1 chain monitor failure If you see an error that looks like the following: {\"lvl\":\"ERR\",\"ts\":\"2021-05-11 09:05:53.547+00:00\",\"msg\":\"Eth1 chain monitoring failure, restarting\",\"topics\":\"eth1\",\"tid\":1,\"err\":\"Trying to access value with err: Failed to setup web3 connection\"} It is because your node can't connect to the web3 provider you have specified. Please double check that you've correctly specified your provider. If you haven't done so already, we recommend allowing multiple execution clients . Discovered new external address warning log WRN 2021-03-11 13:26:25.943-08:00 Discovered new external address but ENR auto update is off topics=\"discv5\" tid=77655 file=protocol.nim:940 majority=Some(\"myIPaddressHere\":9000) previous=None[Address] This message is displayed regularly when Nimbus cannot detect your correct IP address. It may be a sign that you have a dynamic IP address that keeps changing. Or that Nimbus is unable to get your IP from the UPnP . The first step is to try relaunching the beacon node with the --enr-auto-update option. If that doesn't fix the problem, double check that your ports are open and that you have port forwarding enabled on your gateway (assuming that you are behind a NAT ). See our page on monitoring the health of your node for more. Raspberry Pi Trouble transferring data to/from USB3.0 SSDs We have seen reports of degraded performance when using several types of USB3.0 to SSD adapters or when using native USB3.0 disk drives. This post on RPi forums details why there is a difference in behaviour from models prior to Pi 4 and the recommended workaround.","title":"Troubleshooting"},{"location":"troubleshooting.html#troubleshooting","text":"Note The commands on this page refer to mainnet. If you're running on holesky or another testnet, replace mainnet accordingly. We are continuously making improvements to both stability and resource usage. If you run into any problem with Nimbus and are not running the latest version, chances are they have already been fixed. See the update guide for instructions of how to upgrade. If you can't find a solution to your problem here, get in touch with us on our discord . Note When installing Nimbus, you will typically be using the latest stable release. However, the latest changes happen in the unstable branch. If you're looking to test the changes coming to the next Nimbus release, consider building Nimbus from source using the unstable branch.","title":"Troubleshooting"},{"location":"troubleshooting.html#networking","text":"A correctly configured network is key to getting good performance: the networking guide details everything you need to know!","title":"Networking"},{"location":"troubleshooting.html#low-peer-count","text":"If you see a message that looks like the following in your logs: Peer count low, no new peers discovered... Your node is finding it hard to find peers. It's possible that you may be behind a firewall. Try restarting your client and passing --nat:extip:$EXT_IP_ADDRESS as an option to ./run-mainnet-beacon-node.sh , where $EXT_IP_ADDRESS is your real IP. For example, if your real IP address is 1.2.3.4 , you'd run: ./run-mainnet-beacon-node.sh --nat:extip:1.2.3.4 If this doesn't improve things, you may need to set enr-auto-update and/or set up port forwarding .","title":"Low peer count"},{"location":"troubleshooting.html#no-peers-for-topic","text":"If you see a message that looks like the following in your logs: No peers for topic, skipping publish... This means you've missed an attestation because either your peer count is too low, or the quality of your peers is lacking. There can be several reasons behind why this is the case. The first thing to check is that your max peer count ( --max-peers ) hasn't been set too low. In order to ensure your attestations are published correctly, --max-peers should be set to 70, at the very least . Note Nimbus manages peers slightly differently to other clients (we automatically connect to more peers than we actually use, in order not to have to do costly reconnects). As such, --max-peers is set to 160 by default. If this doesn't fix the problem, please double check your node is able to receive incoming connections .","title":"No peers for topic"},{"location":"troubleshooting.html#misc","text":"","title":"Misc"},{"location":"troubleshooting.html#console-hanging-for-too-long-on-update","text":"To update and restart, run git pull , make update , followed by make nimbus_beacon_node : cd nimbus-eth2 git pull make update # Update dependencies make nimbus_beacon_node # Rebuild beacon node ./run-mainnet-beacon-node.sh # Restart using same keys as last run If you find that make update causes the console to hang for too long, try running make update V=1 or make update V=2 instead (these will print a more verbose output to the console which may make it easier to diagnose the problem). Note Rest assured that when you restart the beacon node, the software will resume from where it left off, using the validator keys you have already imported.","title":"Console hanging for too long on update"},{"location":"troubleshooting.html#starting-over-after-importing-wrong-keys","text":"Your keys and secrets are stored in the data directory (usually build/data/shared_mainnet_0 ). If you imported the wrong keys, simply remove them from validators and secrets found in the data directory.","title":"Starting over after importing wrong keys"},{"location":"troubleshooting.html#sync-problems","text":"If you\u2019re experiencing sync problems, make sure that your network is healthy and that you have a recent version installed. In rare cases, such as after an unclean shutdown, it may happen that the database has been corrupted and you need to restart the sync. To do so, remove the db folder from the data directory and restart the node. You can get re-synced faster using trusted node sync .","title":"Sync problems"},{"location":"troubleshooting.html#nocommand-does-not-accept-arguments","text":"If, on start, you see The command 'noCommand' does not accept arguments . Double check to see if your command line flags are in the correct format, e.g. --foo=bar , --baz , or --foo-bar=qux . Tip All options accepting values need a = between the option name and the value!","title":"noCommand does not accept arguments"},{"location":"troubleshooting.html#address-already-in-use-error","text":"If you're seeing an error that looks like: Error: unhandled exception: (98) Address already in use [TransportOsError] It means that you're running another node that is using the same port as the one you're trying to start or that you're trying to start a second instance of the same node. To change the base port, run: ./run-mainnet-beacon-node.sh --tcp-port=9100 --udp-port=9100 You can replace 9100 with a port of your choosing.","title":"Address already in use error"},{"location":"troubleshooting.html#catching-up-on-validator-duties","text":"If you're being flooded with Catching up on validator duties messages, your CPU is probably too slow to run Nimbus. Please check that your setup matches our system requirements .","title":"Catching up on validator duties"},{"location":"troubleshooting.html#eth1-chain-monitor-failure","text":"If you see an error that looks like the following: {\"lvl\":\"ERR\",\"ts\":\"2021-05-11 09:05:53.547+00:00\",\"msg\":\"Eth1 chain monitoring failure, restarting\",\"topics\":\"eth1\",\"tid\":1,\"err\":\"Trying to access value with err: Failed to setup web3 connection\"} It is because your node can't connect to the web3 provider you have specified. Please double check that you've correctly specified your provider. If you haven't done so already, we recommend allowing multiple execution clients .","title":"Eth1 chain monitor failure"},{"location":"troubleshooting.html#discovered-new-external-address-warning-log","text":"WRN 2021-03-11 13:26:25.943-08:00 Discovered new external address but ENR auto update is off topics=\"discv5\" tid=77655 file=protocol.nim:940 majority=Some(\"myIPaddressHere\":9000) previous=None[Address] This message is displayed regularly when Nimbus cannot detect your correct IP address. It may be a sign that you have a dynamic IP address that keeps changing. Or that Nimbus is unable to get your IP from the UPnP . The first step is to try relaunching the beacon node with the --enr-auto-update option. If that doesn't fix the problem, double check that your ports are open and that you have port forwarding enabled on your gateway (assuming that you are behind a NAT ). See our page on monitoring the health of your node for more.","title":"Discovered new external address warning log"},{"location":"troubleshooting.html#raspberry-pi","text":"","title":"Raspberry Pi"},{"location":"troubleshooting.html#trouble-transferring-data-tofrom-usb30-ssds","text":"We have seen reports of degraded performance when using several types of USB3.0 to SSD adapters or when using native USB3.0 disk drives. This post on RPi forums details why there is a difference in behaviour from models prior to Pi 4 and the recommended workaround.","title":"Trouble transferring data to/from USB3.0 SSDs"},{"location":"trusted-node-sync.html","text":"Sync from a trusted node When you start the beacon node for the first time, it connects to the beacon chain network and starts syncing automatically \u2014 a process that can take several hours or even days . Trusted node sync allows you to get started more quickly by fetching a recent checkpoint from a trusted node \u2014 you can get started in minutes instead of hours or days. To use trusted node sync, you must have access to a node that you trust and that exposes the Beacon API (for example, a locally running backup node). Should this node, or your connection to it, be compromised, your node will not be able to detect whether or not it is being served false information. It is possible to use trusted node sync with a third-party API provider. See here for how to verify that the chain you are given corresponds to the canonical chain at the time. Tip A list of community-operated checkpoint sync nodes can be found here . Always verify after after a checkpoint sync that the right chain was provided by the node. Perform a trusted node sync Tip Make sure to replace http://localhost:5052 in the commands below with the appropriate endpoint of the trusted beacon node. http://localhost:5052 is the default endpoint exposed by Nimbus, but this is not consistent across all clients. For example, if your trusted node is a Prysm node , it exposes 127.0.0.1:3500 by default. Which means you would run the commands below with --trusted-node-url=http://127.0.0.1:3500 Note The path specified for --data-dir must be an empty directory, as trusted node sync needs to be started from a fresh database. To start trusted node sync, run: Mainnet Holesky build/nimbus_beacon_node trustedNodeSync \\ --network:mainnet \\ --data-dir = build/data/shared_mainnet_0 \\ --trusted-node-url = http://localhost:5052 build/nimbus_beacon_node trustedNodeSync \\ --network:holesky \\ --data-dir = build/data/shared_holesky_0 \\ --trusted-node-url = http://localhost:5052 If the command was executed successfully, following log lines will be visible: Writing checkpoint state Writing checkpoint block And eventually: Done, your beacon node is ready to serve you! Don't forget to check that you're on the canonical chain by comparing the checkpoint root with other online sources. See https://nimbus.guide/trusted-node-sync.html for more information. After this the application will terminate and you can now start the beacon node as usual. Note Because trusted node sync by default copies blocks via REST, you may hit API limits if you are using a third-party provider. If this happens to you, you may need to use the --backfill option to delay the backfill of the block history . Verify you synced the correct chain When performing a trusted node sync, you can manually verify that the correct chain was synced by comparing the head hash with other sources (e.g. your friends, forums, chats and web sites). If you're syncing using your own backup node you can retrieve the current head from the node using: # Make sure to enable the `--rest` option when running your node: curl http://localhost:5052/eth/v1/beacon/blocks/head/root The head root is also printed in the log output at regular intervals. Note The same Beacon API request works with any API provider. For example, to compare it out with our mainnet testing server , you can run: curl -X GET http://testing.mainnet.beacon-api.nimbus.team/eth/v1/beacon/blocks/head/root Advanced Verify the downloaded state through the Nimbus light client This feature is available from v23.4.0 onwards. The --trusted-block-root option enables you to leverage the Nimbus light client in order to minimize the required trust in the specified Beacon API endpoint. After downloading a state snapshot, the light client will verify that it conforms to the established consensus on the network. Note that the provided --trusted-block-root should be somewhat recent, and that additional security precautions such as comparing the state root against block explorers is still recommended. Sync deposit history The --with-deposit-snapshot allows syncing deposit history via REST, avoiding the need to search the execution client for this information and thus allowing the client to more quickly start producing blocks. Note The API endpoint for downloading this information is a relatively recent addition to the Beacon API specification. It is available on nodes running Nimbus, but if you're using other checkpoint sources, consult their documentation with regards to the /eth/v1/beacon/deposit_snapshot endpoint. Tip It's safe to always specify this option. Nimbus will produce a warning if the specified beacon node doesn't support the required endpoint. Future versions of Nimbus will enable the option by default. Delay block history backfill By default, both state and block history will be downloaded from the trusted node. It is possible to get started more quickly by delaying the backfill of the block history using the --backfill=false parameter. In this case, the beacon node will first sync to the current head so that it can start performing its duties, then backfill the blocks from the network. You can also resume the trusted node backfill at any time by simply running the trusted node sync command again. Note While backfilling blocks, your node will not be able to answer historical requests or sync requests. This might lead to you being de-scored, and eventually disconnected, by your peers. Modify sync point By default, the node will sync up to the latest finalized checkpoint of the node that you're syncing with. While you can choose a different sync point using a state hash or a slot number, this state must fall on an epoch boundary: build/nimbus_beacon_node trustedNodeSync \\ --network:mainnet \\ --data-dir = build/data/shared_mainnet_0 \\ --state-id:1024 Sync from checkpoint files If you have a state file available, you can start the node using the --finalized-checkpoint-state : # Obtain a state and a block from a Beacon API - these must be in SSZ format: curl -o state.finalized.ssz \\ -H 'Accept: application/octet-stream' \\ http://localhost:5052/eth/v2/debug/beacon/states/finalized # Start the beacon node using the downloaded state as starting point ./run-mainnet-beacon-node.sh \\ --finalized-checkpoint-state = state.finalized.ssz Recreate historical state access indices When performing trusted node sync, the historical state data from the time before the trusted is not available. To recreate the indices and caches necessary for historical state access, run trusted node sync with the --reindex flag \u2014 this can be done on an already-synced node as well, in which case the process will simply resume where it left off: To recreate a historical index from before the checkpoint, it is necessary to first download an era archive containing the deep block history. build/nimbus_beacon_node trustedNodeSync \\ --network:mainnet \\ --data-dir = build/data/shared_mainnet_0 \\ --reindex = true","title":"Sync from a trusted node"},{"location":"trusted-node-sync.html#sync-from-a-trusted-node","text":"When you start the beacon node for the first time, it connects to the beacon chain network and starts syncing automatically \u2014 a process that can take several hours or even days . Trusted node sync allows you to get started more quickly by fetching a recent checkpoint from a trusted node \u2014 you can get started in minutes instead of hours or days. To use trusted node sync, you must have access to a node that you trust and that exposes the Beacon API (for example, a locally running backup node). Should this node, or your connection to it, be compromised, your node will not be able to detect whether or not it is being served false information. It is possible to use trusted node sync with a third-party API provider. See here for how to verify that the chain you are given corresponds to the canonical chain at the time. Tip A list of community-operated checkpoint sync nodes can be found here . Always verify after after a checkpoint sync that the right chain was provided by the node.","title":"Sync from a trusted node"},{"location":"trusted-node-sync.html#perform-a-trusted-node-sync","text":"Tip Make sure to replace http://localhost:5052 in the commands below with the appropriate endpoint of the trusted beacon node. http://localhost:5052 is the default endpoint exposed by Nimbus, but this is not consistent across all clients. For example, if your trusted node is a Prysm node , it exposes 127.0.0.1:3500 by default. Which means you would run the commands below with --trusted-node-url=http://127.0.0.1:3500 Note The path specified for --data-dir must be an empty directory, as trusted node sync needs to be started from a fresh database. To start trusted node sync, run: Mainnet Holesky build/nimbus_beacon_node trustedNodeSync \\ --network:mainnet \\ --data-dir = build/data/shared_mainnet_0 \\ --trusted-node-url = http://localhost:5052 build/nimbus_beacon_node trustedNodeSync \\ --network:holesky \\ --data-dir = build/data/shared_holesky_0 \\ --trusted-node-url = http://localhost:5052 If the command was executed successfully, following log lines will be visible: Writing checkpoint state Writing checkpoint block And eventually: Done, your beacon node is ready to serve you! Don't forget to check that you're on the canonical chain by comparing the checkpoint root with other online sources. See https://nimbus.guide/trusted-node-sync.html for more information. After this the application will terminate and you can now start the beacon node as usual. Note Because trusted node sync by default copies blocks via REST, you may hit API limits if you are using a third-party provider. If this happens to you, you may need to use the --backfill option to delay the backfill of the block history .","title":"Perform a trusted node sync"},{"location":"trusted-node-sync.html#verify-you-synced-the-correct-chain","text":"When performing a trusted node sync, you can manually verify that the correct chain was synced by comparing the head hash with other sources (e.g. your friends, forums, chats and web sites). If you're syncing using your own backup node you can retrieve the current head from the node using: # Make sure to enable the `--rest` option when running your node: curl http://localhost:5052/eth/v1/beacon/blocks/head/root The head root is also printed in the log output at regular intervals. Note The same Beacon API request works with any API provider. For example, to compare it out with our mainnet testing server , you can run: curl -X GET http://testing.mainnet.beacon-api.nimbus.team/eth/v1/beacon/blocks/head/root","title":"Verify you synced the correct chain"},{"location":"trusted-node-sync.html#advanced","text":"","title":"Advanced"},{"location":"trusted-node-sync.html#verify-the-downloaded-state-through-the-nimbus-light-client","text":"This feature is available from v23.4.0 onwards. The --trusted-block-root option enables you to leverage the Nimbus light client in order to minimize the required trust in the specified Beacon API endpoint. After downloading a state snapshot, the light client will verify that it conforms to the established consensus on the network. Note that the provided --trusted-block-root should be somewhat recent, and that additional security precautions such as comparing the state root against block explorers is still recommended.","title":"Verify the downloaded state through the Nimbus light client"},{"location":"trusted-node-sync.html#sync-deposit-history","text":"The --with-deposit-snapshot allows syncing deposit history via REST, avoiding the need to search the execution client for this information and thus allowing the client to more quickly start producing blocks. Note The API endpoint for downloading this information is a relatively recent addition to the Beacon API specification. It is available on nodes running Nimbus, but if you're using other checkpoint sources, consult their documentation with regards to the /eth/v1/beacon/deposit_snapshot endpoint. Tip It's safe to always specify this option. Nimbus will produce a warning if the specified beacon node doesn't support the required endpoint. Future versions of Nimbus will enable the option by default.","title":"Sync deposit history"},{"location":"trusted-node-sync.html#delay-block-history-backfill","text":"By default, both state and block history will be downloaded from the trusted node. It is possible to get started more quickly by delaying the backfill of the block history using the --backfill=false parameter. In this case, the beacon node will first sync to the current head so that it can start performing its duties, then backfill the blocks from the network. You can also resume the trusted node backfill at any time by simply running the trusted node sync command again. Note While backfilling blocks, your node will not be able to answer historical requests or sync requests. This might lead to you being de-scored, and eventually disconnected, by your peers.","title":"Delay block history backfill"},{"location":"trusted-node-sync.html#modify-sync-point","text":"By default, the node will sync up to the latest finalized checkpoint of the node that you're syncing with. While you can choose a different sync point using a state hash or a slot number, this state must fall on an epoch boundary: build/nimbus_beacon_node trustedNodeSync \\ --network:mainnet \\ --data-dir = build/data/shared_mainnet_0 \\ --state-id:1024","title":"Modify sync point"},{"location":"trusted-node-sync.html#sync-from-checkpoint-files","text":"If you have a state file available, you can start the node using the --finalized-checkpoint-state : # Obtain a state and a block from a Beacon API - these must be in SSZ format: curl -o state.finalized.ssz \\ -H 'Accept: application/octet-stream' \\ http://localhost:5052/eth/v2/debug/beacon/states/finalized # Start the beacon node using the downloaded state as starting point ./run-mainnet-beacon-node.sh \\ --finalized-checkpoint-state = state.finalized.ssz","title":"Sync from checkpoint files"},{"location":"trusted-node-sync.html#recreate-historical-state-access-indices","text":"When performing trusted node sync, the historical state data from the time before the trusted is not available. To recreate the indices and caches necessary for historical state access, run trusted node sync with the --reindex flag \u2014 this can be done on an already-synced node as well, in which case the process will simply resume where it left off: To recreate a historical index from before the checkpoint, it is necessary to first download an era archive containing the deep block history. build/nimbus_beacon_node trustedNodeSync \\ --network:mainnet \\ --data-dir = build/data/shared_mainnet_0 \\ --reindex = true","title":"Recreate historical state access indices"},{"location":"validator-client-options.html","text":"Validator client In the most simple setup, a single beacon node paired with an execution client is all that is needed to run a successful validator setup. Nimbus however also provides options for running advanded setups that provide additional security and redundancy. See the validator client page to get started! Multiple beacon nodes By default, the validator client will connect to a beacon node running on the same machine using the default port ( 5052 ). You can select one or more beacon nodes to connect to using the --beacon-node option: build/nimbus_validator_client \\ --beacon-node = http://127.0.0.1:5052 \\ --beacon-node = http://127.0.0.1:5053 Beacon node roles When configuring multiple beacon nodes, each beacon node can be assigned to perform specific tasks on behalf of the validator client. Role name Role calls attestation-data produceAttestationData() attestation-publish submitPoolAttestations() aggregated-data getAggregatedAttestation() aggregated-publish publishAggregateAndProofs() block-data produceBlockV2() block-publish publishBlock() sync-data getBlockRoot() produceSyncCommitteeContribution() sync-publish publishContributionAndProofs() submitPoolSyncCommitteeSignatures() duties getGenesis() getSpec() getSyncingStatus() getValidatorsActivity() getForkSchedule() getAttesterDuties() getProposerDuties() getSyncCommitteeDuties() getStateValidators() prepareSyncCommitteeSubnets() prepareBeaconCommitteeSubnet() Also, there could be combinations: Name Roles attestation attestation-data, attestation-publish aggregated aggregated-data, aggregated-publish block block-data, block-publish sync sync-data, sync-publish publish attestation-publish, aggregated-publish, block-publish, sync-publish data attestation-data, aggregated-data, block-data, sync-data all attestation, aggregated, block, sync, duty Configuration Roles are configured using the #roles= URL anchor. The default is all : Examples: http://127.0.0.1:5052/#roles=attestation-data,attestation-publish http://127.0.0.1:5053/#roles=block-proposal-data,block-proposal-publish http://127.0.0.1:5054/#roles=all http://127.0.0.1:5055/ also means all roles. Before usage, all the roles are stripped from beacon node URLs. Advanced topologies Fully redundant nodes Using multiple beacon nodes with the same role allows fully redundant setups. These setups are resilient against any single beacon node getting disconnected and provide additional \"entry points\" for the data that the validator client produces should any node experience poor connectivity. Sentry node setup In the Ethereum network, the block proposer is known up to 12 minutes before they propose the block. Because each validator sends attestations every 6 minutes, it is also possible to map the validator key to the beacon node IP address that serves it. Sentry nodes setups allow separating block production traffic from attestations and sync committee messages, making sure that a separate public IP address is used when proposing blocks. In this setup, there are two beacon nodes: One beacon node has all roles except block The other beacon node has the block role Separating block production makes it harder for an attacker to target the specific IP address that the validator would otherwise use for block production.","title":"Validator client"},{"location":"validator-client-options.html#validator-client","text":"In the most simple setup, a single beacon node paired with an execution client is all that is needed to run a successful validator setup. Nimbus however also provides options for running advanded setups that provide additional security and redundancy. See the validator client page to get started!","title":"Validator client"},{"location":"validator-client-options.html#multiple-beacon-nodes","text":"By default, the validator client will connect to a beacon node running on the same machine using the default port ( 5052 ). You can select one or more beacon nodes to connect to using the --beacon-node option: build/nimbus_validator_client \\ --beacon-node = http://127.0.0.1:5052 \\ --beacon-node = http://127.0.0.1:5053","title":"Multiple beacon nodes"},{"location":"validator-client-options.html#beacon-node-roles","text":"When configuring multiple beacon nodes, each beacon node can be assigned to perform specific tasks on behalf of the validator client. Role name Role calls attestation-data produceAttestationData() attestation-publish submitPoolAttestations() aggregated-data getAggregatedAttestation() aggregated-publish publishAggregateAndProofs() block-data produceBlockV2() block-publish publishBlock() sync-data getBlockRoot() produceSyncCommitteeContribution() sync-publish publishContributionAndProofs() submitPoolSyncCommitteeSignatures() duties getGenesis() getSpec() getSyncingStatus() getValidatorsActivity() getForkSchedule() getAttesterDuties() getProposerDuties() getSyncCommitteeDuties() getStateValidators() prepareSyncCommitteeSubnets() prepareBeaconCommitteeSubnet() Also, there could be combinations: Name Roles attestation attestation-data, attestation-publish aggregated aggregated-data, aggregated-publish block block-data, block-publish sync sync-data, sync-publish publish attestation-publish, aggregated-publish, block-publish, sync-publish data attestation-data, aggregated-data, block-data, sync-data all attestation, aggregated, block, sync, duty","title":"Beacon node roles"},{"location":"validator-client-options.html#configuration","text":"Roles are configured using the #roles= URL anchor. The default is all : Examples: http://127.0.0.1:5052/#roles=attestation-data,attestation-publish http://127.0.0.1:5053/#roles=block-proposal-data,block-proposal-publish http://127.0.0.1:5054/#roles=all http://127.0.0.1:5055/ also means all roles. Before usage, all the roles are stripped from beacon node URLs.","title":"Configuration"},{"location":"validator-client-options.html#advanced-topologies","text":"","title":"Advanced topologies"},{"location":"validator-client-options.html#fully-redundant-nodes","text":"Using multiple beacon nodes with the same role allows fully redundant setups. These setups are resilient against any single beacon node getting disconnected and provide additional \"entry points\" for the data that the validator client produces should any node experience poor connectivity.","title":"Fully redundant nodes"},{"location":"validator-client-options.html#sentry-node-setup","text":"In the Ethereum network, the block proposer is known up to 12 minutes before they propose the block. Because each validator sends attestations every 6 minutes, it is also possible to map the validator key to the beacon node IP address that serves it. Sentry nodes setups allow separating block production traffic from attestations and sync committee messages, making sure that a separate public IP address is used when proposing blocks. In this setup, there are two beacon nodes: One beacon node has all roles except block The other beacon node has the block role Separating block production makes it harder for an attacker to target the specific IP address that the validator would otherwise use for block production.","title":"Sentry node setup"},{"location":"validator-client.html","text":"Run a separate validator client Warning Some features of the validator client, such as the metrics server, are currently in BETA and details may change in response to community feedback. Please consult the --help screen for more details. By default, Nimbus integrates the validator client into the main beacon node process \u2014 this is a simple, safe and efficient way to run a validator. Advanced users may wish to run validators in a separate process, allowing more flexible deployment strategies. The Nimbus beacon node supports both its own and third-party validator clients via the built-in REST API . Warning So far, all slashings with known causes have been linked to overly complex setups involving separation between beacon node and validator client! Only use this setup if you've taken steps to mitigate the increased risk. Setup To run a separate validator client, you must first make sure that your beacon node has its REST API enabled: start it with the --rest option. Next, choose a data directory for the validator client and import the keys there: build/nimbus_beacon_node deposits import \\ --data-dir:build/data/vc_shared_holesky_0 \"<YOUR VALIDATOR KEYS DIRECTORY>\" Warning Do not use the same data directory for beacon node and validator client! They will both try to load the same keys which may result in slashing! Warning If you are migrating your keys from the beacon node to the validator client, simply move the secrets and validators folders in the beacon node data directory to the data directory of the validator client With the keys imported, you are ready to start validator client: build/nimbus_validator_client \\ --data-dir:build/data/vc_shared_holesky_0 Options See the validator client options page for more information about beacon node roles, redundant setups and sentry nodes!","title":"Run a separate validator client"},{"location":"validator-client.html#run-a-separate-validator-client","text":"Warning Some features of the validator client, such as the metrics server, are currently in BETA and details may change in response to community feedback. Please consult the --help screen for more details. By default, Nimbus integrates the validator client into the main beacon node process \u2014 this is a simple, safe and efficient way to run a validator. Advanced users may wish to run validators in a separate process, allowing more flexible deployment strategies. The Nimbus beacon node supports both its own and third-party validator clients via the built-in REST API . Warning So far, all slashings with known causes have been linked to overly complex setups involving separation between beacon node and validator client! Only use this setup if you've taken steps to mitigate the increased risk.","title":"Run a separate validator client"},{"location":"validator-client.html#setup","text":"To run a separate validator client, you must first make sure that your beacon node has its REST API enabled: start it with the --rest option. Next, choose a data directory for the validator client and import the keys there: build/nimbus_beacon_node deposits import \\ --data-dir:build/data/vc_shared_holesky_0 \"<YOUR VALIDATOR KEYS DIRECTORY>\" Warning Do not use the same data directory for beacon node and validator client! They will both try to load the same keys which may result in slashing! Warning If you are migrating your keys from the beacon node to the validator client, simply move the secrets and validators folders in the beacon node data directory to the data directory of the validator client With the keys imported, you are ready to start validator client: build/nimbus_validator_client \\ --data-dir:build/data/vc_shared_holesky_0","title":"Setup"},{"location":"validator-client.html#options","text":"See the validator client options page for more information about beacon node roles, redundant setups and sentry nodes!","title":"Options"},{"location":"validator-monitor.html","text":"Validator monitoring The validator monitoring feature allows for tracking the life cycle and performance of one or more validators in detail. Monitoring can be carried out for any validator, with slightly more detail for validators that are running in the same beacon node. Every time the validator performs a duty, the duty is recorded and the monitor keeps track of the reward-related events for having performed it. For example: When attesting, the attestation is added to an aggregate, then a block, before a reward is applied to the state When performing sync committee duties, likewise Validator actions can be traced either through logging, or comprehensive metrics that allow for creating alerts in monitoring tools. The metrics are broadly compatible with Lighthouse , thus dashboards and alerts can be used with either client with minor adjustments. Command line options The monitor is by default enabled for all keys that are validating via the beacon node. It can also be configured to monitor a specific list of validators, or be disabled entirely with --validator-monitor-auto=false . The --validator-monitor-details flag can be used to enable the detailed monitor mode. In this mode, the performance of each validator is monitored individually in metrics leading to a more detailed view of performance. Tip The detailed mode significantly increases the total number of published metrics for each monitored validator. When used with more than 10 validators, it may adversely impact performance of metrics collection and display. # Disable automatic monitoring of all validators used with this beacon node beacon node ./run-mainnet-beacon-node.sh --validator-monitor-auto = false ... # Enable monitoring of one or more specific validators ./run-mainnet-beacon-node.sh \\ --validator-monitor-pubkey = 0xa1d1ad0714035353258038e964ae9675dc0252ee22cea896825c01458e1807bfad2f9969338798548d9858a571f7425c \\ --validator-monitor-pubkey = 0xb2ff4716ed345b05dd1dfc6a5a9fa70856d8c75dcc9e881dd2f766d5f891326f0d10e96f3a444ce6c912b69c22c6754d ... # Publish detailed metrics for each monitored validator individually instead of an aggregate totals value ./run-mainnet-beacon-node.sh --validator-monitor-details ... Understanding monitoring When a validator performs a duty, such as signing an attestation or a sync committee message, this is broadcast to the network. Other nodes pick it up and package the message into an aggregate and later a block. The block is included in the canonical chain and a reward is given two epochs (~13 minutes) later. The monitor tracks each of these actions and will in detailed mode log each step at the INF level. If any step is missed (irrespective of detail mode), a NTC log is shown instead. The typical life cycle of an attestation might look something like the following: INF 2021-11-22 11:32:44.228+01:00 Attestation seen topics=\"val_mon\" attestation=\"(aggregation_bits: 0b0000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000, data: (slot: 2656363, index: 11, beacon_block_root: \\\"bbe7fc25\\\", source: \\\"83010:a8a1b125\\\", target: \\\"83011:6db281cd\\\"), signature: \\\"b88ef2f2\\\")\" src=api epoch=83011 validator=b93c290b INF 2021-11-22 11:32:51.293+01:00 Attestation included in aggregate topics=\"val_mon\" aggregate=\"(aggregation_bits: 0b1111111101011111001101111111101100111111110100111011111110110101110111111010111111011101111011101111111111101111100001111111100111, data: (slot: 2656363, index: 11, beacon_block_root: \\\"bbe7fc25\\\", source: \\\"83010:a8a1b125\\\", target: \\\"83011:6db281cd\\\"), signature: \\\"8576b3fc\\\")\" src=gossip epoch=83011 validator=b93c290b INF 2021-11-22 11:33:07.193+01:00 Attestation included in block attestation_data=\"(slot: 2656364, index: 9, beacon_block_root: \\\"c7761767\\\", source: \\\"83010:a8a1b125\\\", target: \\\"83011:6db281cd\\\")\" block_slot=2656365 inclusion_lag_slots=0 epoch=83011 validator=b65b6e1b The life cycle of a particular message can be traced by following the epoch=.... validator=... fields in the message. Failures at any point are recorded at a higher logging level, such as NTC : NTC 2021-11-17 20:53:42.108+01:00 Attestation failed to match head topics=\"chaindag\" epoch=81972 validator=... Failures are reported with a lag of two epochs (~13 minutes). To examine the log for potential root causes, the logs from the epoch in the failure message should be looked at. Warning It should be noted that metrics are tracked for the current history. In the case of a reorg on the chain \u2014 in particular a deep reorg \u2014 no attempt is made to revisit previously reported values. In the case that finality is delayed, the risk of stale metrics increases. Likewise, many metrics, such as aggregation inclusion, reflect conditions on the network. It may happen that the same message is counted more than once under certain conditions. Monitoring metrics For instructions on how to use Prometheus and Grafana, see these instructions . The full list of metrics supported by the validator monitoring feature can be seen in the source code or by examining the metrics output: curl -s localhost:8008/metrics | grep HELP.*validator_","title":"Validator monitoring"},{"location":"validator-monitor.html#validator-monitoring","text":"The validator monitoring feature allows for tracking the life cycle and performance of one or more validators in detail. Monitoring can be carried out for any validator, with slightly more detail for validators that are running in the same beacon node. Every time the validator performs a duty, the duty is recorded and the monitor keeps track of the reward-related events for having performed it. For example: When attesting, the attestation is added to an aggregate, then a block, before a reward is applied to the state When performing sync committee duties, likewise Validator actions can be traced either through logging, or comprehensive metrics that allow for creating alerts in monitoring tools. The metrics are broadly compatible with Lighthouse , thus dashboards and alerts can be used with either client with minor adjustments.","title":"Validator monitoring"},{"location":"validator-monitor.html#command-line-options","text":"The monitor is by default enabled for all keys that are validating via the beacon node. It can also be configured to monitor a specific list of validators, or be disabled entirely with --validator-monitor-auto=false . The --validator-monitor-details flag can be used to enable the detailed monitor mode. In this mode, the performance of each validator is monitored individually in metrics leading to a more detailed view of performance. Tip The detailed mode significantly increases the total number of published metrics for each monitored validator. When used with more than 10 validators, it may adversely impact performance of metrics collection and display. # Disable automatic monitoring of all validators used with this beacon node beacon node ./run-mainnet-beacon-node.sh --validator-monitor-auto = false ... # Enable monitoring of one or more specific validators ./run-mainnet-beacon-node.sh \\ --validator-monitor-pubkey = 0xa1d1ad0714035353258038e964ae9675dc0252ee22cea896825c01458e1807bfad2f9969338798548d9858a571f7425c \\ --validator-monitor-pubkey = 0xb2ff4716ed345b05dd1dfc6a5a9fa70856d8c75dcc9e881dd2f766d5f891326f0d10e96f3a444ce6c912b69c22c6754d ... # Publish detailed metrics for each monitored validator individually instead of an aggregate totals value ./run-mainnet-beacon-node.sh --validator-monitor-details ...","title":"Command line options"},{"location":"validator-monitor.html#understanding-monitoring","text":"When a validator performs a duty, such as signing an attestation or a sync committee message, this is broadcast to the network. Other nodes pick it up and package the message into an aggregate and later a block. The block is included in the canonical chain and a reward is given two epochs (~13 minutes) later. The monitor tracks each of these actions and will in detailed mode log each step at the INF level. If any step is missed (irrespective of detail mode), a NTC log is shown instead. The typical life cycle of an attestation might look something like the following: INF 2021-11-22 11:32:44.228+01:00 Attestation seen topics=\"val_mon\" attestation=\"(aggregation_bits: 0b0000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000, data: (slot: 2656363, index: 11, beacon_block_root: \\\"bbe7fc25\\\", source: \\\"83010:a8a1b125\\\", target: \\\"83011:6db281cd\\\"), signature: \\\"b88ef2f2\\\")\" src=api epoch=83011 validator=b93c290b INF 2021-11-22 11:32:51.293+01:00 Attestation included in aggregate topics=\"val_mon\" aggregate=\"(aggregation_bits: 0b1111111101011111001101111111101100111111110100111011111110110101110111111010111111011101111011101111111111101111100001111111100111, data: (slot: 2656363, index: 11, beacon_block_root: \\\"bbe7fc25\\\", source: \\\"83010:a8a1b125\\\", target: \\\"83011:6db281cd\\\"), signature: \\\"8576b3fc\\\")\" src=gossip epoch=83011 validator=b93c290b INF 2021-11-22 11:33:07.193+01:00 Attestation included in block attestation_data=\"(slot: 2656364, index: 9, beacon_block_root: \\\"c7761767\\\", source: \\\"83010:a8a1b125\\\", target: \\\"83011:6db281cd\\\")\" block_slot=2656365 inclusion_lag_slots=0 epoch=83011 validator=b65b6e1b The life cycle of a particular message can be traced by following the epoch=.... validator=... fields in the message. Failures at any point are recorded at a higher logging level, such as NTC : NTC 2021-11-17 20:53:42.108+01:00 Attestation failed to match head topics=\"chaindag\" epoch=81972 validator=... Failures are reported with a lag of two epochs (~13 minutes). To examine the log for potential root causes, the logs from the epoch in the failure message should be looked at. Warning It should be noted that metrics are tracked for the current history. In the case of a reorg on the chain \u2014 in particular a deep reorg \u2014 no attempt is made to revisit previously reported values. In the case that finality is delayed, the risk of stale metrics increases. Likewise, many metrics, such as aggregation inclusion, reflect conditions on the network. It may happen that the same message is counted more than once under certain conditions.","title":"Understanding monitoring"},{"location":"validator-monitor.html#monitoring-metrics","text":"For instructions on how to use Prometheus and Grafana, see these instructions . The full list of metrics supported by the validator monitoring feature can be seen in the source code or by examining the metrics output: curl -s localhost:8008/metrics | grep HELP.*validator_","title":"Monitoring metrics"},{"location":"voluntary-exit.html","text":"Perform a voluntary exit Voluntary exits allow validators to permanently stop performing their duties, and eventually recover the deposit. Exits are subject to a wait period that depends on the length of the exit queue. While a validator is exiting, it still must perform its duties in order not to lose funds to inactivity penalities. Warning Voluntary exits are irreversible . You won't be able to validate again with the same key. Note Voluntary exits won't be processed if the chain isn't finalizing. To perform a voluntary exit, make sure your beacon node is running with the --rest option enabled (e.g. ./run-mainnet-beacon-node.sh --rest ), then run: build/nimbus_beacon_node deposits exit --validator=<VALIDATOR_KEYSTORE_PATH> Note In the command above, you must replace <VALIDATOR_KEYSTORE_PATH> with the file-system path of an Ethereum ERC-2335 Keystore created by a tool such as staking-deposit-cli or ethdo . Tip You can perform multiple voluntary exits at once by supplying the --validator option multiple times on the command-line. This is typically more convenient when the provided keystores share the same password - you'll be asked to enter it only once. rest-url parameter The --rest-url parameter can be used to point the exit command to a specific node for publishing the request, as long as it's compatible with the REST API .","title":"Perform a voluntary exit"},{"location":"voluntary-exit.html#perform-a-voluntary-exit","text":"Voluntary exits allow validators to permanently stop performing their duties, and eventually recover the deposit. Exits are subject to a wait period that depends on the length of the exit queue. While a validator is exiting, it still must perform its duties in order not to lose funds to inactivity penalities. Warning Voluntary exits are irreversible . You won't be able to validate again with the same key. Note Voluntary exits won't be processed if the chain isn't finalizing. To perform a voluntary exit, make sure your beacon node is running with the --rest option enabled (e.g. ./run-mainnet-beacon-node.sh --rest ), then run: build/nimbus_beacon_node deposits exit --validator=<VALIDATOR_KEYSTORE_PATH> Note In the command above, you must replace <VALIDATOR_KEYSTORE_PATH> with the file-system path of an Ethereum ERC-2335 Keystore created by a tool such as staking-deposit-cli or ethdo . Tip You can perform multiple voluntary exits at once by supplying the --validator option multiple times on the command-line. This is typically more convenient when the provided keystores share the same password - you'll be asked to enter it only once.","title":"Perform a voluntary exit"},{"location":"voluntary-exit.html#rest-url-parameter","text":"The --rest-url parameter can be used to point the exit command to a specific node for publishing the request, as long as it's compatible with the REST API .","title":"rest-url parameter"},{"location":"web3signer.html","text":"Web3Signer Web3Signer is a remote signing server developed by Consensys. It offers a standardized REST API allowing the Nimbus beacon node or validator client to operate without storing any validator keys locally. You can instruct Nimbus to connect to a Web3Signer instance by supplying the --web3-signer-url command-line option. Since Nimbus obtains the list of validator keys automatically through the /api/v1/eth2/publicKeys Web3Signer API endpoint, no further configuration is required. Info By default, the list of validators will be refreshed once per hour. You can change the number of seconds between two updates with the --web3signer-update-interval command-line option. Tip You can use multiple Web3Signer instances by specifying the --web3-signer-url parameter multiple times. Alternatively, if you prefer not to depend on the automatic validator discovery mechanism or wish to take advantage of the advanced configurations described below, you have the option to permanently add multiple remote validators to a particular Nimbus data directory. This can be accomplished in two ways: On-the-fly Addition : Utilize the POST /eth/v1/remotekeys request when the Keymanager API is enabled. This allows you to dynamically add and remove remote validators as needed. Manual Configuration : You can manually create a remote keystore file within the validators directory of the client. This configuration will be loaded during the next restart of the client. Here is an example remote_keystore.json file: { \"version\": 3, \"description\": \"This is simple remote keystore file\", \"type\": \"verifying-web3signer\", \"pubkey\": \"0x8107ff6a5cfd1993f0dc19a6a9ec7dc742a528dd6f2e3e10189a4a6fc489ae6c7ba9070ea4e2e328f0d20b91cc129733\", \"remote\": \"http://127.0.0.1:15052\", \"ignore_ssl_verification\": true, \"proven_block_properties\": [ { \"path\": \".execution_payload.fee_recipient\" } ] } The fields have the following semantics: version - A decimal version number of the keystore format. This should be the first field. description - An optional description of the keystore that can be set to any value by the user. type - The type of the remote signer. The currently supported values are web3signer and verifying-web3signer (see below). Future versions may also support the protocol used by the Dirk signer. pubkey - The validator's public key encoded in hexadecimal form. remote - An URL of a remote signing server. remotes - A distributed keystore configuration including two or more remote signing servers. ignore_ssl_verification - An optional boolean flag allowing the use of self-signed certificates by the signing server. proven_block_properties - When the verifying-web3signer type is used, this is a list of locations within the SSZ block body for which the block signing requests will contain additional Merkle proofs, allowing the signer to verify certain details about the signed blocks (e.g. the fee_recipient value). Info The current version of the remote keystore format is 3 which adds support for the experimental verifying web3signer setups . Version 2 introduced the support for distributed keystores. Distributed Keystores Warn This functionality is not currently recommended for production use. All details described below are subject to change after a planned security audit of the implementation. Please refer to the Nimbus SSV Roadmap for more details. The distributed keystores offer a mechanism for spreading the work of signing validator messages over multiple signing servers in order to gain higher resilience (safety, liveness, or both) when compared to running a validator client on a single machine. When properly deployed, they can ensure that the validator key cannot be leaked to unauthorized third parties even when they have physical access to the machines where the signers are running. Furthermore, the scheme supports M-out-of-N threshold signing configurations that can remain active even when some of the signing servers are taken offline. For more information, please refer to the Distributed Validator Specification published by the EF. Currently, the distributed keystore support allows pairing a single Nimbus instance with multiple Web3Signer servers. Future versions may allow creating a highly available cluster of Nimbus instances that mutually act as signers for each other. Please refer to the Nimbus SSV Roadmap for more details. You can migrate any existing validator to a distributed keystore by splitting the key in multiple shares through the ncli_split_keystore program. Info Since this is a preview feature, the ncli_split_keystore program is currently available only when compiling from source. To build it, clone the nimbus-eth2 repository and run the make ncli_split_keystore command within its root. The resulting binary will be placed in the build folder sub-directory. Here is an example invocation of the command: build/ncli_split_keystore \\ --data-dir=$NIMBUS_DATA_DIR \\ --key=$VALIDATOR_PUBLIC_KEY \\ --threshold=2 \\ --remote-signer=http://signer-1-url \\ --remote-signer=http://signer-2-url \\ --remote-signer=http://signer-3-url \\ --out-dir=$OUT_DIR The specified output directory will contain the following files: $OUT_DIR/$VALIDATOR_PUBLIC_KEY/remote_keystore.json $OUT_DIR/shares/secrets/1/$SHARE_1_PUBLIC_KEY $OUT_DIR/shares/secrets/2/$SHARE_2_PUBLIC_KEY $OUT_DIR/shares/secrets/3/$SHARE_3_PUBLIC_KEY $OUT_DIR/shares/validators/1/$SHARE_1_PUBLIC_KEY/keystore.json $OUT_DIR/shares/validators/2/$SHARE_2_PUBLIC_KEY/keystore.json $OUT_DIR/shares/validators/3/$SHARE_3_PUBLIC_KEY/keystore.json The keystores under the created shares directory must be moved to the server where the respective remote signer will be running, while the directory containing the remote_keystore.json file must be placed in the validators directory of the Nimbus. The specified threshold value specifies the minimum number of signers that must remain online in order to create a signature. Naturally, this value must be lower than the total number of specified remote signers. If you are already using a threshold signing setup (e.g. based on Vouch and Dirk), you can migrate your partial keystores to any Web3Signer-compatible server and then manually create the remote_keystore.json file which must have the following structure: { \"version\": 3, \"pubkey\": \"0x8107ff6a5cfd1993f0dc19a6a9ec7dc742a528dd6f2e3e10189a4a6fc489ae6c7ba9070ea4e2e328f0d20b91cc129733\", \"remotes\": [ { \"url\": \"http://signer-1-url\", \"id\": 1, \"pubkey\": \"83b26b1466f001d723e516b9a4f2ca13c01d9541b17a51a62ee8651d223dcc2dead9ce212e499815f43f7f96dddd4f5a\" }, { \"url\": \"http://signer-2-url\", \"id\": 2, \"pubkey\": \"897727ba999519a55ac96b617a39cbba543fcd061a99fa4bcac8340dd19126a1130a8b6c2574add4debd4ec4c0c29faf\" }, { \"url\": \"http://signer-3-url\", \"id\": 3, ` \"pubkey\": \"a68f3ac58974d993908a2e5796d04222411bcdfbb7e5b8c7a10df6717792f9b968772495c554d1b508d4a738014c49b4\" } ], \"threshold\": 2, \"type\": \"web3signer\" } Verifying Web3Signer Warn This functionality is currently considered experimental. The described implementation may be incomplete and is subject to change in future releases. The verifying Web3Signer is an experimental extension to the Web3Signer protocol which allows the remote signer to verify certain details of the signed blocks before creating a signature (for example, the signer may require the signed block to have a particular fee recipient value). To enable this use case, the BLOCK_V2 request type of the /api/v1/eth2/sign/{identifier} endpoint is extended with an additional array field named proofs . The array consists of objects with the properties index , proof and value , where index is an arbitrary generalized index of any property nested under the block body and proof is its corresponding Merkle proof against the block body root included in the request. The value property is optional and it is included only when the SSZ hash of the field included in the Merkle proof doesn't match its value. Since the generalized index of a particular field may change in a hard-fork, in the remote keystore format the proven fields are usually specified by their name: { \"version\": 3, \"description\": \"This is simple remote keystore file\", \"type\": \"verifying-web3signer\", \"pubkey\": \"0x8107ff6a5cfd1993f0dc19a6a9ec7dc742a528dd6f2e3e10189a4a6fc489ae6c7ba9070ea4e2e328f0d20b91cc129733\", \"remote\": \"http://127.0.0.1:15052\", \"ignore_ssl_verification\": true, \"proven_block_properties\": [ { \"path\": \".execution_payload.fee_recipient\" }, { \"path\": \".graffiti\" } ] } Nimbus automatically computes the generalized index depending on the currently active fork. The remote signer is expected to verify the incoming Merkle proof through the standardized is_valid_merkle_branch function by utilizing a similar automatic mapping mechanism for the generalized index. You can instruct Nimbus to use the verifying Web3Signer protocol by either supplying the --verifying-web3-signer command-line option or by creating a remote keystore file in the format described above. You can use the command-line option --proven-block-property once or multiple times to enumerate the properties of the block for which Merkle proofs will be supplied.","title":"Web3Signer"},{"location":"web3signer.html#web3signer","text":"Web3Signer is a remote signing server developed by Consensys. It offers a standardized REST API allowing the Nimbus beacon node or validator client to operate without storing any validator keys locally. You can instruct Nimbus to connect to a Web3Signer instance by supplying the --web3-signer-url command-line option. Since Nimbus obtains the list of validator keys automatically through the /api/v1/eth2/publicKeys Web3Signer API endpoint, no further configuration is required. Info By default, the list of validators will be refreshed once per hour. You can change the number of seconds between two updates with the --web3signer-update-interval command-line option. Tip You can use multiple Web3Signer instances by specifying the --web3-signer-url parameter multiple times. Alternatively, if you prefer not to depend on the automatic validator discovery mechanism or wish to take advantage of the advanced configurations described below, you have the option to permanently add multiple remote validators to a particular Nimbus data directory. This can be accomplished in two ways: On-the-fly Addition : Utilize the POST /eth/v1/remotekeys request when the Keymanager API is enabled. This allows you to dynamically add and remove remote validators as needed. Manual Configuration : You can manually create a remote keystore file within the validators directory of the client. This configuration will be loaded during the next restart of the client. Here is an example remote_keystore.json file: { \"version\": 3, \"description\": \"This is simple remote keystore file\", \"type\": \"verifying-web3signer\", \"pubkey\": \"0x8107ff6a5cfd1993f0dc19a6a9ec7dc742a528dd6f2e3e10189a4a6fc489ae6c7ba9070ea4e2e328f0d20b91cc129733\", \"remote\": \"http://127.0.0.1:15052\", \"ignore_ssl_verification\": true, \"proven_block_properties\": [ { \"path\": \".execution_payload.fee_recipient\" } ] } The fields have the following semantics: version - A decimal version number of the keystore format. This should be the first field. description - An optional description of the keystore that can be set to any value by the user. type - The type of the remote signer. The currently supported values are web3signer and verifying-web3signer (see below). Future versions may also support the protocol used by the Dirk signer. pubkey - The validator's public key encoded in hexadecimal form. remote - An URL of a remote signing server. remotes - A distributed keystore configuration including two or more remote signing servers. ignore_ssl_verification - An optional boolean flag allowing the use of self-signed certificates by the signing server. proven_block_properties - When the verifying-web3signer type is used, this is a list of locations within the SSZ block body for which the block signing requests will contain additional Merkle proofs, allowing the signer to verify certain details about the signed blocks (e.g. the fee_recipient value). Info The current version of the remote keystore format is 3 which adds support for the experimental verifying web3signer setups . Version 2 introduced the support for distributed keystores.","title":"Web3Signer"},{"location":"web3signer.html#distributed-keystores","text":"Warn This functionality is not currently recommended for production use. All details described below are subject to change after a planned security audit of the implementation. Please refer to the Nimbus SSV Roadmap for more details. The distributed keystores offer a mechanism for spreading the work of signing validator messages over multiple signing servers in order to gain higher resilience (safety, liveness, or both) when compared to running a validator client on a single machine. When properly deployed, they can ensure that the validator key cannot be leaked to unauthorized third parties even when they have physical access to the machines where the signers are running. Furthermore, the scheme supports M-out-of-N threshold signing configurations that can remain active even when some of the signing servers are taken offline. For more information, please refer to the Distributed Validator Specification published by the EF. Currently, the distributed keystore support allows pairing a single Nimbus instance with multiple Web3Signer servers. Future versions may allow creating a highly available cluster of Nimbus instances that mutually act as signers for each other. Please refer to the Nimbus SSV Roadmap for more details. You can migrate any existing validator to a distributed keystore by splitting the key in multiple shares through the ncli_split_keystore program. Info Since this is a preview feature, the ncli_split_keystore program is currently available only when compiling from source. To build it, clone the nimbus-eth2 repository and run the make ncli_split_keystore command within its root. The resulting binary will be placed in the build folder sub-directory. Here is an example invocation of the command: build/ncli_split_keystore \\ --data-dir=$NIMBUS_DATA_DIR \\ --key=$VALIDATOR_PUBLIC_KEY \\ --threshold=2 \\ --remote-signer=http://signer-1-url \\ --remote-signer=http://signer-2-url \\ --remote-signer=http://signer-3-url \\ --out-dir=$OUT_DIR The specified output directory will contain the following files: $OUT_DIR/$VALIDATOR_PUBLIC_KEY/remote_keystore.json $OUT_DIR/shares/secrets/1/$SHARE_1_PUBLIC_KEY $OUT_DIR/shares/secrets/2/$SHARE_2_PUBLIC_KEY $OUT_DIR/shares/secrets/3/$SHARE_3_PUBLIC_KEY $OUT_DIR/shares/validators/1/$SHARE_1_PUBLIC_KEY/keystore.json $OUT_DIR/shares/validators/2/$SHARE_2_PUBLIC_KEY/keystore.json $OUT_DIR/shares/validators/3/$SHARE_3_PUBLIC_KEY/keystore.json The keystores under the created shares directory must be moved to the server where the respective remote signer will be running, while the directory containing the remote_keystore.json file must be placed in the validators directory of the Nimbus. The specified threshold value specifies the minimum number of signers that must remain online in order to create a signature. Naturally, this value must be lower than the total number of specified remote signers. If you are already using a threshold signing setup (e.g. based on Vouch and Dirk), you can migrate your partial keystores to any Web3Signer-compatible server and then manually create the remote_keystore.json file which must have the following structure: { \"version\": 3, \"pubkey\": \"0x8107ff6a5cfd1993f0dc19a6a9ec7dc742a528dd6f2e3e10189a4a6fc489ae6c7ba9070ea4e2e328f0d20b91cc129733\", \"remotes\": [ { \"url\": \"http://signer-1-url\", \"id\": 1, \"pubkey\": \"83b26b1466f001d723e516b9a4f2ca13c01d9541b17a51a62ee8651d223dcc2dead9ce212e499815f43f7f96dddd4f5a\" }, { \"url\": \"http://signer-2-url\", \"id\": 2, \"pubkey\": \"897727ba999519a55ac96b617a39cbba543fcd061a99fa4bcac8340dd19126a1130a8b6c2574add4debd4ec4c0c29faf\" }, { \"url\": \"http://signer-3-url\", \"id\": 3, ` \"pubkey\": \"a68f3ac58974d993908a2e5796d04222411bcdfbb7e5b8c7a10df6717792f9b968772495c554d1b508d4a738014c49b4\" } ], \"threshold\": 2, \"type\": \"web3signer\" }","title":"Distributed Keystores"},{"location":"web3signer.html#verifying-web3signer","text":"Warn This functionality is currently considered experimental. The described implementation may be incomplete and is subject to change in future releases. The verifying Web3Signer is an experimental extension to the Web3Signer protocol which allows the remote signer to verify certain details of the signed blocks before creating a signature (for example, the signer may require the signed block to have a particular fee recipient value). To enable this use case, the BLOCK_V2 request type of the /api/v1/eth2/sign/{identifier} endpoint is extended with an additional array field named proofs . The array consists of objects with the properties index , proof and value , where index is an arbitrary generalized index of any property nested under the block body and proof is its corresponding Merkle proof against the block body root included in the request. The value property is optional and it is included only when the SSZ hash of the field included in the Merkle proof doesn't match its value. Since the generalized index of a particular field may change in a hard-fork, in the remote keystore format the proven fields are usually specified by their name: { \"version\": 3, \"description\": \"This is simple remote keystore file\", \"type\": \"verifying-web3signer\", \"pubkey\": \"0x8107ff6a5cfd1993f0dc19a6a9ec7dc742a528dd6f2e3e10189a4a6fc489ae6c7ba9070ea4e2e328f0d20b91cc129733\", \"remote\": \"http://127.0.0.1:15052\", \"ignore_ssl_verification\": true, \"proven_block_properties\": [ { \"path\": \".execution_payload.fee_recipient\" }, { \"path\": \".graffiti\" } ] } Nimbus automatically computes the generalized index depending on the currently active fork. The remote signer is expected to verify the incoming Merkle proof through the standardized is_valid_merkle_branch function by utilizing a similar automatic mapping mechanism for the generalized index. You can instruct Nimbus to use the verifying Web3Signer protocol by either supplying the --verifying-web3-signer command-line option or by creating a remote keystore file in the format described above. You can use the command-line option --proven-block-property once or multiple times to enumerate the properties of the block for which Merkle proofs will be supplied.","title":"Verifying Web3Signer"},{"location":"withdrawals.html","text":"Withdraw your staked funds Withdrawals are enabled for each validator once it's configured to use 0x01 withdrawal credentials which specify an execution layer address that will be the beneficiary of all withdrawn funds. If your validator was created with 0x01 withdrawal credentials, it's already fully prepared for withdrawals and you can safely skip the next step. Updating your withdrawal credentials To migrate your validator from BLS to 0x01 withdrawal credentials, you have to use the same third-party tool that was used to generate the BLS key. You have to create a signed BLS-to-Execution-Change message that must be broadcast to the network (and eventually published in a beacon chain block) in order to execute the desired withdrawal credentials update. If you have used the staking-deposit-cli tool (formerly known as eth2.0-deposit-cli ), please follow the steps provided here . Alternatively, if you have used ethdo , follow the steps provided here . If you have used other software for generating your BLS withdrawal credentials, please refer to its documentation or development team for further assistance regarding creating a signed BLS-to-Execution-Change message. Warning Your choice of withdrawal address is permanent. If you ever wish to switch it later, the only option is to exit your validator and then create a new one. Tip The specified withdrawal address doesn't need to match the fee recipient address used by your validator. Tip It's recommended that you prepare your BLS-to-Execution-Change message on a secure device, disconnected from the internet. You can use an USB drive to transfer the produced JSON file to the machine where Nimbus is running and then use the following command to broadcast the message to the network: curl \\ -X POST \\ -H \u201cContent-type: application/json\u201d \\ -d @<Bls-to-Execution-Change-Filename> \\ http://localhost:5052/eth/v1/beacon/pool/bls_to_execution_changes Periodic withdrawals of staking rewards (partial withdrawals) Once the validator is configured with 0x01 withdrawal credentials, all staking rewards will be periodically withdrawn as long as the validator balance is above 32 ETH. No user action is required. Info It is not possible to manually request specific amounts of ETH to be withdrawn Full withdrawals To withdrawal the entire staked balance of your validator, you must perform a voluntary validator exit. Warning Voluntary exits are irreversible . You won't be able to validate again with the same key. Warning Make sure you've migrated your validator to 0x01 withdrawal credentials before exiting. The time required for the withdrawal to complete depends on multiple factors such as the total number of validators in the network, the number of other validators attempting to exit at the moment and the current time in the periodic withdrawals cycle. Under typical conditions, it's expected to take 2 to 7 days. Warning Do not remove the validator keys or shut down your validator software until the withdrawal operation is complete. Otherwise, you may incur protocol inactivity penalties. To perform the voluntary exit, make sure your beacon node is running with the --rest option enabled (e.g. ./run-mainnet-beacon-node.sh --rest ), then run: build/nimbus_beacon_node deposits exit --validator=<VALIDATOR_KEYSTORE_PATH> Note In the command above, you must replace <VALIDATOR_KEYSTORE_PATH> with the file-system path of an Ethereum ERC-2335 Keystore created by a tool such as staking-deposit-cli or ethdo . rest-url parameter The --rest-url parameter can be used to point the exit command to a specific node for publishing the request, as long as it's compatible with the REST API .","title":"Withdraw your staked funds"},{"location":"withdrawals.html#withdraw-your-staked-funds","text":"Withdrawals are enabled for each validator once it's configured to use 0x01 withdrawal credentials which specify an execution layer address that will be the beneficiary of all withdrawn funds. If your validator was created with 0x01 withdrawal credentials, it's already fully prepared for withdrawals and you can safely skip the next step.","title":"Withdraw your staked funds"},{"location":"withdrawals.html#updating-your-withdrawal-credentials","text":"To migrate your validator from BLS to 0x01 withdrawal credentials, you have to use the same third-party tool that was used to generate the BLS key. You have to create a signed BLS-to-Execution-Change message that must be broadcast to the network (and eventually published in a beacon chain block) in order to execute the desired withdrawal credentials update. If you have used the staking-deposit-cli tool (formerly known as eth2.0-deposit-cli ), please follow the steps provided here . Alternatively, if you have used ethdo , follow the steps provided here . If you have used other software for generating your BLS withdrawal credentials, please refer to its documentation or development team for further assistance regarding creating a signed BLS-to-Execution-Change message. Warning Your choice of withdrawal address is permanent. If you ever wish to switch it later, the only option is to exit your validator and then create a new one. Tip The specified withdrawal address doesn't need to match the fee recipient address used by your validator. Tip It's recommended that you prepare your BLS-to-Execution-Change message on a secure device, disconnected from the internet. You can use an USB drive to transfer the produced JSON file to the machine where Nimbus is running and then use the following command to broadcast the message to the network: curl \\ -X POST \\ -H \u201cContent-type: application/json\u201d \\ -d @<Bls-to-Execution-Change-Filename> \\ http://localhost:5052/eth/v1/beacon/pool/bls_to_execution_changes","title":"Updating your withdrawal credentials"},{"location":"withdrawals.html#periodic-withdrawals-of-staking-rewards-partial-withdrawals","text":"Once the validator is configured with 0x01 withdrawal credentials, all staking rewards will be periodically withdrawn as long as the validator balance is above 32 ETH. No user action is required. Info It is not possible to manually request specific amounts of ETH to be withdrawn","title":"Periodic withdrawals of staking rewards (partial withdrawals)"},{"location":"withdrawals.html#full-withdrawals","text":"To withdrawal the entire staked balance of your validator, you must perform a voluntary validator exit. Warning Voluntary exits are irreversible . You won't be able to validate again with the same key. Warning Make sure you've migrated your validator to 0x01 withdrawal credentials before exiting. The time required for the withdrawal to complete depends on multiple factors such as the total number of validators in the network, the number of other validators attempting to exit at the moment and the current time in the periodic withdrawals cycle. Under typical conditions, it's expected to take 2 to 7 days. Warning Do not remove the validator keys or shut down your validator software until the withdrawal operation is complete. Otherwise, you may incur protocol inactivity penalties. To perform the voluntary exit, make sure your beacon node is running with the --rest option enabled (e.g. ./run-mainnet-beacon-node.sh --rest ), then run: build/nimbus_beacon_node deposits exit --validator=<VALIDATOR_KEYSTORE_PATH> Note In the command above, you must replace <VALIDATOR_KEYSTORE_PATH> with the file-system path of an Ethereum ERC-2335 Keystore created by a tool such as staking-deposit-cli or ethdo .","title":"Full withdrawals"},{"location":"withdrawals.html#rest-url-parameter","text":"The --rest-url parameter can be used to point the exit command to a specific node for publishing the request, as long as it's compatible with the REST API .","title":"rest-url parameter"}]}